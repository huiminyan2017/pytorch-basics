{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ec032c",
   "metadata": {},
   "source": [
    "============================Data Manipulation===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cb45cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (0.15.1)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: sympy in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: networkx in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: filelock in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: triton==2.0.0 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: wheel in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.45.1)\n",
      "Requirement already satisfied: setuptools in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (79.0.1)\n",
      "Requirement already satisfied: cmake in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from triton==2.0.0->torch) (4.1.2)\n",
      "Requirement already satisfied: lit in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from triton==2.0.0->torch) (18.1.8)\n",
      "Requirement already satisfied: numpy in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: requests in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.7.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp310-cp310-linux_x86_64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp310-cp310-linux_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.5.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.5.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.4.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.4.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.3.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.3.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.2%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.1.2%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.1.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.1.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.0.2%2Bcpu-cp310-cp310-linux_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.0.1%2Bcpu-cp310-cp310-linux_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from requests->torchvision) (2.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from requests->torchvision) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from requests->torchvision) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from requests->torchvision) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.0.1+cpu\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch and related packages\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "150dd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(12, dtype=torch.float32)\n",
    "x = x.reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7d149a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]),\n",
       " True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.zeros(2, 3, 4, dtype=torch.float32)\n",
    "x2 = torch.zeros((2, 3, 4), dtype=torch.float32)\n",
    "\n",
    "x1, x1.allclose(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8c1b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(x1.numel()) #total number of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad39d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0991, -1.0500,  0.4707,  0.0314],\n",
       "         [ 0.7967, -0.8625, -0.3932, -1.5073],\n",
       "         [ 1.1234,  0.2980,  2.3677, -0.8220]]),\n",
       " tensor([[-0.0615, -0.1153, -0.9458, -0.1393],\n",
       "         [-0.6815, -1.1407, -1.4976, -0.1457],\n",
       "         [ 1.2717, -0.6156, -0.2133,  0.3379]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(3, 4) # standard Gaussian (normal) distribution \n",
    "x2 = torch.randn((3,4))\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e97d310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 20.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor([[1.0, 2, 3, 4], \n",
    "              [5, 6, 7, 8], \n",
    "              [9, 10, 11, 12]])\n",
    "X[2,3]  = 20\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4214369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 20., 20., 20.],\n",
       "        [20., 20., 20., 20.],\n",
       "        [ 9., 10., 11., 20.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2,:] = 20\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807de49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01],\n",
       "         [1.4841e+02, 4.0343e+02, 1.0966e+03, 2.9810e+03],\n",
       "         [8.1031e+03, 2.2026e+04, 5.9874e+04, 1.6275e+05]]),\n",
       " tensor([[ 2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13.]]),\n",
       " tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]]),\n",
       " tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]]),\n",
       " tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise operations\n",
    "X = torch.Tensor([[1.0, 2, 3, 4], \n",
    "              [5, 6, 7, 8], \n",
    "              [9, 10, 11, 12]])\n",
    "Y = torch.ones(3, 4)\n",
    "\n",
    "torch.exp(X) ,X + Y, X * Y, X / Y, X**Y #exponentiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca25aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]),\n",
       " tensor([12., 15., 18., 21.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1), X.sum(dim=0) \n",
    "\n",
    "# ‚ÄúThe dim=i means the operation is applied across the ith dimension, and the size of that dimension may change \n",
    "# (increase for concatenation, decrease for reduction). The other dimensions stay the same.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b549a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([12., 15., 18., 21.]),\n",
       " tensor([ 6., 22., 38.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.sum(dim=0), X.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b60013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìö THE GOLDEN RULE FOR REMEMBERING dim=0 vs dim=1\n",
      "============================================================\n",
      "Original tensor X (3 rows √ó 4 columns):\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Shape: torch.Size([3, 4])\n",
      "\n",
      "üîç UNDERSTANDING THE PATTERN:\n",
      "‚Ä¢ dim=0 = ROW dimension (first number in shape)\n",
      "‚Ä¢ dim=1 = COLUMN dimension (second number in shape)\n",
      "‚Ä¢ The dimension you specify gets COLLAPSED/JOINED\n",
      "\n",
      "========================================\n",
      "TORCH.CAT EXAMPLES:\n",
      "========================================\n",
      "\n",
      "Y to add: tensor([100., 200., 300., 400.]) (shape: torch.Size([1, 4]))\n",
      "\n",
      "üîΩ cat(dim=0) - ADDS ROWS (vertical stacking):\n",
      "tensor([[  0.,   1.,   2.,   3.],\n",
      "        [  4.,   5.,   6.,   7.],\n",
      "        [  8.,   9.,  10.,  11.],\n",
      "        [100., 200., 300., 400.]])\n",
      "Shape: torch.Size([3, 4]) ‚Üí torch.Size([4, 4]) (rows increased!)\n",
      "\n",
      "Z to add: tensor([100., 200., 300.]) (shape: torch.Size([3, 1]))\n",
      "\n",
      "‚û°Ô∏è cat(dim=1) - ADDS COLUMNS (horizontal stacking):\n",
      "tensor([[  0.,   1.,   2.,   3., 100.],\n",
      "        [  4.,   5.,   6.,   7., 200.],\n",
      "        [  8.,   9.,  10.,  11., 300.]])\n",
      "Shape: torch.Size([3, 4]) ‚Üí torch.Size([3, 5]) (columns increased!)\n"
     ]
    }
   ],
   "source": [
    "# üß† MEMORY TRICK for dim=0 vs dim=1\n",
    "# Think of dimensions as DIRECTIONS in your tensor\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìö THE GOLDEN RULE FOR REMEMBERING dim=0 vs dim=1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a clear example\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "print(\"Original tensor X (3 rows √ó 4 columns):\")\n",
    "print(X)\n",
    "print(f\"Shape: {X.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"üîç UNDERSTANDING THE PATTERN:\")\n",
    "print(\"‚Ä¢ dim=0 = ROW dimension (first number in shape)\")\n",
    "print(\"‚Ä¢ dim=1 = COLUMN dimension (second number in shape)\")\n",
    "print(\"‚Ä¢ The dimension you specify gets COLLAPSED/JOINED\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"TORCH.CAT EXAMPLES:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "Y = torch.tensor([[100., 200, 300, 400]])  \n",
    "print(f\"\\nY to add: {Y.squeeze()} (shape: {Y.shape})\")\n",
    "\n",
    "# dim=0: Add more ROWS (stack vertically)\n",
    "cat_dim0 = torch.cat((X, Y), dim=0)\n",
    "print(f\"\\nüîΩ cat(dim=0) - ADDS ROWS (vertical stacking):\")\n",
    "print(cat_dim0)\n",
    "print(f\"Shape: {X.shape} ‚Üí {cat_dim0.shape} (rows increased!)\")\n",
    "\n",
    "Z = torch.tensor([[100.], [200.], [300.]])  \n",
    "print(f\"\\nZ to add: {Z.squeeze()} (shape: {Z.shape})\")\n",
    "\n",
    "# dim=1: Add more COLUMNS (stack horizontally)  \n",
    "cat_dim1 = torch.cat((X, Z), dim=1)\n",
    "print(f\"\\n‚û°Ô∏è cat(dim=1) - ADDS COLUMNS (horizontal stacking):\")\n",
    "print(cat_dim1)\n",
    "print(f\"Shape: {X.shape} ‚Üí {cat_dim1.shape} (columns increased!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63dc9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "TENSOR.SUM EXAMPLES:\n",
      "========================================\n",
      "\n",
      "Original tensor X:\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Shape: torch.Size([3, 4])\n",
      "\n",
      "üîΩ sum(dim=0) - Sum DOWN the rows (collapse rows):\n",
      "Result: tensor([12., 15., 18., 21.])\n",
      "Shape: torch.Size([3, 4]) ‚Üí torch.Size([4]) (row dimension collapsed!)\n",
      "Math: Column 0: 0+4+8=12, Column 1: 1+5+9=15, etc.\n",
      "\n",
      "‚û°Ô∏è sum(dim=1) - Sum ACROSS the columns (collapse columns):\n",
      "Result: tensor([ 6., 22., 38.])\n",
      "Shape: torch.Size([3, 4]) ‚Üí torch.Size([3]) (column dimension collapsed!)\n",
      "Math: Row 0: 0+1+2+3=6, Row 1: 4+5+6+7=22, Row 2: 8+9+10+11=38\n",
      "\n",
      "üéØ UNIVERSAL MEMORY TRICKS:\n",
      "üí° dim=0: Think 'DOWN' (‚¨áÔ∏è) - operates on rows\n",
      "üí° dim=1: Think 'ACROSS' (‚û°Ô∏è) - operates on columns\n",
      "üí° For cat(): the dimension GROWS\n",
      "üí° For sum()/mean(): the dimension becomes 1 or disappears\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"TENSOR.SUM EXAMPLES:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "print(\"\\nOriginal tensor X:\")\n",
    "print(X)\n",
    "print(f\"Shape: {X.shape}\")\n",
    "\n",
    "# dim=0: Sum DOWN the rows (collapse row dimension)\n",
    "sum_dim0 = X.sum(dim=0)\n",
    "print(f\"\\nüîΩ sum(dim=0) - Sum DOWN the rows (collapse rows):\")\n",
    "print(f\"Result: {sum_dim0}\")\n",
    "print(f\"Shape: {X.shape} ‚Üí {sum_dim0.shape} (row dimension collapsed!)\")\n",
    "print(\"Math: Column 0: 0+4+8=12, Column 1: 1+5+9=15, etc.\")\n",
    "\n",
    "# dim=1: Sum ACROSS the columns (collapse column dimension)\n",
    "sum_dim1 = X.sum(dim=1)  \n",
    "print(f\"\\n‚û°Ô∏è sum(dim=1) - Sum ACROSS the columns (collapse columns):\")\n",
    "print(f\"Result: {sum_dim1}\")\n",
    "print(f\"Shape: {X.shape} ‚Üí {sum_dim1.shape} (column dimension collapsed!)\")\n",
    "print(\"Math: Row 0: 0+1+2+3=6, Row 1: 4+5+6+7=22, Row 2: 8+9+10+11=38\")\n",
    "\n",
    "print(\"\\n\" + \"üéØ UNIVERSAL MEMORY TRICKS:\")\n",
    "print(\"üí° dim=0: Think 'DOWN' (‚¨áÔ∏è) - operates on rows\")  \n",
    "print(\"üí° dim=1: Think 'ACROSS' (‚û°Ô∏è) - operates on columns\")\n",
    "print(\"üí° For cat(): the dimension GROWS\")\n",
    "print(\"üí° For sum()/mean(): the dimension becomes 1 or disappears\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f3ee2",
   "metadata": {},
   "source": [
    "Broadcasting:\n",
    "\n",
    "- Align dimensions\n",
    "\t- If x and y have different numbers of dimensions, prepend 1s to the shape of the smaller tensor until they have the same number of dimensions.\n",
    "- Compare each dimension from left to right (or right-to-left in some explanations):\n",
    "\t- If the sizes match, no problem.\n",
    "\t- If one of them is 1, that dimension is stretched (broadcasted) to match the other size.\n",
    "\t- If neither is 1 and sizes don‚Äôt match ‚Üí error.\n",
    "- Resulting shape\n",
    "\t- Each dimension size = max of x and y along that dimension (after prepending 1s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db07981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]),\n",
       " tensor([[0, 1],\n",
       "         [1, 2],\n",
       "         [2, 3]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "\n",
    "a, b, a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dce6831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(b)\n",
    "b = b + a\n",
    "id(b) == before  # False, b now references a new tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68e5876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(b)\n",
    "b[:] = b + a  # in-place update: Y[:] = <expression>\n",
    "id(b) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4bcbf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(b)\n",
    "b += a  # in-place assignment\n",
    "id(b) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b67e7597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4.]),\n",
       " tensor([1., 2., 3., 4.], dtype=torch.float64),\n",
       " array([1., 2., 3., 4.]),\n",
       " numpy.ndarray,\n",
       " torch.Tensor,\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting between Numpy and Torch tensors\n",
    "import numpy as np\n",
    "a = np.array([1.0, 2, 3, 4])\n",
    "b = torch.from_numpy(a)\n",
    "c = b.numpy()\n",
    "a, b, c, type(a), type(b), type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f682e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.5, 3.5, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert a size-1 tensor to a Python scalar\n",
    "a = torch.tensor([3.5])\n",
    "a.item(), float(a), int(a)  # 3.5 as a Python float, 3 as a Python int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f768160",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m3.5\u001b[39m, \u001b[38;5;241m4.5\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# error! only for size-1 tensors\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3.5, 4.5])\n",
    "float(a)  # error! only for size-1 tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c816438",
   "metadata": {},
   "source": [
    "===========================Data Preprocessing===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bc2457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price\n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f092c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /workspaces/pytorch-basics/.venv310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install pandas for data manipulation\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f55adafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms RoofType   Price\n",
      "0       NaN      NaN  127500\n",
      "1       2.0      NaN  106000\n",
      "2       4.0    Slate  178100\n",
      "3       NaN      NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "144a4533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   NumRooms RoofType\n",
       " 0       NaN      NaN\n",
       " 1       2.0      NaN\n",
       " 2       4.0    Slate\n",
       " 3       NaN      NaN,\n",
       "    NumRooms  RoofType_Slate  RoofType_nan\n",
       " 0       NaN           False          True\n",
       " 1       2.0           False          True\n",
       " 2       4.0            True         False\n",
       " 3       NaN           False          True,\n",
       "    NumRooms  RoofType_Slate\n",
       " 0       NaN           False\n",
       " 1       2.0           False\n",
       " 2       4.0            True\n",
       " 3       NaN           False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variable into dummy/indicator variables.\n",
    "\n",
    "org_inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = pd.get_dummies(org_inputs, dummy_na=True) # we can treat NaN as a category. like one-hot encoding\n",
    "inputs2 = pd.get_dummies(org_inputs, dummy_na=False) # we can treat NaN as a category. like one-hot encoding\n",
    "org_inputs, inputs, inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6b5854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       3.0           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       3.0           False          True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs), type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87fb5990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(inputs.to_numpy(dtype=float)) # two-step conversion: DataFrame -> NumPy -> PyTorch\n",
    "y = torch.tensor(targets.to_numpy(dtype=float))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f83d93",
   "metadata": {},
   "source": [
    "============================Linear Algebra===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7590bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]),\n",
       " torch.Size([1]),\n",
       " tensor(3.),\n",
       " tensor([2.]),\n",
       " tensor([5.]),\n",
       " torch.Size([1]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0) # Scalars are 0-dim tensors\n",
    "y = torch.tensor([2.0]) # 1-dim tensor with one element\n",
    "x.shape, y.shape, x, y, x+y, (x + y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8d90874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), torch.Size([3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3) # Vectors are 1-dim tensors\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65c9a1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 2, 4],\n",
       "         [1, 3, 5]]),\n",
       " tensor([[0, 2, 4],\n",
       "         [1, 3, 5]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2) # Matrices are 2-dim tensors\n",
    "A, A.T, A.transpose(0, 1)  # swap the two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9acbe61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4) # 3-dim tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78cc6584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]),\n",
       " tensor([[ 0.,  1.,  4.],\n",
       "         [ 9., 16., 25.]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
    "A, A + B, A * B # elementwise product of two matrices is called their Hadamard product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cb5f1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]),\n",
       " tensor(3.),\n",
       " torch.Size([]),\n",
       " tensor([3.]),\n",
       " torch.Size([1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "y = x.sum()\n",
    "z = x.sum(axis=0,keepdim=True)\n",
    "x, y, y.shape, z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47c61a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[12, 14, 16, 18],\n",
       "         [20, 22, 24, 26],\n",
       "         [28, 30, 32, 34]]),\n",
       " tensor([[12, 15, 18, 21],\n",
       "         [48, 51, 54, 57]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(24).reshape(2, 3, 4) # 3-dim tensor\n",
    "y = x.sum(axis=0) # sum over the first dimension, reduce the first dimension\n",
    "z = x.sum(axis=1) # sum over the second dimension, reduce the second dimension\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca5c7431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç UNDERSTANDING HOW reshape(2, 3, 4) FILLS THE TENSOR\n",
      "======================================================================\n",
      "Original 1D tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23])\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Reshaped to (2, 3, 4):\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "\n",
      "==================================================\n",
      "üéØ THE FILLING PATTERN: 'ROW-MAJOR' ORDER\n",
      "==================================================\n",
      "\n",
      "üìù Step-by-step filling process:\n",
      "1Ô∏è‚É£ Fill the LAST dimension (rightmost) first\n",
      "2Ô∏è‚É£ When last dimension is full, move to next row\n",
      "3Ô∏è‚É£ When all rows in a 'page' are full, move to next 'page'\n",
      "\n",
      "üèóÔ∏è Think of it as filling a bookshelf:\n",
      "   Dimension 0 (2): Number of shelves\n",
      "   Dimension 1 (3): Number of rows per shelf\n",
      "   Dimension 2 (4): Number of books per row\n",
      "\n",
      "üìñ Filling order visualization:\n",
      "   Shelf 0, Row 0: [0, 1, 2, 3]     ‚Üê Fill row left-to-right\n",
      "   Shelf 0, Row 1: [4, 5, 6, 7]     ‚Üê Then next row\n",
      "   Shelf 0, Row 2: [8, 9, 10, 11]   ‚Üê Then next row\n",
      "   Shelf 1, Row 0: [12, 13, 14, 15] ‚Üê Then next shelf, first row\n",
      "   Shelf 1, Row 1: [16, 17, 18, 19] ‚Üê Continue...\n",
      "   Shelf 1, Row 2: [20, 21, 22, 23] ‚Üê Until done\n"
     ]
    }
   ],
   "source": [
    "# üìö HOW RESHAPE FILLS DIMENSIONS: \"ROW-MAJOR\" ORDER\n",
    "print(\"=\"*70)\n",
    "print(\"üîç UNDERSTANDING HOW reshape(2, 3, 4) FILLS THE TENSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Start with the original 1D array\n",
    "original = torch.arange(24)\n",
    "print(f\"Original 1D tensor: {original}\")\n",
    "print(f\"Shape: {original.shape}\")\n",
    "\n",
    "# Reshape to 3D\n",
    "tensor_3d = original.reshape(2, 3, 4)\n",
    "print(f\"\\nReshaped to (2, 3, 4):\")\n",
    "print(tensor_3d)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéØ THE FILLING PATTERN: 'ROW-MAJOR' ORDER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìù Step-by-step filling process:\")\n",
    "print(\"1Ô∏è‚É£ Fill the LAST dimension (rightmost) first\")\n",
    "print(\"2Ô∏è‚É£ When last dimension is full, move to next row\")  \n",
    "print(\"3Ô∏è‚É£ When all rows in a 'page' are full, move to next 'page'\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Think of it as filling a bookshelf:\")\n",
    "print(\"   Dimension 0 (2): Number of shelves\")\n",
    "print(\"   Dimension 1 (3): Number of rows per shelf\") \n",
    "print(\"   Dimension 2 (4): Number of books per row\")\n",
    "\n",
    "print(\"\\nüìñ Filling order visualization:\")\n",
    "print(\"   Shelf 0, Row 0: [0, 1, 2, 3]     ‚Üê Fill row left-to-right\")\n",
    "print(\"   Shelf 0, Row 1: [4, 5, 6, 7]     ‚Üê Then next row\")  \n",
    "print(\"   Shelf 0, Row 2: [8, 9, 10, 11]   ‚Üê Then next row\")\n",
    "print(\"   Shelf 1, Row 0: [12, 13, 14, 15] ‚Üê Then next shelf, first row\")\n",
    "print(\"   Shelf 1, Row 1: [16, 17, 18, 19] ‚Üê Continue...\")\n",
    "print(\"   Shelf 1, Row 2: [20, 21, 22, 23] ‚Üê Until done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bc81ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üéØ ACCESSING ELEMENTS BY INDEX\n",
      "==================================================\n",
      "For tensor with shape (2, 3, 4):\n",
      "Index format: [dimension_0, dimension_1, dimension_2]\n",
      "\n",
      "tensor_3d[0, 0, 0] = 0 (first shelf, first row, first book)\n",
      "tensor_3d[0, 0, 3] = 3 (first shelf, first row, last book)\n",
      "tensor_3d[0, 1, 0] = 4 (first shelf, second row, first book)\n",
      "tensor_3d[1, 0, 0] = 12 (second shelf, first row, first book)\n",
      "tensor_3d[1, 2, 3] = 23 (last shelf, last row, last book)\n",
      "\n",
      "üîë KEY RULE:\n",
      "PyTorch uses 'C-style' or 'row-major' ordering\n",
      "‚Ä¢ Rightmost index changes fastest\n",
      "‚Ä¢ Fill from right to left in index space\n",
      "‚Ä¢ Same as NumPy's default behavior\n",
      "\n",
      "üí° Memory trick:\n",
      "Think like reading a book:\n",
      "1. Read words left-to-right (last dimension)\n",
      "2. Then move to next line (second dimension)\n",
      "3. Then turn the page (first dimension)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéØ ACCESSING ELEMENTS BY INDEX\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "tensor_3d = torch.arange(24).reshape(2, 3, 4)\n",
    "\n",
    "print(\"For tensor with shape (2, 3, 4):\")\n",
    "print(\"Index format: [dimension_0, dimension_1, dimension_2]\")\n",
    "\n",
    "print(f\"\\ntensor_3d[0, 0, 0] = {tensor_3d[0, 0, 0]} (first shelf, first row, first book)\")\n",
    "print(f\"tensor_3d[0, 0, 3] = {tensor_3d[0, 0, 3]} (first shelf, first row, last book)\")\n",
    "print(f\"tensor_3d[0, 1, 0] = {tensor_3d[0, 1, 0]} (first shelf, second row, first book)\")\n",
    "print(f\"tensor_3d[1, 0, 0] = {tensor_3d[1, 0, 0]} (second shelf, first row, first book)\")\n",
    "print(f\"tensor_3d[1, 2, 3] = {tensor_3d[1, 2, 3]} (last shelf, last row, last book)\")\n",
    "\n",
    "print(\"\\nüîë KEY RULE:\")\n",
    "print(\"PyTorch uses 'C-style' or 'row-major' ordering\")\n",
    "print(\"‚Ä¢ Rightmost index changes fastest\")\n",
    "print(\"‚Ä¢ Fill from right to left in index space\")\n",
    "print(\"‚Ä¢ Same as NumPy's default behavior\")\n",
    "\n",
    "print(\"\\nüí° Memory trick:\")\n",
    "print(\"Think like reading a book:\")\n",
    "print(\"1. Read words left-to-right (last dimension)\")\n",
    "print(\"2. Then move to next line (second dimension)\")\n",
    "print(\"3. Then turn the page (first dimension)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff7437c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  1.],\n",
       "          [ 2.,  3.],\n",
       "          [ 4.,  5.]],\n",
       " \n",
       "         [[ 6.,  7.],\n",
       "          [ 8.,  9.],\n",
       "          [10., 11.]]]),\n",
       " tensor([30., 36.]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "A= torch.arange(12, dtype=torch.float32).reshape(2, 3, 2)\n",
    "A, A.sum(axis=[0, 1])  # Reducing a matrix along both rows and columns via summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bed418ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç STEP-BY-STEP CALCULATION OF sum(axis=[0, 1])\n",
      "======================================================================\n",
      "Original tensor A with shape (2, 3, 2):\n",
      "tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.],\n",
      "         [ 4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.],\n",
      "         [ 8.,  9.],\n",
      "         [10., 11.]]])\n",
      "Shape: torch.Size([2, 3, 2])\n",
      "\n",
      "==================================================\n",
      "üéØ UNDERSTANDING axis=[0, 1]\n",
      "==================================================\n",
      "axis=[0, 1] means:\n",
      "‚Ä¢ Sum across dimension 0 (first dimension)\n",
      "‚Ä¢ AND dimension 1 (second dimension)\n",
      "‚Ä¢ This collapses BOTH dimensions 0 and 1\n",
      "‚Ä¢ Only dimension 2 remains!\n",
      "\n",
      "Result shape: torch.Size([2, 3, 2]) ‚Üí torch.Size([2])\n",
      "From (2, 3, 2) ‚Üí (2,) because we collapsed dimensions 0 and 1\n",
      "\n",
      "==================================================\n",
      "üßÆ MANUAL CALCULATION:\n",
      "==================================================\n",
      "Let's visualize the tensor as two 3√ó2 matrices:\n",
      "\n",
      "Matrix 0 (A[0,:,:]):\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.]])\n",
      "\n",
      "Matrix 1 (A[1,:,:]):\n",
      "tensor([[ 6.,  7.],\n",
      "        [ 8.,  9.],\n",
      "        [10., 11.]])\n",
      "\n",
      "To sum across axis=[0, 1], we add ALL elements in the same column position:\n",
      "\n",
      "For position [:, :, 0] (first column of each matrix):\n",
      "Elements: 0, 2, 4, 6, 8, 10\n",
      "Sum: 0 + 2 + 4 + 6 + 8 + 10 = 30.0\n",
      "\n",
      "For position [:, :, 1] (second column of each matrix):\n",
      "Elements: 1, 3, 5, 7, 9, 11\n",
      "Sum: 1 + 3 + 5 + 7 + 9 + 11 = 36.0\n",
      "\n",
      "Final result: [30.0, 36.0]\n",
      "Which matches: tensor([30., 36.])\n"
     ]
    }
   ],
   "source": [
    "# üìö DETAILED BREAKDOWN: A.sum(axis=[0, 1])\n",
    "print(\"=\"*70)\n",
    "print(\"üîç STEP-BY-STEP CALCULATION OF sum(axis=[0, 1])\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "A = torch.arange(12, dtype=torch.float32).reshape(2, 3, 2)\n",
    "print(\"Original tensor A with shape (2, 3, 2):\")\n",
    "print(A)\n",
    "print(f\"Shape: {A.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéØ UNDERSTANDING axis=[0, 1]\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"axis=[0, 1] means:\")\n",
    "print(\"‚Ä¢ Sum across dimension 0 (first dimension)\")\n",
    "print(\"‚Ä¢ AND dimension 1 (second dimension)\")\n",
    "print(\"‚Ä¢ This collapses BOTH dimensions 0 and 1\")\n",
    "print(\"‚Ä¢ Only dimension 2 remains!\")\n",
    "\n",
    "print(f\"\\nResult shape: {A.shape} ‚Üí {A.sum(axis=[0, 1]).shape}\")\n",
    "print(\"From (2, 3, 2) ‚Üí (2,) because we collapsed dimensions 0 and 1\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üßÆ MANUAL CALCULATION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Let's visualize the tensor as two 3√ó2 matrices:\")\n",
    "print(\"\\nMatrix 0 (A[0,:,:]):\")\n",
    "print(A[0])\n",
    "print(\"\\nMatrix 1 (A[1,:,:]):\")\n",
    "print(A[1])\n",
    "\n",
    "print(\"\\nTo sum across axis=[0, 1], we add ALL elements in the same column position:\")\n",
    "print(\"\\nFor position [:, :, 0] (first column of each matrix):\")\n",
    "print(\"Elements: 0, 2, 4, 6, 8, 10\")\n",
    "print(f\"Sum: 0 + 2 + 4 + 6 + 8 + 10 = {A[:, :, 0].sum()}\")\n",
    "\n",
    "print(\"\\nFor position [:, :, 1] (second column of each matrix):\")  \n",
    "print(\"Elements: 1, 3, 5, 7, 9, 11\")\n",
    "print(f\"Sum: 1 + 3 + 5 + 7 + 9 + 11 = {A[:, :, 1].sum()}\")\n",
    "\n",
    "print(f\"\\nFinal result: [{A[:, :, 0].sum()}, {A[:, :, 1].sum()}]\")\n",
    "print(f\"Which matches: {A.sum(axis=[0, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üîÑ COMPARING DIFFERENT AXIS COMBINATIONS\n",
      "==================================================\n",
      "Original shape: torch.Size([2, 3, 2])\n",
      "\n",
      "Different summation options:\n",
      "A.sum(axis=0).shape = torch.Size([3, 2]) ‚Üê Sum along axis 0 only\n",
      "A.sum(axis=1).shape = torch.Size([2, 2]) ‚Üê Sum along axis 1 only\n",
      "A.sum(axis=2).shape = torch.Size([2, 3]) ‚Üê Sum along axis 2 only\n",
      "A.sum(axis=[0,1]).shape = torch.Size([2]) ‚Üê Sum along axes 0 AND 1\n",
      "A.sum(axis=[0,2]).shape = torch.Size([3]) ‚Üê Sum along axes 0 AND 2\n",
      "A.sum(axis=[1,2]).shape = torch.Size([2]) ‚Üê Sum along axes 1 AND 2\n",
      "A.sum().shape = torch.Size([]) ‚Üê Sum ALL elements (scalar)\n",
      "\n",
      "üéØ KEY INSIGHT:\n",
      "‚Ä¢ Each axis in the list gets COLLAPSED (disappears)\n",
      "‚Ä¢ Remaining dimensions keep their original size\n",
      "‚Ä¢ Order of axes in the list doesn't matter: [0,1] = [1,0]\n",
      "\n",
      "üí° Memory trick:\n",
      "Think of it as 'Which dimensions do I want to REMOVE?'\n",
      "‚Ä¢ axis=[0,1] ‚Üí Remove dimensions 0 and 1, keep dimension 2\n",
      "‚Ä¢ Result has only the dimensions NOT listed in axis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîÑ COMPARING DIFFERENT AXIS COMBINATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "A = torch.arange(12, dtype=torch.float32).reshape(2, 3, 2)\n",
    "\n",
    "print(f\"Original shape: {A.shape}\")\n",
    "print(\"\\nDifferent summation options:\")\n",
    "\n",
    "# Single axis sums\n",
    "print(f\"A.sum(axis=0).shape = {A.sum(axis=0).shape} ‚Üê Sum along axis 0 only\")\n",
    "print(f\"A.sum(axis=1).shape = {A.sum(axis=1).shape} ‚Üê Sum along axis 1 only\") \n",
    "print(f\"A.sum(axis=2).shape = {A.sum(axis=2).shape} ‚Üê Sum along axis 2 only\")\n",
    "\n",
    "# Multi-axis sums\n",
    "print(f\"A.sum(axis=[0,1]).shape = {A.sum(axis=[0,1]).shape} ‚Üê Sum along axes 0 AND 1\")\n",
    "print(f\"A.sum(axis=[0,2]).shape = {A.sum(axis=[0,2]).shape} ‚Üê Sum along axes 0 AND 2\")\n",
    "print(f\"A.sum(axis=[1,2]).shape = {A.sum(axis=[1,2]).shape} ‚Üê Sum along axes 1 AND 2\")\n",
    "\n",
    "# All axes\n",
    "print(f\"A.sum().shape = {A.sum().shape} ‚Üê Sum ALL elements (scalar)\")\n",
    "\n",
    "print(\"\\nüéØ KEY INSIGHT:\")\n",
    "print(\"‚Ä¢ Each axis in the list gets COLLAPSED (disappears)\")\n",
    "print(\"‚Ä¢ Remaining dimensions keep their original size\") \n",
    "print(\"‚Ä¢ Order of axes in the list doesn't matter: [0,1] = [1,0]\")\n",
    "\n",
    "print(\"\\nüí° Memory trick:\")\n",
    "print(\"Think of it as 'Which dimensions do I want to REMOVE?'\")\n",
    "print(\"‚Ä¢ axis=[0,1] ‚Üí Remove dimensions 0 and 1, keep dimension 2\")\n",
    "print(\"‚Ä¢ Result has only the dimensions NOT listed in axis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260b295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.), tensor(True))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "y = torch.ones(3, dtype = torch.float32)\n",
    "z = torch.dot(x, y) # dot product of two vectors, or x @ y; can be used as weighted average\n",
    "x, y, z, z == (x * y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e16d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([0., 1., 2.]),\n",
       " tensor([ 5., 14.]),\n",
       " tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "x = torch.arange(3, dtype=torch.float32)\n",
    "A, x, torch.mv(A, x), A@x # matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8d95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = torch.ones(3, 4)\n",
    "torch.mm(A, B), A@B # matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25b683f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(7.))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "x1 = torch.norm(u) # L2 norm (Euclidean norm) by default\n",
    "x2 = torch.abs(u).sum() # L1 norm (Manhattan norm)\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d238cf2",
   "metadata": {},
   "source": [
    "=================================Calculus===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04f3da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib_inline import backend_inline\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9c7b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3 * x ** 2 - 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e99be6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=0.10000, numerical limit=2.30000\n",
      "h=0.01000, numerical limit=2.03000\n",
      "h=0.00100, numerical limit=2.00300\n",
      "h=0.00010, numerical limit=2.00030\n",
      "h=0.00001, numerical limit=2.00003\n"
     ]
    }
   ],
   "source": [
    "for h in 10.0**np.arange(-1, -6, -1):\n",
    "    print(f'h={h:.5f}, numerical limit={(f(1+h)-f(1))/h:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67c2ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_svg_display tells matplotlib to output graphics in SVG format for crisper images. The comment #@save is a special \n",
    "# modifier that allows us to save any function, class, or other code block to the d2l package so that we can invoke it \n",
    "# later without repeating the code, e.g., via d2l.use_svg_display().\n",
    "\n",
    "def use_svg_display():  #@save\n",
    "    \"\"\"Use the svg format to display a plot in Jupyter.\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conveniently, we can set figure sizes with set_figsize. Since the import statement from matplotlib import pyplot as plt was\n",
    "# marked via #@save in the d2l package, we can call d2l.plt.\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):  #@save\n",
    "    \"\"\"Set the figure size for matplotlib.\"\"\"\n",
    "    use_svg_display()\n",
    "    d2l.plt.rcParams['figure.figsize'] = figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83e72e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"Set the axes for matplotlib.\"\"\"\n",
    "    axes.set_xlabel(xlabel), axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale), axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim),     axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51facaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def plot(X, Y=None, xlabel=None, ylabel=None, legend=[], xlim=None,\n",
    "         ylim=None, xscale='linear', yscale='linear',\n",
    "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
    "    \"\"\"Plot data points.\"\"\"\n",
    "\n",
    "    def has_one_axis(X):  # True if X (tensor or list) has 1 axis\n",
    "        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n",
    "                and not hasattr(X[0], \"__len__\"))\n",
    "\n",
    "    if has_one_axis(X): X = [X]\n",
    "    if Y is None:\n",
    "        X, Y = [[]] * len(X), X\n",
    "    elif has_one_axis(Y):\n",
    "        Y = [Y]\n",
    "    if len(X) != len(Y):\n",
    "        X = X * len(Y)\n",
    "\n",
    "    set_figsize(figsize)\n",
    "    if axes is None:\n",
    "        axes = d2l.plt.gca()\n",
    "    axes.cla()\n",
    "    for x, y, fmt in zip(X, Y, fmts):\n",
    "        axes.plot(x,y,fmt) if len(x) else axes.plot(y,fmt)\n",
    "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5dd4a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"243.529359pt\" height=\"183.35625pt\" viewBox=\"0 0 243.529359 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-11-16T20:43:05.661408</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 243.529359 183.35625 \n",
       "L 243.529359 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "L 40.603125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 49.480398 145.8 \n",
       "L 49.480398 7.2 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m2f96c64c51\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f96c64c51\" x=\"49.480398\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(46.299148 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 110.702968 145.8 \n",
       "L 110.702968 7.2 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f96c64c51\" x=\"110.702968\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(107.521718 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 171.925539 145.8 \n",
       "L 171.925539 7.2 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f96c64c51\" x=\"171.925539\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(168.744289 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 233.148109 145.8 \n",
       "L 233.148109 7.2 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f96c64c51\" x=\"233.148109\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 3 -->\n",
       "      <g transform=\"translate(229.966859 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_5\">\n",
       "     <!-- x -->\n",
       "     <g transform=\"translate(135.29375 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-78\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 40.603125 116.769994 \n",
       "L 235.903125 116.769994 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <defs>\n",
       "       <path id=\"me7d042f7dc\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#me7d042f7dc\" x=\"40.603125\" y=\"116.769994\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(27.240625 120.569213) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 40.603125 78.886651 \n",
       "L 235.903125 78.886651 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#me7d042f7dc\" x=\"40.603125\" y=\"78.886651\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(27.240625 82.685869) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 40.603125 41.003307 \n",
       "L 235.903125 41.003307 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#me7d042f7dc\" x=\"40.603125\" y=\"41.003307\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(20.878125 44.802526) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- f(x) -->\n",
       "     <g transform=\"translate(14.798437 85.121094) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \n",
       "L 2375 4384 \n",
       "L 1825 4384 \n",
       "Q 1516 4384 1395 4259 \n",
       "Q 1275 4134 1275 3809 \n",
       "L 1275 3500 \n",
       "L 2222 3500 \n",
       "L 2222 3053 \n",
       "L 1275 3053 \n",
       "L 1275 0 \n",
       "L 697 0 \n",
       "L 697 3053 \n",
       "L 147 3053 \n",
       "L 147 3500 \n",
       "L 697 3500 \n",
       "L 697 3744 \n",
       "Q 697 4328 969 4595 \n",
       "Q 1241 4863 1831 4863 \n",
       "L 2375 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" x=\"35.205078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"74.21875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" x=\"133.398438\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 49.480398 116.769994 \n",
       "L 55.602655 119.573361 \n",
       "L 61.724912 121.922129 \n",
       "L 67.847169 123.816296 \n",
       "L 73.969426 125.255863 \n",
       "L 80.091683 126.24083 \n",
       "L 86.21394 126.771197 \n",
       "L 92.336197 126.846963 \n",
       "L 98.458454 126.46813 \n",
       "L 104.580711 125.634696 \n",
       "L 110.702968 124.346663 \n",
       "L 116.825225 122.604029 \n",
       "L 122.947482 120.406795 \n",
       "L 129.069739 117.754961 \n",
       "L 135.191996 114.648527 \n",
       "L 141.314254 111.087492 \n",
       "L 147.436511 107.071858 \n",
       "L 153.558768 102.601624 \n",
       "L 159.681025 97.676789 \n",
       "L 165.803282 92.297354 \n",
       "L 171.925539 86.463319 \n",
       "L 178.047796 80.174684 \n",
       "L 184.170053 73.431449 \n",
       "L 190.29231 66.233614 \n",
       "L 196.414567 58.581179 \n",
       "L 202.536824 50.474143 \n",
       "L 208.659081 41.912508 \n",
       "L 214.781338 32.896272 \n",
       "L 220.903595 23.425436 \n",
       "L 227.025852 13.5 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 49.480398 139.5 \n",
       "L 55.602655 137.984666 \n",
       "L 61.724912 136.469333 \n",
       "L 67.847169 134.953999 \n",
       "L 73.969426 133.438665 \n",
       "L 80.091683 131.923331 \n",
       "L 86.21394 130.407998 \n",
       "L 92.336197 128.892664 \n",
       "L 98.458454 127.37733 \n",
       "L 104.580711 125.861996 \n",
       "L 110.702968 124.346663 \n",
       "L 116.825225 122.831329 \n",
       "L 122.947482 121.315995 \n",
       "L 129.069739 119.800661 \n",
       "L 135.191996 118.285328 \n",
       "L 141.314254 116.769994 \n",
       "L 147.436511 115.25466 \n",
       "L 153.558768 113.739327 \n",
       "L 159.681025 112.223993 \n",
       "L 165.803282 110.708659 \n",
       "L 171.925539 109.193325 \n",
       "L 178.047796 107.677992 \n",
       "L 184.170053 106.162658 \n",
       "L 190.29231 104.647324 \n",
       "L 196.414567 103.13199 \n",
       "L 202.536824 101.616657 \n",
       "L 208.659081 100.101323 \n",
       "L 214.781338 98.585989 \n",
       "L 220.903595 97.070655 \n",
       "L 227.025852 95.555322 \n",
       "\" clip-path=\"url(#p6baf37f6f4)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 40.603125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 235.903125 145.8 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 40.603125 145.8 \n",
       "L 235.903125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 40.603125 7.2 \n",
       "L 235.903125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 47.603125 44.55625 \n",
       "L 172.153125 44.55625 \n",
       "Q 174.153125 44.55625 174.153125 42.55625 \n",
       "L 174.153125 14.2 \n",
       "Q 174.153125 12.2 172.153125 12.2 \n",
       "L 47.603125 12.2 \n",
       "Q 45.603125 12.2 45.603125 14.2 \n",
       "L 45.603125 42.55625 \n",
       "Q 45.603125 44.55625 47.603125 44.55625 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 49.603125 20.298438 \n",
       "L 59.603125 20.298438 \n",
       "L 69.603125 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- f(x) -->\n",
       "     <g transform=\"translate(77.603125 23.798438) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" x=\"35.205078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"74.21875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" x=\"133.398438\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 49.603125 34.976562 \n",
       "L 59.603125 34.976562 \n",
       "L 69.603125 34.976562 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- Tangent line (x=1) -->\n",
       "     <g transform=\"translate(77.603125 38.476562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \n",
       "L 3928 4666 \n",
       "L 3928 4134 \n",
       "L 2272 4134 \n",
       "L 2272 0 \n",
       "L 1638 0 \n",
       "L 1638 4134 \n",
       "L -19 4134 \n",
       "L -19 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \n",
       "L 4684 2906 \n",
       "L 4684 2381 \n",
       "L 678 2381 \n",
       "L 678 2906 \n",
       "z\n",
       "M 678 1631 \n",
       "L 4684 1631 \n",
       "L 4684 1100 \n",
       "L 678 1100 \n",
       "L 678 1631 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"44.583984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"105.863281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" x=\"169.242188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"232.71875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"294.242188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"357.621094\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"396.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"428.617188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"456.400391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"484.183594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"547.5625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"609.085938\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" x=\"640.873047\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"679.886719\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" x=\"739.066406\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" x=\"822.855469\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" x=\"886.478516\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p6baf37f6f4\">\n",
       "   <rect x=\"40.603125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0, 3, 0.1)\n",
    "plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598dab87",
   "metadata": {},
   "source": [
    "===================================Automatic Differentiation===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "029c7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4.0)\n",
    "\n",
    "x.requires_grad_(True)\n",
    "x.grad # The gradient is None by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b33aa223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0095139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29355068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()  # Reset the gradient\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a58ec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14., grad_fn=<SumBackward0>), tensor([0., 2., 4., 6.]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward for Non-Scalar Variables\n",
    "x.grad.zero_()\n",
    "y = (x * x).sum()\n",
    "y.backward()\n",
    "y, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42a6e1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>), tensor([0., 2., 4., 6.]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward for Non-Scalar Variables\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "\n",
    "# ‚Ä¢\t.backward() works only if the tensor is a scalar.\n",
    "# ‚Ä¢\tIf y is a vector, PyTorch needs a vector of gradients of some scalar w.r.t. y (think chain rule) to compute ‚àÇL/‚àÇx.\n",
    "# ‚Ä¢\tHere we use gradient=torch.ones(len(y)) to sum all elements (equivalent to .sum()).\n",
    "\n",
    "y.backward(gradient=torch.ones(len(y)))  # Faster: y.sum().backward();  sum up the gradients of each component of y with respect to the full vector x,\n",
    "\n",
    "# y = x * x  # [0., 1., 4., 9.]\n",
    "# gradient = torch.ones(4)  # dL/dy = [1, 1, 1, 1]\n",
    "# The chain rule:\n",
    "\n",
    "# ‚àÇL/‚àÇx = ‚àÇL/‚àÇy * ‚àÇy/‚àÇx. (x.grad[i] = ‚àÇL/‚àÇy[i] * ‚àÇy[i]/‚àÇx[i]. (*: elementwise product)\n",
    "# \t‚Ä¢\t‚àÇy/‚àÇx = 2*x elementwise\n",
    "# \t‚Ä¢\t‚àÇL/‚àÇy = gradient = [1, 1, 1, 1]\n",
    "\n",
    "# Elementwise multiplication: x.grad = 2*x * 1 = [0, 2, 4, 6]\n",
    "\n",
    "y, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5fdfbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detaching Computation\n",
    "\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach() # detach() creates a new tensor with the same data as y, but removes it from the gradient computation graph\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea883afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a146b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç WHAT DOES y.detach() MEAN?\n",
      "======================================================================\n",
      "x = tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "x.requires_grad = True\n",
      "\n",
      "y = x * x = tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n",
      "y.requires_grad = True\n",
      "\n",
      "u = y.detach() = tensor([0., 1., 4., 9.])\n",
      "u.requires_grad = False\n",
      "\n",
      "==================================================\n",
      "üéØ KEY CONCEPTS:\n",
      "==================================================\n",
      "1Ô∏è‚É£ COMPUTATIONAL GRAPH:\n",
      "   ‚Ä¢ PyTorch builds a graph: x ‚Üí y = x¬≤ ‚Üí z = u * x\n",
      "   ‚Ä¢ Each operation tracks gradients for backpropagation\n",
      "\n",
      "2Ô∏è‚É£ WHAT .detach() DOES:\n",
      "   ‚Ä¢ Creates a NEW tensor with SAME DATA as y\n",
      "   ‚Ä¢ Removes the tensor from the computation graph\n",
      "   ‚Ä¢ Sets requires_grad = False\n",
      "   ‚Ä¢ u and y share the same data, but u has no gradient history\n",
      "\n",
      "3Ô∏è‚É£ WHY USE .detach():\n",
      "   ‚Ä¢ Stop gradient flow at a specific point\n",
      "   ‚Ä¢ Treat intermediate results as constants\n",
      "   ‚Ä¢ Prevent certain operations from affecting gradients\n",
      "\n",
      "4Ô∏è‚É£ THE RESULT:\n",
      "   ‚Ä¢ u is treated as a CONSTANT during backpropagation\n",
      "   ‚Ä¢ When we compute z = u * x, gradients flow only through x\n",
      "   ‚Ä¢ The gradient path x ‚Üí y is 'broken' at u\n"
     ]
    }
   ],
   "source": [
    "# üìö UNDERSTANDING .detach(): \"BREAKING THE COMPUTATION GRAPH\"\n",
    "print(\"=\"*70)\n",
    "print(\"üîç WHAT DOES y.detach() MEAN?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Let's create a step-by-step example\n",
    "x = torch.arange(4.0, requires_grad=True)\n",
    "print(f\"x = {x}\")\n",
    "print(f\"x.requires_grad = {x.requires_grad}\")\n",
    "\n",
    "y = x * x  # y = x¬≤\n",
    "print(f\"\\ny = x * x = {y}\")\n",
    "print(f\"y.requires_grad = {y.requires_grad}\")\n",
    "\n",
    "# Now detach y\n",
    "u = y.detach()\n",
    "print(f\"\\nu = y.detach() = {u}\")\n",
    "print(f\"u.requires_grad = {u.requires_grad}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéØ KEY CONCEPTS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"1Ô∏è‚É£ COMPUTATIONAL GRAPH:\")\n",
    "print(\"   ‚Ä¢ PyTorch builds a graph: x ‚Üí y = x¬≤ ‚Üí z = u * x\")\n",
    "print(\"   ‚Ä¢ Each operation tracks gradients for backpropagation\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ WHAT .detach() DOES:\")\n",
    "print(\"   ‚Ä¢ Creates a NEW tensor with SAME DATA as y\")\n",
    "print(\"   ‚Ä¢ Removes the tensor from the computation graph\")\n",
    "print(\"   ‚Ä¢ Sets requires_grad = False\")\n",
    "print(\"   ‚Ä¢ u and y share the same data, but u has no gradient history\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ WHY USE .detach():\")\n",
    "print(\"   ‚Ä¢ Stop gradient flow at a specific point\")\n",
    "print(\"   ‚Ä¢ Treat intermediate results as constants\")\n",
    "print(\"   ‚Ä¢ Prevent certain operations from affecting gradients\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ THE RESULT:\")\n",
    "print(\"   ‚Ä¢ u is treated as a CONSTANT during backpropagation\")\n",
    "print(\"   ‚Ä¢ When we compute z = u * x, gradients flow only through x\")\n",
    "print(\"   ‚Ä¢ The gradient path x ‚Üí y is 'broken' at u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3753ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî¨ COMPARISON: WITH vs WITHOUT .detach()\n",
      "============================================================\n",
      "WITHOUT .detach():\n",
      "x1 = tensor([0., 1., 2., 3.])\n",
      "y1 = x1¬≤ = tensor([0., 1., 4., 9.])\n",
      "z1 = y1 * x1 = x1¬≥ = tensor([ 0.,  1.,  8., 27.])\n",
      "x1.grad = tensor([ 0.,  3., 12., 27.])\n",
      "Gradient computation: dz/dx = d(x¬≥)/dx = 3x¬≤ = 3 * [0, 1, 4, 9]\n",
      "\n",
      "----------------------------------------\n",
      "WITH .detach():\n",
      "x2 = tensor([0., 1., 2., 3.])\n",
      "y2 = x2¬≤ = tensor([0., 1., 4., 9.])\n",
      "u2 = y2.detach() = tensor([0., 1., 4., 9.]) (same values, no gradients)\n",
      "z2 = u2 * x2 = tensor([ 0.,  1.,  8., 27.])\n",
      "x2.grad = tensor([0., 1., 4., 9.])\n",
      "Gradient computation: dz/dx = d(u*x)/dx = u = [0, 1, 4, 9]\n",
      "Note: u is treated as constant, so gradient is just u\n",
      "\n",
      "üéØ THE DIFFERENCE:\n",
      "‚Ä¢ Without detach: x.grad = 3x¬≤ (derivative of x¬≥)\n",
      "‚Ä¢ With detach:    x.grad = u = x¬≤ (u treated as constant)\n",
      "‚Ä¢ detach() 'freezes' the values but stops gradient flow\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî¨ COMPARISON: WITH vs WITHOUT .detach()\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example 1: WITHOUT detach (normal gradient flow)\n",
    "x1 = torch.arange(4.0, requires_grad=True)\n",
    "y1 = x1 * x1\n",
    "z1 = y1 * x1  # z = y * x = x¬≤ * x = x¬≥\n",
    "\n",
    "x1.grad = None  # Clear previous gradients\n",
    "z1.sum().backward()\n",
    "print(\"WITHOUT .detach():\")\n",
    "print(f\"x1 = {x1.data}\")\n",
    "print(f\"y1 = x1¬≤ = {y1.data}\")\n",
    "print(f\"z1 = y1 * x1 = x1¬≥ = {z1.data}\")\n",
    "print(f\"x1.grad = {x1.grad}\")\n",
    "print(\"Gradient computation: dz/dx = d(x¬≥)/dx = 3x¬≤ = 3 * [0, 1, 4, 9]\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "\n",
    "# Example 2: WITH detach (broken gradient flow)\n",
    "x2 = torch.arange(4.0, requires_grad=True)\n",
    "y2 = x2 * x2\n",
    "u2 = y2.detach()  # Detach here!\n",
    "z2 = u2 * x2      # z = u * x (u is treated as constant)\n",
    "\n",
    "x2.grad = None  # Clear previous gradients\n",
    "z2.sum().backward()\n",
    "print(\"WITH .detach():\")\n",
    "print(f\"x2 = {x2.data}\")\n",
    "print(f\"y2 = x2¬≤ = {y2.data}\")\n",
    "print(f\"u2 = y2.detach() = {u2.data} (same values, no gradients)\")\n",
    "print(f\"z2 = u2 * x2 = {z2.data}\")\n",
    "print(f\"x2.grad = {x2.grad}\")\n",
    "print(\"Gradient computation: dz/dx = d(u*x)/dx = u = [0, 1, 4, 9]\")\n",
    "print(\"Note: u is treated as constant, so gradient is just u\")\n",
    "\n",
    "print(\"\\nüéØ THE DIFFERENCE:\")\n",
    "print(\"‚Ä¢ Without detach: x.grad = 3x¬≤ (derivative of x¬≥)\")\n",
    "print(\"‚Ä¢ With detach:    x.grad = u = x¬≤ (u treated as constant)\")\n",
    "print(\"‚Ä¢ detach() 'freezes' the values but stops gradient flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One benefit of using automatic differentiation is that even if building the computational graph of (a function required passing through a maze of \n",
    "# Python control flow) (e.g., conditionals, loops, and arbitrary function calls), (we can still calculate the gradient of the resulting variable.)\n",
    "\n",
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "\n",
    "a.grad == d / a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b6719",
   "metadata": {},
   "source": [
    "=======================================Probability and Statistics===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b6f3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa77e28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads, tails:  [48, 52]\n"
     ]
    }
   ],
   "source": [
    "num_tosses = 100\n",
    "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
    "tails = num_tosses - heads\n",
    "print(\"heads, tails: \", [heads, tails])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "365dee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50040., 49960.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_probs = torch.tensor([0.5, 0.5])\n",
    "Multinomial(100000, fair_probs).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33474def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Multinomial(1, fair_probs).sample((10000,))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0f2270e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00],\n",
       "        [2.0000e+00, 0.0000e+00],\n",
       "        [3.0000e+00, 0.0000e+00],\n",
       "        ...,\n",
       "        [5.0430e+03, 4.9550e+03],\n",
       "        [5.0430e+03, 4.9560e+03],\n",
       "        [5.0430e+03, 4.9570e+03]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_counts = counts.cumsum(dim=0)\n",
    "cum_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5bc347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.5044009 , 0.49559912],\n",
       "       [0.5043504 , 0.49564958],\n",
       "       [0.5043    , 0.4957    ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
    "estimates = estimates.numpy()\n",
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9428dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"306.596693pt\" height=\"253.914375pt\" viewBox=\"0 0 306.596693 253.914375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-11-16T21:29:49.544937</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 253.914375 \n",
       "L 306.596693 253.914375 \n",
       "L 306.596693 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 216.358125 \n",
       "L 294.88125 216.358125 \n",
       "L 294.88125 22.318125 \n",
       "L 43.78125 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 55.194886 216.358125 \n",
       "L 55.194886 22.318125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m77b336e3c7\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b336e3c7\" x=\"55.194886\" y=\"216.358125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(52.013636 230.956562) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 100.853998 216.358125 \n",
       "L 100.853998 22.318125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b336e3c7\" x=\"100.853998\" y=\"216.358125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2000 -->\n",
       "      <g transform=\"translate(88.128998 230.956562) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 146.513109 216.358125 \n",
       "L 146.513109 22.318125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b336e3c7\" x=\"146.513109\" y=\"216.358125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 4000 -->\n",
       "      <g transform=\"translate(133.788109 230.956562) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 192.17222 216.358125 \n",
       "L 192.17222 22.318125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b336e3c7\" x=\"192.17222\" y=\"216.358125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 6000 -->\n",
       "      <g transform=\"translate(179.44722 230.956562) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 237.831332 216.358125 \n",
       "L 237.831332 22.318125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b336e3c7\" x=\"237.831332\" y=\"216.358125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 8000 -->\n",
       "      <g transform=\"translate(225.106332 230.956562) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 283.490443 216.358125 \n",
       "L 283.490443 22.318125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b336e3c7\" x=\"283.490443\" y=\"216.358125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 10000 -->\n",
       "      <g transform=\"translate(267.584193 230.956562) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Samples -->\n",
       "     <g transform=\"translate(147.978125 244.634687) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
       "L 3425 3897 \n",
       "Q 3066 4069 2747 4153 \n",
       "Q 2428 4238 2131 4238 \n",
       "Q 1616 4238 1336 4038 \n",
       "Q 1056 3838 1056 3469 \n",
       "Q 1056 3159 1242 3001 \n",
       "Q 1428 2844 1947 2747 \n",
       "L 2328 2669 \n",
       "Q 3034 2534 3370 2195 \n",
       "Q 3706 1856 3706 1288 \n",
       "Q 3706 609 3251 259 \n",
       "Q 2797 -91 1919 -91 \n",
       "Q 1588 -91 1214 -16 \n",
       "Q 841 59 441 206 \n",
       "L 441 856 \n",
       "Q 825 641 1194 531 \n",
       "Q 1563 422 1919 422 \n",
       "Q 2459 422 2753 634 \n",
       "Q 3047 847 3047 1241 \n",
       "Q 3047 1584 2836 1778 \n",
       "Q 2625 1972 2144 2069 \n",
       "L 1759 2144 \n",
       "Q 1053 2284 737 2584 \n",
       "Q 422 2884 422 3419 \n",
       "Q 422 4038 858 4394 \n",
       "Q 1294 4750 2059 4750 \n",
       "Q 2388 4750 2728 4690 \n",
       "Q 3069 4631 3425 4513 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"374.951172\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 43.78125 207.538125 \n",
       "L 294.88125 207.538125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path id=\"m0419859dfc\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0419859dfc\" x=\"43.78125\" y=\"207.538125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(20.878125 211.337344) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 43.78125 172.258125 \n",
       "L 294.88125 172.258125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0419859dfc\" x=\"43.78125\" y=\"172.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(20.878125 176.057344) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 43.78125 136.978125 \n",
       "L 294.88125 136.978125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0419859dfc\" x=\"43.78125\" y=\"136.978125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(20.878125 140.777344) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 43.78125 101.698125 \n",
       "L 294.88125 101.698125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0419859dfc\" x=\"43.78125\" y=\"101.698125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(20.878125 105.497344) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 43.78125 66.418125 \n",
       "L 294.88125 66.418125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0419859dfc\" x=\"43.78125\" y=\"66.418125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(20.878125 70.217344) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 43.78125 31.138125 \n",
       "L 294.88125 31.138125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #b0b0b0; stroke-opacity: 0.3; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0419859dfc\" x=\"43.78125\" y=\"31.138125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(20.878125 34.937344) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- Estimated probability -->\n",
       "     <g transform=\"translate(14.798438 172.861562) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \n",
       "L 3578 4666 \n",
       "L 3578 4134 \n",
       "L 1259 4134 \n",
       "L 1259 2753 \n",
       "L 3481 2753 \n",
       "L 3481 2222 \n",
       "L 1259 2222 \n",
       "L 1259 531 \n",
       "L 3634 531 \n",
       "L 3634 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"63.183594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"115.283203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"154.492188\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\" x=\"182.275391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"279.6875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"340.966797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"380.175781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"441.699219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"505.175781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"536.962891\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"600.439453\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"639.302734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"700.484375\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"763.960938\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"825.240234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"888.716797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"916.5\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"944.283203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"972.066406\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"1011.275391\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path d=\"M 55.194886 31.138125 \n",
       "L 55.240545 31.138125 \n",
       "L 55.331864 131.938124 \n",
       "L 55.377523 109.53812 \n",
       "L 55.423182 111.31994 \n",
       "L 55.491671 94.138127 \n",
       "L 55.5145 101.698121 \n",
       "L 55.582989 89.938121 \n",
       "L 55.605818 96.127603 \n",
       "L 55.628648 101.698121 \n",
       "L 55.674307 95.283581 \n",
       "L 55.719966 97.288125 \n",
       "L 55.742796 101.698121 \n",
       "L 55.788455 96.471461 \n",
       "L 55.834114 98.048474 \n",
       "L 55.971091 106.73812 \n",
       "L 55.993921 104.638129 \n",
       "L 56.03958 110.053918 \n",
       "L 56.222216 119.338125 \n",
       "L 56.267875 115.663129 \n",
       "L 56.336364 117.608708 \n",
       "L 56.404853 122.60479 \n",
       "L 56.450512 119.338125 \n",
       "L 56.54183 116.398128 \n",
       "L 56.56466 117.892225 \n",
       "L 56.587489 119.338125 \n",
       "L 56.633148 116.581875 \n",
       "L 56.747296 112.946822 \n",
       "L 56.792955 113.126858 \n",
       "L 56.929933 115.90176 \n",
       "L 56.952762 114.815048 \n",
       "L 56.998421 117.133127 \n",
       "L 57.06691 116.15017 \n",
       "L 57.181058 121.342669 \n",
       "L 57.203887 120.329136 \n",
       "L 57.249546 122.245817 \n",
       "L 57.272376 123.172907 \n",
       "L 57.340865 122.123389 \n",
       "L 57.363694 123.013127 \n",
       "L 57.660478 115.292249 \n",
       "L 57.728967 116.188127 \n",
       "L 57.751797 115.435474 \n",
       "L 57.797456 113.969429 \n",
       "L 57.843115 115.568889 \n",
       "L 58.002922 117.915546 \n",
       "L 58.025751 117.221321 \n",
       "L 58.07141 118.643637 \n",
       "L 58.254047 121.298125 \n",
       "L 58.368195 119.338125 \n",
       "L 58.391024 119.963655 \n",
       "L 58.61932 123.426868 \n",
       "L 58.687808 123.919945 \n",
       "L 58.756297 122.147041 \n",
       "L 58.801956 123.221146 \n",
       "L 58.847615 122.077258 \n",
       "L 58.961763 119.338125 \n",
       "L 59.030252 119.860016 \n",
       "L 59.075911 120.885493 \n",
       "L 59.12157 119.847951 \n",
       "L 59.144399 120.35192 \n",
       "L 59.372695 117.420734 \n",
       "L 59.395525 117.90786 \n",
       "L 59.441184 116.97984 \n",
       "L 59.464013 117.461529 \n",
       "L 59.600991 115.701011 \n",
       "L 59.64665 115.738127 \n",
       "L 59.669479 116.204119 \n",
       "L 59.715138 115.349183 \n",
       "L 59.783627 114.098523 \n",
       "L 59.852116 114.605447 \n",
       "L 59.874945 115.056571 \n",
       "L 59.920604 114.249665 \n",
       "L 60.080411 113.184634 \n",
       "L 60.103241 113.621459 \n",
       "L 60.1489 112.864727 \n",
       "L 60.240218 112.981372 \n",
       "L 60.308707 111.890129 \n",
       "L 60.422855 113.202476 \n",
       "L 60.445684 112.847221 \n",
       "L 60.491343 112.145846 \n",
       "L 60.537002 112.957704 \n",
       "L 60.582662 113.755842 \n",
       "L 60.65115 113.45812 \n",
       "L 60.67398 113.116543 \n",
       "L 60.719639 113.893684 \n",
       "L 60.765298 113.218122 \n",
       "L 60.810957 113.981846 \n",
       "L 60.856616 113.31644 \n",
       "L 61.107741 111.196587 \n",
       "L 61.244719 112.043384 \n",
       "L 61.358866 111.201592 \n",
       "L 61.290378 112.097827 \n",
       "L 61.381696 111.555775 \n",
       "L 61.632821 114.039895 \n",
       "L 61.769798 112.318753 \n",
       "L 61.815458 112.973181 \n",
       "L 61.838287 113.297031 \n",
       "L 61.883946 112.738125 \n",
       "L 62.043753 111.426502 \n",
       "L 62.066583 111.744748 \n",
       "L 62.135071 111.530257 \n",
       "L 62.18073 112.155719 \n",
       "L 62.20356 111.892673 \n",
       "L 62.272049 112.248097 \n",
       "L 62.294878 112.553505 \n",
       "L 62.340537 112.034941 \n",
       "L 62.431856 112.126805 \n",
       "L 62.523174 111.120737 \n",
       "L 62.660151 111.808853 \n",
       "L 62.751469 111.368243 \n",
       "L 62.70581 111.854485 \n",
       "L 62.774299 111.657048 \n",
       "L 62.842788 111.988121 \n",
       "L 62.865617 111.748218 \n",
       "L 62.956935 111.837242 \n",
       "L 63.071083 110.671074 \n",
       "L 63.139572 111.50374 \n",
       "L 63.185231 111.045813 \n",
       "L 63.23089 110.593079 \n",
       "L 63.276549 111.139253 \n",
       "L 63.299379 111.410037 \n",
       "L 63.345038 110.961593 \n",
       "L 63.367867 111.230601 \n",
       "L 63.390697 111.008129 \n",
       "L 63.459186 111.31994 \n",
       "L 63.482015 111.584279 \n",
       "L 63.527674 111.144678 \n",
       "L 63.550504 111.407335 \n",
       "L 63.573333 111.189217 \n",
       "L 63.618992 111.710019 \n",
       "L 63.641822 111.492837 \n",
       "L 63.915777 113.580948 \n",
       "L 63.938606 113.366246 \n",
       "L 64.007095 113.640448 \n",
       "L 64.075584 114.362735 \n",
       "L 64.144072 114.176297 \n",
       "L 64.23539 114.2283 \n",
       "L 64.28105 113.811809 \n",
       "L 64.326709 114.279273 \n",
       "L 64.395197 114.098523 \n",
       "L 64.509345 113.084338 \n",
       "L 64.600663 113.1449 \n",
       "L 64.669152 113.401585 \n",
       "L 64.691982 113.204316 \n",
       "L 64.828959 112.040251 \n",
       "L 64.897448 112.298692 \n",
       "L 64.965936 112.553505 \n",
       "L 64.988766 112.364174 \n",
       "L 65.080084 112.021998 \n",
       "L 65.034425 112.396453 \n",
       "L 65.125743 112.05556 \n",
       "L 65.239891 113.138129 \n",
       "L 65.28555 112.767922 \n",
       "L 65.354039 112.218846 \n",
       "L 65.422527 112.462851 \n",
       "L 65.627993 113.560834 \n",
       "L 65.696482 113.024459 \n",
       "L 65.742141 113.432728 \n",
       "L 65.81063 113.660015 \n",
       "L 65.833459 113.483312 \n",
       "L 65.901948 112.957704 \n",
       "L 65.947607 113.358466 \n",
       "L 66.153073 114.387192 \n",
       "L 66.175903 114.214474 \n",
       "L 66.221562 114.600105 \n",
       "L 66.449857 115.767272 \n",
       "L 66.678153 114.788121 \n",
       "L 66.792301 115.352663 \n",
       "L 66.81513 115.187537 \n",
       "L 66.952108 114.552076 \n",
       "L 66.860789 115.20375 \n",
       "L 66.997767 114.57056 \n",
       "L 67.066255 114.767303 \n",
       "L 67.089085 114.607087 \n",
       "L 67.111914 114.447491 \n",
       "L 67.157574 114.802126 \n",
       "L 67.248892 115.169884 \n",
       "L 67.271721 115.011329 \n",
       "L 67.294551 114.853383 \n",
       "L 67.34021 115.201163 \n",
       "L 67.36304 115.043744 \n",
       "L 67.431528 114.903484 \n",
       "L 67.568506 115.927078 \n",
       "L 67.614165 115.615919 \n",
       "L 67.682653 115.797248 \n",
       "L 67.819631 116.472422 \n",
       "L 67.84246 116.318661 \n",
       "L 67.86529 116.165468 \n",
       "L 67.910949 116.492966 \n",
       "L 67.956608 116.188127 \n",
       "L 67.979438 116.350961 \n",
       "L 68.025097 116.048245 \n",
       "L 68.184904 115.31497 \n",
       "L 68.207733 115.476479 \n",
       "L 68.276222 115.957633 \n",
       "L 68.321881 115.663129 \n",
       "L 68.34471 115.516633 \n",
       "L 68.39037 115.8345 \n",
       "L 68.458858 115.701011 \n",
       "L 68.504517 116.015524 \n",
       "L 68.687154 115.166508 \n",
       "L 68.709983 115.322277 \n",
       "L 68.778472 115.490474 \n",
       "L 68.801302 115.349183 \n",
       "L 68.86979 114.928129 \n",
       "L 68.915449 115.235797 \n",
       "L 68.983938 115.401923 \n",
       "L 69.006768 115.262882 \n",
       "L 69.098086 115.000425 \n",
       "L 69.052427 115.276288 \n",
       "L 69.120915 115.151873 \n",
       "L 69.212234 115.752763 \n",
       "L 69.257893 115.478477 \n",
       "L 69.37204 115.084108 \n",
       "L 69.4177 115.097745 \n",
       "L 69.623166 115.854709 \n",
       "L 69.645995 115.721094 \n",
       "L 69.691654 116.009826 \n",
       "L 69.714484 115.876589 \n",
       "L 69.760143 116.163481 \n",
       "L 69.805802 115.898185 \n",
       "L 69.874291 115.503343 \n",
       "L 69.965609 115.527011 \n",
       "L 70.056927 115.820948 \n",
       "L 70.079757 115.691265 \n",
       "L 70.102586 115.561981 \n",
       "L 70.148245 115.842397 \n",
       "L 70.171075 115.981963 \n",
       "L 70.216734 115.724469 \n",
       "L 70.239564 115.863583 \n",
       "L 70.285223 115.607613 \n",
       "L 70.376541 115.630019 \n",
       "L 70.513518 116.450626 \n",
       "L 70.559177 116.197474 \n",
       "L 70.582007 116.07146 \n",
       "L 70.627666 116.341666 \n",
       "L 70.696155 116.744005 \n",
       "L 70.764643 116.626266 \n",
       "L 70.810302 116.376668 \n",
       "L 70.901621 116.393859 \n",
       "L 70.92445 116.52595 \n",
       "L 70.970109 116.279169 \n",
       "L 71.038598 115.911654 \n",
       "L 71.084257 116.174563 \n",
       "L 71.152746 116.566125 \n",
       "L 71.198405 116.322741 \n",
       "L 71.518019 115.149854 \n",
       "L 71.563678 115.407201 \n",
       "L 71.609337 115.173122 \n",
       "L 71.700655 114.708844 \n",
       "L 71.769144 114.849262 \n",
       "L 71.791973 114.976589 \n",
       "L 71.837632 114.746895 \n",
       "L 71.860462 114.873834 \n",
       "L 71.883292 114.759438 \n",
       "L 71.928951 115.012243 \n",
       "L 72.020269 115.274711 \n",
       "L 72.043098 115.160862 \n",
       "L 72.065928 115.047319 \n",
       "L 72.134417 115.183342 \n",
       "L 72.157246 115.070387 \n",
       "L 72.225735 115.44174 \n",
       "L 72.271394 115.21663 \n",
       "L 72.431201 114.671455 \n",
       "L 72.45403 114.794135 \n",
       "L 72.522519 114.696016 \n",
       "L 72.591008 115.061061 \n",
       "L 72.613837 114.951219 \n",
       "L 72.682326 115.083362 \n",
       "L 72.705156 114.974066 \n",
       "L 72.750815 115.214485 \n",
       "L 72.796474 114.996672 \n",
       "L 72.910622 114.457048 \n",
       "L 73.00194 114.482041 \n",
       "L 73.161747 114.860964 \n",
       "L 73.298724 114.450466 \n",
       "L 73.344383 114.462747 \n",
       "L 73.549849 115.284216 \n",
       "L 73.572679 115.179809 \n",
       "L 73.663997 114.76479 \n",
       "L 73.709656 114.993297 \n",
       "L 73.846633 115.240813 \n",
       "L 73.915122 114.933491 \n",
       "L 73.960781 115.158539 \n",
       "L 74.074929 115.290303 \n",
       "L 74.143418 115.198777 \n",
       "L 74.166247 115.309755 \n",
       "L 74.326054 115.658744 \n",
       "L 74.463031 115.476111 \n",
       "L 74.55435 115.702084 \n",
       "L 74.577179 115.602598 \n",
       "L 74.668497 115.413531 \n",
       "L 74.691327 115.521281 \n",
       "L 74.714156 115.628778 \n",
       "L 74.759816 115.431836 \n",
       "L 74.828304 115.13812 \n",
       "L 74.873963 115.352264 \n",
       "L 74.988111 115.476837 \n",
       "L 75.03377 115.282954 \n",
       "L 75.102259 115.397917 \n",
       "L 75.170748 115.713471 \n",
       "L 75.239236 115.625498 \n",
       "L 75.284895 115.433697 \n",
       "L 75.353384 115.546725 \n",
       "L 75.467532 115.865686 \n",
       "L 75.490361 115.77049 \n",
       "L 75.604509 115.691864 \n",
       "L 75.627339 115.794378 \n",
       "L 75.672998 115.605826 \n",
       "L 75.695827 115.708087 \n",
       "L 75.764316 115.817951 \n",
       "L 75.992612 114.889437 \n",
       "L 76.175248 115.311605 \n",
       "L 76.380714 114.875905 \n",
       "L 76.449203 115.174173 \n",
       "L 76.517691 115.093203 \n",
       "L 76.677498 114.843857 \n",
       "L 76.860135 115.253072 \n",
       "L 76.882964 115.164626 \n",
       "L 76.928623 115.358478 \n",
       "L 76.951453 115.2702 \n",
       "L 77.042771 115.471317 \n",
       "L 77.065601 115.383376 \n",
       "L 77.08843 115.295624 \n",
       "L 77.134089 115.487393 \n",
       "L 77.156919 115.399809 \n",
       "L 77.339555 115.795587 \n",
       "L 77.408044 115.715952 \n",
       "L 77.430874 115.810128 \n",
       "L 77.476533 115.997903 \n",
       "L 77.545021 115.91812 \n",
       "L 77.818976 115.070387 \n",
       "L 77.841806 115.163501 \n",
       "L 78.024442 115.549312 \n",
       "L 78.047272 115.465071 \n",
       "L 78.092931 115.648482 \n",
       "L 78.11576 115.564389 \n",
       "L 78.252738 115.761269 \n",
       "L 78.412544 115.179378 \n",
       "L 78.458204 115.360476 \n",
       "L 78.526692 115.458363 \n",
       "L 78.549522 115.376016 \n",
       "L 78.61801 115.12995 \n",
       "L 78.686499 115.227838 \n",
       "L 78.732158 115.406728 \n",
       "L 78.777817 115.243736 \n",
       "L 78.800647 115.162471 \n",
       "L 78.846306 115.340635 \n",
       "L 78.869136 115.259507 \n",
       "L 78.891965 115.348332 \n",
       "L 78.937624 115.186538 \n",
       "L 78.960454 115.275173 \n",
       "L 79.234408 114.651972 \n",
       "L 79.348556 114.757388 \n",
       "L 79.371386 114.6785 \n",
       "L 79.417045 114.853383 \n",
       "L 79.439874 114.774621 \n",
       "L 79.554022 114.878576 \n",
       "L 79.66817 114.817151 \n",
       "L 79.713829 114.989659 \n",
       "L 79.759488 114.833942 \n",
       "L 79.827977 114.601462 \n",
       "L 79.896466 114.696016 \n",
       "L 79.987784 114.875379 \n",
       "L 80.010613 114.798415 \n",
       "L 80.079102 114.89175 \n",
       "L 80.17042 114.585795 \n",
       "L 80.353057 114.940115 \n",
       "L 80.512864 114.729473 \n",
       "L 80.672671 114.995242 \n",
       "L 80.6955 114.920233 \n",
       "L 80.741159 115.085622 \n",
       "L 80.809648 115.018447 \n",
       "L 80.855307 115.182921 \n",
       "L 80.923796 115.272166 \n",
       "L 81.106432 114.679677 \n",
       "L 81.289069 115.020644 \n",
       "L 81.357557 115.108827 \n",
       "L 81.471705 114.744371 \n",
       "L 81.563023 114.912863 \n",
       "L 81.585853 114.840461 \n",
       "L 81.608682 114.768176 \n",
       "L 81.654341 114.928129 \n",
       "L 81.814148 115.181313 \n",
       "L 81.882637 115.267351 \n",
       "L 81.928296 115.123789 \n",
       "L 81.996785 115.35974 \n",
       "L 82.042444 115.21663 \n",
       "L 82.24791 114.876063 \n",
       "L 82.270739 114.954131 \n",
       "L 82.316399 114.813145 \n",
       "L 82.384887 114.750543 \n",
       "L 82.407717 114.828317 \n",
       "L 82.430546 114.905965 \n",
       "L 82.476205 114.765884 \n",
       "L 82.499035 114.843384 \n",
       "L 82.544694 114.703765 \n",
       "L 82.613183 114.78871 \n",
       "L 82.681671 114.726834 \n",
       "L 82.727331 114.880626 \n",
       "L 82.795819 114.964572 \n",
       "L 82.841478 114.826246 \n",
       "L 82.932797 114.986147 \n",
       "L 82.955626 114.917257 \n",
       "L 83.115433 114.726361 \n",
       "L 83.389388 115.342013 \n",
       "L 83.435047 115.205979 \n",
       "L 83.480706 115.354903 \n",
       "L 83.503535 115.429176 \n",
       "L 83.549195 115.293552 \n",
       "L 83.617683 115.090932 \n",
       "L 83.686172 115.171755 \n",
       "L 83.823149 115.332224 \n",
       "L 83.868808 115.198272 \n",
       "L 83.914467 115.344957 \n",
       "L 84.074274 115.715374 \n",
       "L 84.097104 115.648619 \n",
       "L 84.30257 115.329038 \n",
       "L 84.439547 115.485395 \n",
       "L 84.462377 115.41965 \n",
       "L 84.508036 115.563033 \n",
       "L 84.599354 115.711589 \n",
       "L 84.622184 115.646032 \n",
       "L 84.690672 115.449962 \n",
       "L 84.736331 115.592178 \n",
       "L 84.80482 115.532888 \n",
       "L 84.850479 115.674431 \n",
       "L 84.918968 115.750555 \n",
       "L 85.010286 115.491609 \n",
       "L 85.215752 115.853016 \n",
       "L 85.238582 115.78869 \n",
       "L 85.284241 115.927814 \n",
       "L 85.30707 115.997219 \n",
       "L 85.352729 115.86884 \n",
       "L 85.581025 115.365154 \n",
       "L 85.603855 115.434296 \n",
       "L 85.649514 115.572285 \n",
       "L 85.695173 115.445978 \n",
       "L 85.85498 115.26938 \n",
       "L 86.060446 115.622386 \n",
       "L 86.106105 115.497687 \n",
       "L 86.151764 115.633331 \n",
       "L 86.174593 115.701011 \n",
       "L 86.220253 115.576659 \n",
       "L 86.243082 115.514615 \n",
       "L 86.288741 115.649639 \n",
       "L 86.311571 115.587689 \n",
       "L 86.402889 115.727602 \n",
       "L 86.425719 115.66581 \n",
       "L 86.608355 115.430932 \n",
       "L 86.790991 115.835594 \n",
       "L 86.813821 115.774485 \n",
       "L 86.836651 115.713471 \n",
       "L 86.88231 115.845688 \n",
       "L 86.905139 115.784747 \n",
       "L 87.087776 116.057434 \n",
       "L 87.316071 115.704891 \n",
       "L 87.338901 115.770059 \n",
       "L 87.38456 115.650101 \n",
       "L 87.544367 115.481705 \n",
       "L 87.658515 115.681203 \n",
       "L 87.681344 115.621828 \n",
       "L 87.749833 115.567838 \n",
       "L 87.772662 115.632238 \n",
       "L 87.841151 115.701642 \n",
       "L 87.863981 115.642594 \n",
       "L 87.90964 115.52474 \n",
       "L 87.955299 115.652888 \n",
       "L 88.023787 115.599275 \n",
       "L 88.137935 115.917626 \n",
       "L 88.229253 115.683432 \n",
       "L 88.297742 115.751774 \n",
       "L 88.343401 115.878114 \n",
       "L 88.38906 115.761626 \n",
       "L 88.640185 115.246995 \n",
       "L 88.663015 115.309902 \n",
       "L 88.731504 115.498128 \n",
       "L 88.777163 115.383502 \n",
       "L 88.845651 115.212161 \n",
       "L 88.91414 115.28021 \n",
       "L 88.93697 115.342591 \n",
       "L 88.982629 115.228879 \n",
       "L 89.005458 115.291166 \n",
       "L 89.051117 115.177748 \n",
       "L 89.096777 115.302058 \n",
       "L 89.142436 115.426032 \n",
       "L 89.210924 115.374743 \n",
       "L 89.302243 115.267351 \n",
       "L 89.325072 115.329038 \n",
       "L 89.484879 115.641122 \n",
       "L 89.507709 115.584934 \n",
       "L 89.530538 115.528819 \n",
       "L 89.576197 115.650932 \n",
       "L 89.599027 115.711862 \n",
       "L 89.644686 115.599843 \n",
       "L 89.667515 115.660689 \n",
       "L 89.713175 115.548965 \n",
       "L 89.781663 115.614647 \n",
       "L 89.872981 115.740492 \n",
       "L 89.895811 115.684872 \n",
       "L 90.078447 115.473241 \n",
       "L 90.146936 115.538387 \n",
       "L 90.169766 115.483335 \n",
       "L 90.192595 115.428345 \n",
       "L 90.238254 115.548281 \n",
       "L 90.46655 115.915103 \n",
       "L 90.672016 115.65131 \n",
       "L 90.786164 115.832745 \n",
       "L 90.808993 115.77848 \n",
       "L 90.831823 115.7243 \n",
       "L 90.877482 115.841703 \n",
       "L 91.014459 115.967422 \n",
       "L 91.082948 115.917784 \n",
       "L 91.105777 115.975991 \n",
       "L 91.128607 116.034124 \n",
       "L 91.174266 115.926458 \n",
       "L 91.197096 115.87273 \n",
       "L 91.242755 115.988755 \n",
       "L 91.334073 116.108576 \n",
       "L 91.356903 116.054974 \n",
       "L 91.379732 116.001425 \n",
       "L 91.425391 116.116714 \n",
       "L 91.448221 116.063238 \n",
       "L 91.516709 116.12481 \n",
       "L 91.539539 116.07146 \n",
       "L 91.608028 116.022338 \n",
       "L 91.630857 116.07964 \n",
       "L 91.653687 116.136869 \n",
       "L 91.699346 116.030623 \n",
       "L 91.790664 115.818918 \n",
       "L 91.859153 115.880374 \n",
       "L 91.881982 115.937382 \n",
       "L 91.927641 115.83204 \n",
       "L 91.950471 115.888964 \n",
       "L 91.973301 115.836393 \n",
       "L 92.01896 115.950021 \n",
       "L 92.041789 115.897502 \n",
       "L 92.224426 116.131844 \n",
       "L 92.315744 116.031306 \n",
       "L 92.338573 116.087516 \n",
       "L 92.452721 116.259497 \n",
       "L 92.475551 116.207399 \n",
       "L 92.544039 116.159265 \n",
       "L 92.566869 116.215043 \n",
       "L 92.681017 116.278234 \n",
       "L 92.703846 116.226451 \n",
       "L 92.749505 116.337397 \n",
       "L 92.932142 116.56521 \n",
       "L 92.977801 116.462033 \n",
       "L 93.04629 116.520409 \n",
       "L 93.114778 116.472422 \n",
       "L 93.160437 116.581875 \n",
       "L 93.183267 116.530555 \n",
       "L 93.228926 116.639745 \n",
       "L 93.365903 116.860303 \n",
       "L 93.388733 116.809088 \n",
       "L 93.411563 116.757947 \n",
       "L 93.457222 116.866212 \n",
       "L 93.480051 116.920245 \n",
       "L 93.52571 116.81812 \n",
       "L 93.594199 116.770206 \n",
       "L 93.617029 116.824113 \n",
       "L 93.639858 116.877946 \n",
       "L 93.685517 116.776294 \n",
       "L 93.799665 116.627486 \n",
       "L 93.822495 116.681182 \n",
       "L 93.845324 116.734815 \n",
       "L 93.890983 116.633879 \n",
       "L 93.959472 116.586743 \n",
       "L 93.982301 116.64024 \n",
       "L 94.210597 116.965498 \n",
       "L 94.393233 116.668512 \n",
       "L 94.416063 116.721368 \n",
       "L 94.438893 116.77417 \n",
       "L 94.484552 116.674705 \n",
       "L 94.644359 116.430428 \n",
       "L 94.667188 116.483094 \n",
       "L 94.826995 116.646937 \n",
       "L 95.055291 116.359414 \n",
       "L 95.07812 116.411576 \n",
       "L 95.123779 116.314129 \n",
       "L 95.146609 116.366228 \n",
       "L 95.215097 116.220447 \n",
       "L 95.260757 116.324454 \n",
       "L 95.397734 116.434833 \n",
       "L 95.58037 116.148971 \n",
       "L 95.6032 116.200575 \n",
       "L 95.717348 116.358394 \n",
       "L 95.740177 116.310439 \n",
       "L 95.763007 116.262536 \n",
       "L 95.808666 116.365092 \n",
       "L 95.831495 116.317242 \n",
       "L 96.014132 116.527947 \n",
       "L 96.173939 116.19514 \n",
       "L 96.219598 116.296749 \n",
       "L 96.379405 116.552866 \n",
       "L 96.402234 116.505563 \n",
       "L 96.493553 116.414372 \n",
       "L 96.516382 116.464683 \n",
       "L 96.539212 116.514941 \n",
       "L 96.584871 116.420818 \n",
       "L 96.790337 116.096547 \n",
       "L 96.813166 116.146679 \n",
       "L 97.13278 116.746833 \n",
       "L 97.15561 116.700276 \n",
       "L 97.201269 116.60733 \n",
       "L 97.246928 116.706006 \n",
       "L 97.315417 116.662498 \n",
       "L 97.429564 116.907975 \n",
       "L 97.543712 116.867001 \n",
       "L 97.726349 117.066877 \n",
       "L 97.908985 116.793895 \n",
       "L 97.931815 116.842345 \n",
       "L 98.000303 116.79932 \n",
       "L 98.091621 116.992383 \n",
       "L 98.18294 116.903727 \n",
       "L 98.205769 116.951809 \n",
       "L 98.251428 117.047825 \n",
       "L 98.297087 116.956866 \n",
       "L 98.502553 116.735804 \n",
       "L 98.68519 117.024378 \n",
       "L 98.708019 116.979346 \n",
       "L 98.730849 116.934355 \n",
       "L 98.776508 117.029225 \n",
       "L 98.890656 117.173428 \n",
       "L 98.913485 117.128522 \n",
       "L 99.073292 116.998965 \n",
       "L 99.278758 117.238122 \n",
       "L 99.529883 116.932263 \n",
       "L 99.644031 117.074268 \n",
       "L 99.666861 117.030171 \n",
       "L 99.963645 116.640881 \n",
       "L 100.009304 116.733438 \n",
       "L 100.054963 116.646369 \n",
       "L 100.123452 116.516087 \n",
       "L 100.169111 116.608445 \n",
       "L 100.306088 116.705954 \n",
       "L 100.420236 116.579089 \n",
       "L 100.443066 116.624962 \n",
       "L 100.465895 116.670784 \n",
       "L 100.511554 116.584651 \n",
       "L 100.534384 116.63043 \n",
       "L 100.694191 116.507234 \n",
       "L 100.71702 116.552866 \n",
       "L 100.76268 116.467322 \n",
       "L 100.785509 116.512901 \n",
       "L 100.876827 116.430428 \n",
       "L 100.899657 116.475923 \n",
       "L 101.036634 116.572275 \n",
       "L 101.105123 116.620231 \n",
       "L 101.196441 116.450626 \n",
       "L 101.219271 116.495784 \n",
       "L 101.26493 116.411229 \n",
       "L 101.310589 116.326841 \n",
       "L 101.356248 116.417022 \n",
       "L 101.424737 116.377814 \n",
       "L 101.493225 116.512597 \n",
       "L 101.675862 116.263903 \n",
       "L 101.698691 116.308683 \n",
       "L 101.76718 116.442782 \n",
       "L 101.835669 116.403879 \n",
       "L 101.881328 116.320533 \n",
       "L 101.926987 116.409609 \n",
       "L 101.995476 116.542899 \n",
       "L 102.041135 116.459699 \n",
       "L 102.246601 116.087305 \n",
       "L 102.29226 116.175919 \n",
       "L 102.383578 116.26733 \n",
       "L 102.406408 116.226188 \n",
       "L 102.429237 116.185077 \n",
       "L 102.474896 116.27326 \n",
       "L 102.497726 116.317284 \n",
       "L 102.543385 116.235188 \n",
       "L 102.566214 116.279169 \n",
       "L 102.703192 116.203257 \n",
       "L 102.79451 116.378393 \n",
       "L 102.862999 116.340426 \n",
       "L 102.931487 116.302564 \n",
       "L 102.954317 116.346156 \n",
       "L 103.159783 116.568764 \n",
       "L 103.228272 116.614606 \n",
       "L 103.273931 116.533478 \n",
       "L 103.410908 116.62492 \n",
       "L 103.433738 116.584483 \n",
       "L 103.479397 116.670447 \n",
       "L 103.570715 116.758693 \n",
       "L 103.593544 116.718319 \n",
       "L 103.730522 116.559848 \n",
       "L 103.753351 116.602599 \n",
       "L 103.79901 116.687985 \n",
       "L 103.867499 116.650365 \n",
       "L 103.890329 116.610295 \n",
       "L 103.935988 116.695429 \n",
       "L 103.958817 116.737938 \n",
       "L 104.004476 116.657904 \n",
       "L 104.027306 116.617939 \n",
       "L 104.072965 116.702831 \n",
       "L 104.095795 116.662908 \n",
       "L 104.255602 116.876726 \n",
       "L 104.278431 116.836867 \n",
       "L 104.34692 116.717509 \n",
       "L 104.392579 116.80176 \n",
       "L 104.461068 116.927847 \n",
       "L 104.506727 116.848443 \n",
       "L 104.712193 116.655548 \n",
       "L 104.803511 116.822757 \n",
       "L 104.84917 116.744005 \n",
       "L 104.940488 116.66785 \n",
       "L 104.963318 116.709518 \n",
       "L 105.054636 116.714323 \n",
       "L 105.237272 116.563023 \n",
       "L 105.328591 116.56807 \n",
       "L 105.35142 116.529209 \n",
       "L 105.397079 116.611946 \n",
       "L 105.488398 116.696922 \n",
       "L 105.511227 116.658124 \n",
       "L 105.625375 116.624279 \n",
       "L 105.648204 116.6654 \n",
       "L 105.693864 116.588099 \n",
       "L 105.716693 116.549512 \n",
       "L 105.762352 116.631628 \n",
       "L 105.967818 116.840778 \n",
       "L 106.036307 116.804556 \n",
       "L 106.059136 116.845257 \n",
       "L 106.150455 116.928719 \n",
       "L 106.173284 116.890321 \n",
       "L 106.424409 116.627297 \n",
       "L 106.538557 116.672529 \n",
       "L 106.607046 116.715227 \n",
       "L 106.652705 116.639325 \n",
       "L 106.766853 116.684315 \n",
       "L 106.835341 116.648861 \n",
       "L 106.858171 116.689005 \n",
       "L 107.109296 116.973205 \n",
       "L 107.132126 116.935491 \n",
       "L 107.177785 117.015031 \n",
       "L 107.200614 116.977348 \n",
       "L 107.269103 117.01911 \n",
       "L 107.291932 116.98149 \n",
       "L 107.314762 116.943902 \n",
       "L 107.360421 117.023169 \n",
       "L 107.451739 117.027206 \n",
       "L 107.680035 116.807164 \n",
       "L 107.794183 116.927458 \n",
       "L 107.817012 116.890248 \n",
       "L 107.90833 116.894485 \n",
       "L 108.182285 117.210996 \n",
       "L 108.205115 117.173943 \n",
       "L 108.250774 117.251675 \n",
       "L 108.43341 117.410052 \n",
       "L 108.593217 117.302743 \n",
       "L 108.775854 117.459931 \n",
       "L 108.821513 117.386468 \n",
       "L 108.867172 117.463128 \n",
       "L 108.95849 117.466313 \n",
       "L 108.98132 117.429682 \n",
       "L 109.026979 117.506078 \n",
       "L 109.163956 117.585314 \n",
       "L 109.278104 117.551794 \n",
       "L 109.437911 117.668377 \n",
       "L 109.620547 117.526045 \n",
       "L 109.711865 117.602925 \n",
       "L 109.734695 117.566746 \n",
       "L 109.826013 117.5697 \n",
       "L 110.00865 117.722472 \n",
       "L 110.259775 117.473968 \n",
       "L 110.396752 117.624437 \n",
       "L 110.419582 117.588699 \n",
       "L 110.533729 117.555937 \n",
       "L 110.602218 117.594472 \n",
       "L 110.625048 117.55887 \n",
       "L 110.762025 117.490812 \n",
       "L 111.01315 117.751534 \n",
       "L 111.03598 117.716143 \n",
       "L 111.081639 117.78949 \n",
       "L 111.218616 117.86513 \n",
       "L 111.309934 117.72405 \n",
       "L 111.355593 117.797039 \n",
       "L 111.446912 117.799542 \n",
       "L 111.5154 117.765675 \n",
       "L 111.53823 117.802034 \n",
       "L 111.675207 117.877032 \n",
       "L 111.766525 117.879387 \n",
       "L 111.857844 117.952787 \n",
       "L 111.880673 117.917838 \n",
       "L 112.01765 117.85041 \n",
       "L 112.04048 117.886421 \n",
       "L 112.086139 117.816827 \n",
       "L 112.177457 117.819267 \n",
       "L 112.268776 117.962755 \n",
       "L 112.314435 117.893382 \n",
       "L 112.474242 117.721715 \n",
       "L 112.497071 117.757485 \n",
       "L 112.519901 117.793223 \n",
       "L 112.56556 117.724281 \n",
       "L 112.588389 117.689857 \n",
       "L 112.634048 117.761249 \n",
       "L 112.793855 117.87045 \n",
       "L 112.953662 117.769965 \n",
       "L 113.113469 117.878546 \n",
       "L 113.296106 117.744563 \n",
       "L 113.318935 117.779817 \n",
       "L 113.364594 117.711842 \n",
       "L 113.478742 117.680489 \n",
       "L 113.638549 117.788344 \n",
       "L 113.661378 117.75452 \n",
       "L 113.707038 117.824555 \n",
       "L 113.844015 117.965362 \n",
       "L 113.866844 117.93159 \n",
       "L 113.958163 117.796766 \n",
       "L 114.003822 117.866413 \n",
       "L 114.140799 117.93812 \n",
       "L 114.277776 117.805104 \n",
       "L 114.300606 117.839748 \n",
       "L 114.483242 117.980156 \n",
       "L 114.643049 117.814514 \n",
       "L 114.665879 117.848948 \n",
       "L 114.688708 117.883351 \n",
       "L 114.734368 117.816848 \n",
       "L 114.825686 117.819183 \n",
       "L 115.053981 118.026723 \n",
       "L 115.12247 117.994634 \n",
       "L 115.1453 118.028721 \n",
       "L 115.168129 118.062787 \n",
       "L 115.213788 117.996684 \n",
       "L 115.327936 117.898807 \n",
       "L 115.350766 117.93281 \n",
       "L 115.64755 118.239374 \n",
       "L 115.830186 118.109902 \n",
       "L 115.944334 118.211606 \n",
       "L 115.967164 118.178907 \n",
       "L 116.104141 118.115422 \n",
       "L 116.263948 118.217494 \n",
       "L 116.286777 118.184974 \n",
       "L 116.332436 118.251676 \n",
       "L 116.515073 118.386206 \n",
       "L 116.629221 118.35521 \n",
       "L 116.789028 118.4558 \n",
       "L 116.857516 118.424131 \n",
       "L 116.880346 118.457104 \n",
       "L 116.903175 118.490045 \n",
       "L 116.948834 118.425487 \n",
       "L 117.1543 118.201113 \n",
       "L 117.17713 118.234002 \n",
       "L 117.336937 118.334013 \n",
       "L 117.405426 118.302765 \n",
       "L 117.428255 118.335485 \n",
       "L 117.633721 118.49997 \n",
       "L 117.725039 118.50119 \n",
       "L 117.816358 118.50241 \n",
       "L 117.839187 118.470583 \n",
       "L 117.998994 118.376638 \n",
       "L 118.113142 118.346399 \n",
       "L 118.272949 118.25318 \n",
       "L 118.318608 118.317737 \n",
       "L 118.387096 118.223277 \n",
       "L 118.478415 118.161274 \n",
       "L 118.501244 118.193501 \n",
       "L 118.683881 118.260193 \n",
       "L 118.775199 118.261738 \n",
       "L 119.049154 118.455495 \n",
       "L 119.186131 118.39447 \n",
       "L 119.323108 118.459259 \n",
       "L 119.345938 118.4282 \n",
       "L 119.482915 118.367522 \n",
       "L 119.642722 118.526088 \n",
       "L 119.688381 118.464243 \n",
       "L 119.916677 118.280716 \n",
       "L 120.076484 118.438441 \n",
       "L 120.122143 118.377069 \n",
       "L 120.28195 118.224802 \n",
       "L 120.304779 118.256103 \n",
       "L 120.464586 118.28959 \n",
       "L 120.624393 118.199862 \n",
       "L 120.647223 118.231016 \n",
       "L 120.807029 118.264388 \n",
       "L 120.966836 118.175185 \n",
       "L 120.989666 118.206181 \n",
       "L 121.012495 118.237156 \n",
       "L 121.080984 118.146649 \n",
       "L 121.195132 118.118208 \n",
       "L 121.217961 118.14912 \n",
       "L 121.377768 118.243233 \n",
       "L 121.400598 118.213204 \n",
       "L 121.674553 118.036165 \n",
       "L 121.7887 118.068623 \n",
       "L 121.81153 118.038846 \n",
       "L 121.971337 118.011814 \n",
       "L 122.131144 118.105191 \n",
       "L 122.153973 118.075552 \n",
       "L 122.405098 117.930518 \n",
       "L 122.610564 118.024379 \n",
       "L 122.793201 117.96838 \n",
       "L 123.089985 118.181893 \n",
       "L 123.112815 118.152642 \n",
       "L 123.181303 118.242655 \n",
       "L 123.272621 118.303259 \n",
       "L 123.318281 118.244863 \n",
       "L 123.500917 118.188843 \n",
       "L 123.615065 118.220175 \n",
       "L 123.637894 118.191145 \n",
       "L 123.729213 118.075184 \n",
       "L 123.797701 118.164471 \n",
       "L 123.934679 118.166815 \n",
       "L 123.980338 118.109061 \n",
       "L 124.048826 118.19799 \n",
       "L 124.117315 118.286731 \n",
       "L 124.185804 118.200251 \n",
       "L 124.322781 118.202501 \n",
       "L 124.436929 118.1753 \n",
       "L 124.87069 117.806975 \n",
       "L 125.076156 117.897892 \n",
       "L 125.304452 117.787734 \n",
       "L 125.4186 117.876243 \n",
       "L 125.464259 117.819908 \n",
       "L 125.715384 117.682592 \n",
       "L 125.943679 117.801739 \n",
       "L 125.989339 117.745867 \n",
       "L 126.057827 117.83262 \n",
       "L 126.308952 117.979462 \n",
       "L 126.400271 117.924662 \n",
       "L 126.44593 117.982069 \n",
       "L 126.560077 118.068854 \n",
       "L 126.605737 118.013297 \n",
       "L 126.788373 117.904211 \n",
       "L 126.811203 117.932768 \n",
       "L 126.879691 117.962197 \n",
       "L 126.92535 117.906945 \n",
       "L 126.971009 117.851766 \n",
       "L 127.039498 117.937237 \n",
       "L 127.290623 118.081713 \n",
       "L 127.518919 117.974352 \n",
       "L 127.747214 118.200598 \n",
       "L 127.792873 118.145861 \n",
       "L 127.998339 118.066278 \n",
       "L 128.135317 118.179054 \n",
       "L 128.180976 118.124622 \n",
       "L 128.340783 118.099745 \n",
       "L 128.614737 118.268867 \n",
       "L 128.797374 118.216821 \n",
       "L 128.911522 118.245862 \n",
       "L 128.934351 118.218903 \n",
       "L 129.071329 118.220974 \n",
       "L 129.231135 118.304952 \n",
       "L 129.253965 118.278098 \n",
       "L 129.436601 118.226473 \n",
       "L 129.596408 118.255913 \n",
       "L 129.756215 118.231236 \n",
       "L 129.870363 118.259888 \n",
       "L 129.893193 118.233266 \n",
       "L 129.984511 118.234611 \n",
       "L 130.00734 118.261854 \n",
       "L 130.121488 118.344096 \n",
       "L 130.167147 118.290999 \n",
       "L 130.235636 118.265134 \n",
       "L 130.281295 118.319398 \n",
       "L 130.509591 118.429399 \n",
       "L 130.692227 118.378268 \n",
       "L 130.874863 118.540177 \n",
       "L 130.920523 118.48749 \n",
       "L 131.125989 118.410263 \n",
       "L 131.331455 118.492085 \n",
       "L 131.514091 118.441353 \n",
       "L 131.58258 118.468512 \n",
       "L 131.628239 118.416361 \n",
       "L 131.810875 118.366008 \n",
       "L 131.925023 118.341216 \n",
       "L 131.970682 118.28937 \n",
       "L 132.039171 118.368889 \n",
       "L 132.198978 118.449323 \n",
       "L 132.221807 118.423458 \n",
       "L 132.427273 118.295573 \n",
       "L 132.450103 118.321932 \n",
       "L 132.541421 118.323131 \n",
       "L 132.564251 118.297413 \n",
       "L 132.815376 118.171116 \n",
       "L 132.998012 118.225601 \n",
       "L 133.11216 118.253064 \n",
       "L 133.340455 118.359268 \n",
       "L 133.660069 118.158015 \n",
       "L 133.865535 118.289044 \n",
       "L 133.888365 118.263767 \n",
       "L 134.11666 118.164849 \n",
       "L 134.322126 118.244211 \n",
       "L 134.344956 118.219092 \n",
       "L 134.413445 118.296288 \n",
       "L 134.550422 118.298086 \n",
       "L 134.710229 118.224234 \n",
       "L 134.733058 118.249857 \n",
       "L 134.870036 118.30226 \n",
       "L 134.892865 118.277299 \n",
       "L 135.098331 118.204446 \n",
       "L 135.189649 118.306403 \n",
       "L 135.258138 118.231857 \n",
       "L 135.349456 118.233118 \n",
       "L 135.372286 118.258531 \n",
       "L 135.395115 118.283944 \n",
       "L 135.463604 118.209609 \n",
       "L 135.577752 118.236252 \n",
       "L 135.6919 118.212805 \n",
       "L 135.874536 118.165449 \n",
       "L 135.943025 118.191377 \n",
       "L 135.988684 118.142191 \n",
       "L 136.011513 118.117619 \n",
       "L 136.080002 118.193322 \n",
       "L 136.308298 118.295804 \n",
       "L 136.331127 118.271285 \n",
       "L 136.399616 118.346557 \n",
       "L 136.559423 118.422722 \n",
       "L 136.582252 118.398245 \n",
       "L 136.71923 118.350447 \n",
       "L 136.742059 118.375408 \n",
       "L 136.856207 118.401399 \n",
       "L 136.879037 118.377017 \n",
       "L 137.038843 118.30511 \n",
       "L 137.061673 118.329986 \n",
       "L 137.244309 118.381296 \n",
       "L 137.404116 118.309694 \n",
       "L 137.426946 118.334465 \n",
       "L 137.449775 118.359216 \n",
       "L 137.518264 118.286668 \n",
       "L 137.792219 118.143926 \n",
       "L 137.860707 118.169265 \n",
       "L 137.906367 118.121236 \n",
       "L 138.066173 118.099293 \n",
       "L 138.111833 118.148531 \n",
       "L 138.180321 118.07674 \n",
       "L 138.362958 118.031097 \n",
       "L 138.522765 118.057762 \n",
       "L 138.728231 117.892225 \n",
       "L 138.77389 117.941179 \n",
       "L 139.002185 118.041065 \n",
       "L 139.116333 118.066814 \n",
       "L 139.390288 118.214403 \n",
       "L 139.664242 118.027396 \n",
       "L 139.687072 118.051579 \n",
       "L 139.915368 118.197612 \n",
       "L 139.938197 118.174165 \n",
       "L 140.098004 118.152642 \n",
       "L 140.28064 118.202501 \n",
       "L 140.394788 118.1804 \n",
       "L 140.417618 118.20433 \n",
       "L 140.600254 118.253895 \n",
       "L 140.691572 118.255051 \n",
       "L 140.714402 118.278876 \n",
       "L 140.965527 118.399328 \n",
       "L 141.079675 118.33026 \n",
       "L 141.125334 118.377647 \n",
       "L 141.35363 118.473653 \n",
       "L 141.536266 118.382221 \n",
       "L 141.559096 118.405773 \n",
       "L 141.764562 118.477754 \n",
       "L 141.970028 118.410189 \n",
       "L 142.175494 118.528106 \n",
       "L 142.198323 118.505175 \n",
       "L 142.3353 118.460279 \n",
       "L 142.35813 118.48361 \n",
       "L 142.517937 118.508224 \n",
       "L 142.700573 118.463948 \n",
       "L 142.837551 118.511252 \n",
       "L 142.86038 118.488499 \n",
       "L 142.997358 118.443971 \n",
       "L 143.020187 118.467124 \n",
       "L 143.134335 118.44537 \n",
       "L 143.294142 118.424131 \n",
       "L 143.431119 118.471182 \n",
       "L 143.453949 118.448598 \n",
       "L 143.568096 118.472528 \n",
       "L 143.819222 118.588553 \n",
       "L 144.093176 118.45499 \n",
       "L 144.252983 118.479184 \n",
       "L 144.344301 118.525226 \n",
       "L 144.481279 118.526466 \n",
       "L 144.618256 118.527707 \n",
       "L 144.823722 118.596943 \n",
       "L 145.006358 118.553625 \n",
       "L 145.188995 118.599961 \n",
       "L 145.41729 118.512577 \n",
       "L 145.599927 118.558777 \n",
       "L 145.805393 118.493893 \n",
       "L 145.988029 118.539935 \n",
       "L 146.079348 118.585041 \n",
       "L 146.216325 118.586166 \n",
       "L 146.353302 118.587302 \n",
       "L 146.46745 118.566179 \n",
       "L 146.604427 118.567335 \n",
       "L 146.764234 118.590666 \n",
       "L 146.9697 118.52654 \n",
       "L 147.129507 118.549839 \n",
       "L 147.47195 118.35643 \n",
       "L 147.700246 118.445895 \n",
       "L 147.837223 118.44722 \n",
       "L 147.974201 118.448535 \n",
       "L 148.134008 118.4284 \n",
       "L 148.293814 118.451584 \n",
       "L 148.407962 118.474263 \n",
       "L 148.54494 118.475535 \n",
       "L 148.773235 118.391589 \n",
       "L 148.864553 118.349532 \n",
       "L 148.978701 118.372201 \n",
       "L 149.206997 118.460195 \n",
       "L 149.458122 118.355757 \n",
       "L 149.57227 118.335611 \n",
       "L 149.686417 118.358122 \n",
       "L 149.823395 118.359542 \n",
       "L 150.05169 118.277005 \n",
       "L 150.143008 118.235621 \n",
       "L 150.257156 118.258121 \n",
       "L 150.394134 118.259677 \n",
       "L 150.55394 118.240373 \n",
       "L 150.690918 118.24195 \n",
       "L 150.873554 118.201965 \n",
       "L 151.033361 118.224865 \n",
       "L 151.307316 118.102363 \n",
       "L 151.421464 118.082912 \n",
       "L 151.558441 118.084689 \n",
       "L 151.741077 118.128764 \n",
       "L 151.900884 118.109944 \n",
       "L 152.220498 118.27997 \n",
       "L 152.425964 118.220102 \n",
       "L 152.540112 118.200724 \n",
       "L 152.63143 118.243117 \n",
       "L 152.722748 118.202858 \n",
       "L 152.928214 118.143453 \n",
       "L 153.110851 118.186793 \n",
       "L 153.293487 118.1479 \n",
       "L 153.407635 118.128785 \n",
       "L 153.65876 118.029636 \n",
       "L 153.818567 118.052168 \n",
       "L 154.092522 117.933599 \n",
       "L 154.252328 117.956194 \n",
       "L 154.389306 117.958097 \n",
       "L 154.617601 118.042253 \n",
       "L 154.823067 117.984309 \n",
       "L 155.028533 118.047594 \n",
       "L 155.233999 117.989871 \n",
       "L 155.325318 117.950895 \n",
       "L 155.599272 117.834376 \n",
       "L 155.759079 117.856782 \n",
       "L 156.010204 117.760629 \n",
       "L 156.101522 117.722157 \n",
       "L 156.192841 117.763478 \n",
       "L 156.421136 117.846583 \n",
       "L 156.512454 117.887662 \n",
       "L 156.626602 117.869451 \n",
       "L 156.809239 117.832462 \n",
       "L 156.969046 117.854605 \n",
       "L 157.106023 117.856603 \n",
       "L 157.243 117.85859 \n",
       "L 157.402807 117.84121 \n",
       "L 157.539784 117.843208 \n",
       "L 157.653932 117.86452 \n",
       "L 157.882228 117.946216 \n",
       "L 158.019205 117.948066 \n",
       "L 158.201842 117.989619 \n",
       "L 158.430137 117.914599 \n",
       "L 158.704092 118.035061 \n",
       "L 158.978046 117.922117 \n",
       "L 159.115024 117.923978 \n",
       "L 159.29766 117.887788 \n",
       "L 159.457467 117.909311 \n",
       "L 159.685763 117.835374 \n",
       "L 159.799911 117.817763 \n",
       "L 159.936888 117.81975 \n",
       "L 160.34782 118.055427 \n",
       "L 160.461968 118.075941 \n",
       "L 160.827241 118.270886 \n",
       "L 160.964218 118.272263 \n",
       "L 161.078366 118.254399 \n",
       "L 161.283832 118.199567 \n",
       "L 161.489298 118.258584 \n",
       "L 161.694764 118.203962 \n",
       "L 161.831741 118.205424 \n",
       "L 162.128525 118.076782 \n",
       "L 162.333991 118.135567 \n",
       "L 162.539457 118.081608 \n",
       "L 162.722094 118.121184 \n",
       "L 162.90473 118.085866 \n",
       "L 163.224344 118.238649 \n",
       "L 163.384151 118.221668 \n",
       "L 163.475469 118.185426 \n",
       "L 163.635276 118.168561 \n",
       "L 163.772253 118.170033 \n",
       "L 164.069037 118.043788 \n",
       "L 164.228844 118.064144 \n",
       "L 164.43431 118.011257 \n",
       "L 164.708265 118.124874 \n",
       "L 164.890901 118.090188 \n",
       "L 165.096367 118.147469 \n",
       "L 165.210515 118.167005 \n",
       "L 165.530129 118.31636 \n",
       "L 165.781254 118.227661 \n",
       "L 165.918231 118.229039 \n",
       "L 166.146527 118.158741 \n",
       "L 166.283504 118.160191 \n",
       "L 166.466141 118.125936 \n",
       "L 166.603118 118.127429 \n",
       "L 166.740095 118.128922 \n",
       "L 166.899902 118.148668 \n",
       "L 167.082539 118.114623 \n",
       "L 167.219516 118.116116 \n",
       "L 167.310834 118.153031 \n",
       "L 167.424982 118.136293 \n",
       "L 167.676107 118.049487 \n",
       "L 167.881573 118.105433 \n",
       "L 168.087039 118.054176 \n",
       "L 168.360994 118.164019 \n",
       "L 168.452312 118.200524 \n",
       "L 168.634949 118.237839 \n",
       "L 168.726267 118.274198 \n",
       "L 168.886074 118.293397 \n",
       "L 169.09154 118.242255 \n",
       "L 169.205687 118.225695 \n",
       "L 169.479642 118.122666 \n",
       "L 169.753597 118.195866 \n",
       "L 169.890574 118.197233 \n",
       "L 170.141699 118.252265 \n",
       "L 170.301506 118.236283 \n",
       "L 170.438483 118.202648 \n",
       "L 170.62112 118.16957 \n",
       "L 170.758097 118.136114 \n",
       "L 170.895075 118.137533 \n",
       "L 171.12337 118.174628 \n",
       "L 171.351666 118.142254 \n",
       "L 171.534302 118.144126 \n",
       "L 171.716939 118.145997 \n",
       "L 172.059382 118.270076 \n",
       "L 172.333337 118.203826 \n",
       "L 172.515973 118.205592 \n",
       "L 172.858416 118.089126 \n",
       "L 173.223689 118.229438 \n",
       "L 173.520473 118.147154 \n",
       "L 173.771599 118.200608 \n",
       "L 173.999894 118.168908 \n",
       "L 174.273849 118.239217 \n",
       "L 174.456485 118.240899 \n",
       "L 174.684781 118.276689 \n",
       "L 174.867417 118.278309 \n",
       "L 175.141372 118.347871 \n",
       "L 175.278349 118.382526 \n",
       "L 175.438156 118.36706 \n",
       "L 175.575133 118.401609 \n",
       "L 175.73494 118.386143 \n",
       "L 176.100213 118.255819 \n",
       "L 176.374168 118.324719 \n",
       "L 176.579634 118.309841 \n",
       "L 176.7851 118.328136 \n",
       "L 177.013395 118.296982 \n",
       "L 177.241691 118.331921 \n",
       "L 177.538475 118.252076 \n",
       "L 177.81243 118.320176 \n",
       "L 177.972237 118.337904 \n",
       "L 178.200532 118.372495 \n",
       "L 178.383169 118.373925 \n",
       "L 178.634294 118.424814 \n",
       "L 178.771271 118.458407 \n",
       "L 179.090885 118.558167 \n",
       "L 179.387669 118.478984 \n",
       "L 179.547476 118.463896 \n",
       "L 179.752942 118.449176 \n",
       "L 179.958408 118.466777 \n",
       "L 180.118215 118.48401 \n",
       "L 180.414999 118.56642 \n",
       "L 180.597636 118.567535 \n",
       "L 180.780272 118.56866 \n",
       "L 180.91725 118.601528 \n",
       "L 181.145545 118.634826 \n",
       "L 181.533648 118.493567 \n",
       "L 181.647795 118.446568 \n",
       "L 181.830432 118.447862 \n",
       "L 182.013068 118.449144 \n",
       "L 182.150046 118.481812 \n",
       "L 182.469659 118.578869 \n",
       "L 182.720784 118.533006 \n",
       "L 182.94908 118.565958 \n",
       "L 183.200205 118.520294 \n",
       "L 183.656796 118.711254 \n",
       "L 183.839433 118.712148 \n",
       "L 184.044899 118.728771 \n",
       "L 184.318853 118.667694 \n",
       "L 184.50149 118.668651 \n",
       "L 184.638467 118.700456 \n",
       "L 184.866763 118.73263 \n",
       "L 185.049399 118.733481 \n",
       "L 185.277695 118.765497 \n",
       "L 185.483161 118.750946 \n",
       "L 185.711456 118.782825 \n",
       "L 185.916922 118.768294 \n",
       "L 186.213706 118.846415 \n",
       "L 186.487661 118.786105 \n",
       "L 186.715957 118.81768 \n",
       "L 187.104059 118.681856 \n",
       "L 187.378014 118.744132 \n",
       "L 187.994412 118.458849 \n",
       "L 188.222707 118.490634 \n",
       "L 188.58798 118.372212 \n",
       "L 188.747787 118.358291 \n",
       "L 188.953253 118.344748 \n",
       "L 189.13589 118.346105 \n",
       "L 189.364185 118.317779 \n",
       "L 189.523992 118.304006 \n",
       "L 189.729458 118.290621 \n",
       "L 190.026242 118.367585 \n",
       "L 190.208879 118.368889 \n",
       "L 190.368686 118.355147 \n",
       "L 190.688299 118.26831 \n",
       "L 190.802447 118.224675 \n",
       "L 191.030743 118.196907 \n",
       "L 191.281868 118.243391 \n",
       "L 191.510163 118.215686 \n",
       "L 191.715629 118.23212 \n",
       "L 191.852607 118.262695 \n",
       "L 192.058073 118.279024 \n",
       "L 192.309198 118.236914 \n",
       "L 192.560323 118.282893 \n",
       "L 192.811448 118.24093 \n",
       "L 192.994084 118.242381 \n",
       "L 193.176721 118.243832 \n",
       "L 193.382187 118.260024 \n",
       "L 193.564823 118.261454 \n",
       "L 193.793119 118.292272 \n",
       "L 194.067074 118.236346 \n",
       "L 194.27254 118.252454 \n",
       "L 194.455176 118.253874 \n",
       "L 194.706301 118.299116 \n",
       "L 194.888938 118.300473 \n",
       "L 195.071574 118.301829 \n",
       "L 195.29987 118.274786 \n",
       "L 195.482506 118.276164 \n",
       "L 195.756461 118.220943 \n",
       "L 196.076074 118.309221 \n",
       "L 196.235881 118.324656 \n",
       "L 196.464177 118.3548 \n",
       "L 196.692472 118.327925 \n",
       "L 196.852279 118.314856 \n",
       "L 197.012086 118.330207 \n",
       "L 197.171893 118.317159 \n",
       "L 197.582825 118.178718 \n",
       "L 197.742632 118.16589 \n",
       "L 198.062246 118.083963 \n",
       "L 198.244882 118.085561 \n",
       "L 198.473178 118.059454 \n",
       "L 198.632985 118.046848 \n",
       "L 198.929769 117.979483 \n",
       "L 199.249383 118.066341 \n",
       "L 199.454849 118.054197 \n",
       "L 199.568997 118.013381 \n",
       "L 199.728803 118.028774 \n",
       "L 199.91144 118.030425 \n",
       "L 200.116906 118.018386 \n",
       "L 200.322372 118.034126 \n",
       "L 200.619156 117.96757 \n",
       "L 200.847452 117.997368 \n",
       "L 201.144236 117.931117 \n",
       "L 201.326872 117.932873 \n",
       "L 201.486679 117.948171 \n",
       "L 201.669316 117.949906 \n",
       "L 201.851952 117.951631 \n",
       "L 202.103077 117.995118 \n",
       "L 202.308543 117.98331 \n",
       "L 202.46835 117.971103 \n",
       "L 202.719475 117.932495 \n",
       "L 202.924941 117.948077 \n",
       "L 203.176066 117.909616 \n",
       "L 203.427191 117.952787 \n",
       "L 203.586998 117.967844 \n",
       "L 203.792464 117.983289 \n",
       "L 204.157737 117.878483 \n",
       "L 204.317544 117.866549 \n",
       "L 204.52301 117.855089 \n",
       "L 204.659987 117.829508 \n",
       "L 204.819794 117.844574 \n",
       "L 205.185067 117.955595 \n",
       "L 205.413363 117.930897 \n",
       "L 205.595999 117.9326 \n",
       "L 205.801465 117.92115 \n",
       "L 206.029761 117.94999 \n",
       "L 206.303715 117.899217 \n",
       "L 206.440693 117.873888 \n",
       "L 206.646159 117.862585 \n",
       "L 206.942943 117.931811 \n",
       "L 207.171239 117.907429 \n",
       "L 207.582171 118.043399 \n",
       "L 207.924614 117.954028 \n",
       "L 208.061591 117.92893 \n",
       "L 208.244228 117.930613 \n",
       "L 208.495353 117.972312 \n",
       "L 208.700819 117.96102 \n",
       "L 208.837796 117.936049 \n",
       "L 209.043262 117.92483 \n",
       "L 209.271558 117.953061 \n",
       "L 209.499853 117.929014 \n",
       "L 209.728149 117.957151 \n",
       "L 209.865126 117.984404 \n",
       "L 210.024933 117.972796 \n",
       "L 210.321717 117.91052 \n",
       "L 210.504354 117.912202 \n",
       "L 210.68699 117.913874 \n",
       "L 210.983774 117.981197 \n",
       "L 211.257729 117.931979 \n",
       "L 211.486025 117.9598 \n",
       "L 211.759979 117.910772 \n",
       "L 212.011104 117.951578 \n",
       "L 212.2394 117.927953 \n",
       "L 212.467695 117.955595 \n",
       "L 212.787309 117.881753 \n",
       "L 213.061264 117.909784 \n",
       "L 213.198241 117.936511 \n",
       "L 213.632003 118.054712 \n",
       "L 214.020105 117.943755 \n",
       "L 214.27123 117.958612 \n",
       "L 214.636503 117.860756 \n",
       "L 214.933287 117.901309 \n",
       "L 215.207242 117.878609 \n",
       "L 215.526856 117.931748 \n",
       "L 215.800811 117.909079 \n",
       "L 216.143254 117.974657 \n",
       "L 216.32589 118.001195 \n",
       "L 216.485697 117.965068 \n",
       "L 216.691163 117.979283 \n",
       "L 216.919459 117.981197 \n",
       "L 217.170584 117.970872 \n",
       "L 217.558686 118.060947 \n",
       "L 217.764152 118.074942 \n",
       "L 218.038107 118.101795 \n",
       "L 218.449039 118.006242 \n",
       "L 218.722994 118.033095 \n",
       "L 218.996948 118.0107 \n",
       "L 219.270903 118.037459 \n",
       "L 219.750324 117.906661 \n",
       "L 220.161256 118.007861 \n",
       "L 220.503699 117.949728 \n",
       "L 220.754824 117.963985 \n",
       "L 221.028779 117.941979 \n",
       "L 221.234245 117.93158 \n",
       "L 221.439711 117.945427 \n",
       "L 221.622347 117.922758 \n",
       "L 221.941961 117.877179 \n",
       "L 222.147427 117.866917 \n",
       "L 222.581189 117.762479 \n",
       "L 223.060609 117.898912 \n",
       "L 223.357394 117.865529 \n",
       "L 223.813985 117.988914 \n",
       "L 224.04228 117.990744 \n",
       "L 224.476042 118.101228 \n",
       "L 224.704337 118.102899 \n",
       "L 224.955462 118.116589 \n",
       "L 225.229417 118.094866 \n",
       "L 225.480542 118.108524 \n",
       "L 225.754497 118.086897 \n",
       "L 225.937133 118.064648 \n",
       "L 226.188258 118.054744 \n",
       "L 226.416554 118.056458 \n",
       "L 226.895975 117.931054 \n",
       "L 227.1471 117.944817 \n",
       "L 227.352566 117.958171 \n",
       "L 227.67218 118.007419 \n",
       "L 227.946134 117.986223 \n",
       "L 228.197259 117.999818 \n",
       "L 228.516873 117.955826 \n",
       "L 228.790828 117.981197 \n",
       "L 229.110442 117.937394 \n",
       "L 229.384396 117.962713 \n",
       "L 229.567033 117.987242 \n",
       "L 229.909476 118.04751 \n",
       "L 230.411726 117.913317 \n",
       "L 230.913976 118.054881 \n",
       "L 231.096613 118.079106 \n",
       "L 231.370568 118.103919 \n",
       "L 231.598863 118.105517 \n",
       "L 231.73584 118.060853 \n",
       "L 231.941306 118.073733 \n",
       "L 232.306579 118.144546 \n",
       "L 232.489216 118.168487 \n",
       "L 232.740341 118.181483 \n",
       "L 232.922977 118.205319 \n",
       "L 233.28825 118.27547 \n",
       "L 233.425228 118.32148 \n",
       "L 233.676353 118.334181 \n",
       "L 233.973137 118.302071 \n",
       "L 234.247092 118.326138 \n",
       "L 234.498217 118.316328 \n",
       "L 234.772171 118.340311 \n",
       "L 235.068956 118.308379 \n",
       "L 235.34291 118.332299 \n",
       "L 235.548376 118.344601 \n",
       "L 235.913649 118.413459 \n",
       "L 236.164774 118.403618 \n",
       "L 236.461558 118.438462 \n",
       "L 236.598536 118.483537 \n",
       "L 236.804002 118.473422 \n",
       "L 237.123616 118.430671 \n",
       "L 237.39757 118.454139 \n",
       "L 237.625866 118.455243 \n",
       "L 237.831332 118.445212 \n",
       "L 238.036798 118.45723 \n",
       "L 238.196605 118.424993 \n",
       "L 238.516218 118.382652 \n",
       "L 238.744514 118.38384 \n",
       "L 239.041298 118.352529 \n",
       "L 239.315253 118.37586 \n",
       "L 239.566378 118.36625 \n",
       "L 239.771844 118.35643 \n",
       "L 239.954481 118.379193 \n",
       "L 240.159947 118.369373 \n",
       "L 240.433901 118.34907 \n",
       "L 240.753515 118.394176 \n",
       "L 241.050299 118.36318 \n",
       "L 241.438402 118.44088 \n",
       "L 241.598209 118.474053 \n",
       "L 241.803675 118.464222 \n",
       "L 242.0548 118.454612 \n",
       "L 242.305925 118.466567 \n",
       "L 242.625539 118.425077 \n",
       "L 242.808175 118.404511 \n",
       "L 243.173448 118.342057 \n",
       "L 243.493062 118.386521 \n",
       "L 243.698528 118.398234 \n",
       "L 243.903994 118.388593 \n",
       "L 244.132289 118.389739 \n",
       "L 244.337755 118.380129 \n",
       "L 244.58888 118.370761 \n",
       "L 244.840005 118.382663 \n",
       "L 245.13679 118.35235 \n",
       "L 245.524892 118.42841 \n",
       "L 245.730358 118.439955 \n",
       "L 245.958654 118.441038 \n",
       "L 246.14129 118.462981 \n",
       "L 246.460904 118.506542 \n",
       "L 246.712029 118.497121 \n",
       "L 246.985984 118.519317 \n",
       "L 247.19145 118.530682 \n",
       "L 247.419745 118.531639 \n",
       "L 247.67087 118.522229 \n",
       "L 247.876336 118.51265 \n",
       "L 248.058973 118.53431 \n",
       "L 248.401416 118.587838 \n",
       "L 248.675371 118.568092 \n",
       "L 248.972155 118.600445 \n",
       "L 249.383087 118.519054 \n",
       "L 249.565723 118.499108 \n",
       "L 249.953826 118.428421 \n",
       "L 250.25061 118.460773 \n",
       "L 250.570224 118.420987 \n",
       "L 250.77569 118.411651 \n",
       "L 251.026815 118.402566 \n",
       "L 251.163792 118.362118 \n",
       "L 251.323599 118.393713 \n",
       "L 251.78019 118.49832 \n",
       "L 252.008486 118.499297 \n",
       "L 252.30527 118.531198 \n",
       "L 252.556395 118.522029 \n",
       "L 252.967327 118.605165 \n",
       "L 253.149964 118.626183 \n",
       "L 253.446748 118.657716 \n",
       "L 253.697873 118.648432 \n",
       "L 253.971828 118.649378 \n",
       "L 254.38276 118.569943 \n",
       "L 254.679544 118.581172 \n",
       "L 255.044817 118.542259 \n",
       "L 255.478578 118.614355 \n",
       "L 255.843851 118.575536 \n",
       "L 256.072147 118.556348 \n",
       "L 256.346101 118.55742 \n",
       "L 256.688545 118.588721 \n",
       "L 257.053818 118.550176 \n",
       "L 257.259284 118.521093 \n",
       "L 257.46475 118.551785 \n",
       "L 257.898511 118.622987 \n",
       "L 258.263784 118.584621 \n",
       "L 258.560568 118.595619 \n",
       "L 258.743205 118.635846 \n",
       "L 259.245455 118.736247 \n",
       "L 259.565069 118.717479 \n",
       "L 260.067319 118.81728 \n",
       "L 260.478251 118.759473 \n",
       "L 260.797865 118.779955 \n",
       "L 261.094649 118.770986 \n",
       "L 261.505581 118.830665 \n",
       "L 261.733877 118.850726 \n",
       "L 261.985002 118.841579 \n",
       "L 262.464422 118.755309 \n",
       "L 262.784036 118.775602 \n",
       "L 263.217798 118.709025 \n",
       "L 263.537412 118.729318 \n",
       "L 263.948344 118.672646 \n",
       "L 264.222298 118.673519 \n",
       "L 264.701719 118.588553 \n",
       "L 264.998503 118.599204 \n",
       "L 265.249628 118.609676 \n",
       "L 265.592072 118.639568 \n",
       "L 265.934515 118.612042 \n",
       "L 266.231299 118.622598 \n",
       "L 266.68789 118.547989 \n",
       "L 267.030334 118.577776 \n",
       "L 267.304288 118.578764 \n",
       "L 267.760879 118.65617 \n",
       "L 268.126152 118.619517 \n",
       "L 268.514255 118.668009 \n",
       "L 268.833868 118.650166 \n",
       "L 269.039334 118.622588 \n",
       "L 269.313289 118.623502 \n",
       "L 269.610073 118.63388 \n",
       "L 269.952517 118.606879 \n",
       "L 270.386278 118.673845 \n",
       "L 270.705892 118.656139 \n",
       "L 271.162483 118.732167 \n",
       "L 271.550586 118.686725 \n",
       "L 271.801711 118.678187 \n",
       "L 272.189813 118.632965 \n",
       "L 272.463768 118.633859 \n",
       "L 272.943188 118.552195 \n",
       "L 273.194314 118.543867 \n",
       "L 273.513927 118.526582 \n",
       "L 273.787882 118.527602 \n",
       "L 274.153155 118.492169 \n",
       "L 274.472769 118.511767 \n",
       "L 274.838042 118.476471 \n",
       "L 275.089167 118.468301 \n",
       "L 275.40878 118.451279 \n",
       "L 275.796883 118.498477 \n",
       "L 276.253474 118.427348 \n",
       "L 276.687236 118.492758 \n",
       "L 276.915531 118.511788 \n",
       "L 277.212315 118.521966 \n",
       "L 277.668906 118.451237 \n",
       "L 278.034179 118.488836 \n",
       "L 278.285304 118.498814 \n",
       "L 278.627748 118.527129 \n",
       "L 278.993021 118.492474 \n",
       "L 279.221316 118.475356 \n",
       "L 279.56376 118.449754 \n",
       "L 279.974692 118.505122 \n",
       "L 280.248646 118.506132 \n",
       "L 280.613919 118.543205 \n",
       "L 280.865044 118.553015 \n",
       "L 281.390124 118.652753 \n",
       "L 281.778227 118.609497 \n",
       "L 282.166329 118.655087 \n",
       "L 282.62292 118.58564 \n",
       "L 282.805557 118.550859 \n",
       "L 283.033852 118.569322 \n",
       "L 283.307807 118.570248 \n",
       "L 283.467614 118.579605 \n",
       "L 283.467614 118.579605 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_26\">\n",
       "    <path d=\"M 55.194886 207.538125 \n",
       "L 55.240545 207.538125 \n",
       "L 55.331864 106.73812 \n",
       "L 55.377523 129.138124 \n",
       "L 55.423182 127.356304 \n",
       "L 55.491671 144.538123 \n",
       "L 55.5145 136.978124 \n",
       "L 55.582989 148.738123 \n",
       "L 55.605818 142.548652 \n",
       "L 55.628648 136.978124 \n",
       "L 55.674307 143.392669 \n",
       "L 55.719966 141.388125 \n",
       "L 55.742796 136.978124 \n",
       "L 55.788455 142.204794 \n",
       "L 55.834114 140.627781 \n",
       "L 55.971091 131.938124 \n",
       "L 55.993921 134.038127 \n",
       "L 56.03958 128.622337 \n",
       "L 56.222216 119.338125 \n",
       "L 56.267875 123.013127 \n",
       "L 56.336364 121.067537 \n",
       "L 56.404853 116.07146 \n",
       "L 56.450512 119.338125 \n",
       "L 56.54183 122.278127 \n",
       "L 56.56466 120.784025 \n",
       "L 56.587489 119.338125 \n",
       "L 56.633148 122.094375 \n",
       "L 56.747296 125.729428 \n",
       "L 56.792955 125.549392 \n",
       "L 56.929933 122.77449 \n",
       "L 56.952762 123.861202 \n",
       "L 56.998421 121.543123 \n",
       "L 57.06691 122.526075 \n",
       "L 57.181058 117.333581 \n",
       "L 57.203887 118.347114 \n",
       "L 57.249546 116.430428 \n",
       "L 57.272376 115.503343 \n",
       "L 57.340865 116.552866 \n",
       "L 57.363694 115.663129 \n",
       "L 57.660478 123.383996 \n",
       "L 57.728967 122.488123 \n",
       "L 57.751797 123.240781 \n",
       "L 57.797456 124.706821 \n",
       "L 57.843115 123.107356 \n",
       "L 58.002922 120.760704 \n",
       "L 58.025751 121.454924 \n",
       "L 58.07141 120.032613 \n",
       "L 58.254047 117.37812 \n",
       "L 58.368195 119.338125 \n",
       "L 58.391024 118.71259 \n",
       "L 58.61932 115.249382 \n",
       "L 58.687808 114.756305 \n",
       "L 58.756297 116.529209 \n",
       "L 58.801956 115.455104 \n",
       "L 58.847615 116.598992 \n",
       "L 58.961763 119.338125 \n",
       "L 59.030252 118.816229 \n",
       "L 59.075911 117.790752 \n",
       "L 59.12157 118.828299 \n",
       "L 59.144399 118.32433 \n",
       "L 59.372695 121.255516 \n",
       "L 59.395525 120.768395 \n",
       "L 59.441184 121.696416 \n",
       "L 59.464013 121.214721 \n",
       "L 59.600991 122.975239 \n",
       "L 59.64665 122.938123 \n",
       "L 59.669479 122.472137 \n",
       "L 59.715138 123.327072 \n",
       "L 59.783627 124.577727 \n",
       "L 59.852116 124.070809 \n",
       "L 59.874945 123.619679 \n",
       "L 59.920604 124.426585 \n",
       "L 60.080411 125.491611 \n",
       "L 60.103241 125.054791 \n",
       "L 60.1489 125.811518 \n",
       "L 60.240218 125.694883 \n",
       "L 60.308707 126.786127 \n",
       "L 60.422855 125.473779 \n",
       "L 60.445684 125.829035 \n",
       "L 60.491343 126.530399 \n",
       "L 60.537002 125.718551 \n",
       "L 60.582662 124.920403 \n",
       "L 60.65115 125.218125 \n",
       "L 60.67398 125.559701 \n",
       "L 60.719639 124.782571 \n",
       "L 60.765298 125.458123 \n",
       "L 60.810957 124.694399 \n",
       "L 60.856616 125.35981 \n",
       "L 61.107741 127.479663 \n",
       "L 61.244719 126.63286 \n",
       "L 61.358866 127.474658 \n",
       "L 61.290378 126.578423 \n",
       "L 61.381696 127.12048 \n",
       "L 61.632821 124.63636 \n",
       "L 61.769798 126.357502 \n",
       "L 61.815458 125.703074 \n",
       "L 61.838287 125.379219 \n",
       "L 61.883946 125.938125 \n",
       "L 62.043753 127.249753 \n",
       "L 62.066583 126.931502 \n",
       "L 62.135071 127.145993 \n",
       "L 62.18073 126.520536 \n",
       "L 62.20356 126.783577 \n",
       "L 62.272049 126.428158 \n",
       "L 62.294878 126.12274 \n",
       "L 62.340537 126.641309 \n",
       "L 62.431856 126.549445 \n",
       "L 62.523174 127.555518 \n",
       "L 62.660151 126.867391 \n",
       "L 62.751469 127.308002 \n",
       "L 62.70581 126.821759 \n",
       "L 62.774299 127.019207 \n",
       "L 62.842788 126.688123 \n",
       "L 62.865617 126.928038 \n",
       "L 62.956935 126.839003 \n",
       "L 63.071083 128.005176 \n",
       "L 63.139572 127.17251 \n",
       "L 63.185231 127.630432 \n",
       "L 63.23089 128.083166 \n",
       "L 63.276549 127.536997 \n",
       "L 63.299379 127.266213 \n",
       "L 63.345038 127.714662 \n",
       "L 63.367867 127.445644 \n",
       "L 63.390697 127.668126 \n",
       "L 63.459186 127.356304 \n",
       "L 63.482015 127.091971 \n",
       "L 63.527674 127.531567 \n",
       "L 63.550504 127.268915 \n",
       "L 63.573333 127.487039 \n",
       "L 63.618992 126.966231 \n",
       "L 63.641822 127.183408 \n",
       "L 63.915777 125.095308 \n",
       "L 63.938606 125.309998 \n",
       "L 64.007095 125.035797 \n",
       "L 64.075584 124.313509 \n",
       "L 64.144072 124.499959 \n",
       "L 64.23539 124.44795 \n",
       "L 64.28105 124.864441 \n",
       "L 64.326709 124.396977 \n",
       "L 64.395197 124.577727 \n",
       "L 64.509345 125.591917 \n",
       "L 64.600663 125.531344 \n",
       "L 64.669152 125.274665 \n",
       "L 64.691982 125.471939 \n",
       "L 64.828959 126.635999 \n",
       "L 64.897448 126.377564 \n",
       "L 64.965936 126.12274 \n",
       "L 64.988766 126.312081 \n",
       "L 65.080084 126.654252 \n",
       "L 65.034425 126.279791 \n",
       "L 65.125743 126.620695 \n",
       "L 65.239891 125.538126 \n",
       "L 65.28555 125.908328 \n",
       "L 65.354039 126.457409 \n",
       "L 65.422527 126.213404 \n",
       "L 65.627993 125.115416 \n",
       "L 65.696482 125.651791 \n",
       "L 65.742141 125.243527 \n",
       "L 65.81063 125.016235 \n",
       "L 65.833459 125.192943 \n",
       "L 65.901948 125.718551 \n",
       "L 65.947607 125.317784 \n",
       "L 66.153073 124.289058 \n",
       "L 66.175903 124.461776 \n",
       "L 66.221562 124.076139 \n",
       "L 66.449857 122.908978 \n",
       "L 66.678153 123.888123 \n",
       "L 66.792301 123.323587 \n",
       "L 66.81513 123.488713 \n",
       "L 66.952108 124.124174 \n",
       "L 66.860789 123.4725 \n",
       "L 66.997767 124.105695 \n",
       "L 67.066255 123.908952 \n",
       "L 67.089085 124.069158 \n",
       "L 67.111914 124.228754 \n",
       "L 67.157574 123.874124 \n",
       "L 67.248892 123.506366 \n",
       "L 67.271721 123.664916 \n",
       "L 67.294551 123.822872 \n",
       "L 67.34021 123.475087 \n",
       "L 67.36304 123.632506 \n",
       "L 67.431528 123.772761 \n",
       "L 67.568506 122.749177 \n",
       "L 67.614165 123.060325 \n",
       "L 67.682653 122.879002 \n",
       "L 67.819631 122.203828 \n",
       "L 67.84246 122.357584 \n",
       "L 67.86529 122.510787 \n",
       "L 67.910949 122.183289 \n",
       "L 67.956608 122.488123 \n",
       "L 67.979438 122.325289 \n",
       "L 68.025097 122.628 \n",
       "L 68.184904 123.361285 \n",
       "L 68.207733 123.199771 \n",
       "L 68.276222 122.718612 \n",
       "L 68.321881 123.013127 \n",
       "L 68.34471 123.159617 \n",
       "L 68.39037 122.84175 \n",
       "L 68.458858 122.975239 \n",
       "L 68.504517 122.660726 \n",
       "L 68.687154 123.509747 \n",
       "L 68.709983 123.353978 \n",
       "L 68.778472 123.185776 \n",
       "L 68.801302 123.327072 \n",
       "L 68.86979 123.748126 \n",
       "L 68.915449 123.440453 \n",
       "L 68.983938 123.274322 \n",
       "L 69.006768 123.413373 \n",
       "L 69.098086 123.67583 \n",
       "L 69.052427 123.399967 \n",
       "L 69.120915 123.524377 \n",
       "L 69.212234 122.923493 \n",
       "L 69.257893 123.197768 \n",
       "L 69.37204 123.592142 \n",
       "L 69.4177 123.57851 \n",
       "L 69.623166 122.821536 \n",
       "L 69.645995 122.955162 \n",
       "L 69.691654 122.666424 \n",
       "L 69.714484 122.799661 \n",
       "L 69.760143 122.512774 \n",
       "L 69.805802 122.778065 \n",
       "L 69.874291 123.172907 \n",
       "L 69.965609 123.149234 \n",
       "L 70.056927 122.855302 \n",
       "L 70.079757 122.984985 \n",
       "L 70.102586 123.114274 \n",
       "L 70.148245 122.833859 \n",
       "L 70.171075 122.694287 \n",
       "L 70.216734 122.951781 \n",
       "L 70.239564 122.812672 \n",
       "L 70.285223 123.068637 \n",
       "L 70.376541 123.046231 \n",
       "L 70.513518 122.225624 \n",
       "L 70.559177 122.478776 \n",
       "L 70.582007 122.60479 \n",
       "L 70.627666 122.334579 \n",
       "L 70.696155 121.932245 \n",
       "L 70.764643 122.049984 \n",
       "L 70.810302 122.299587 \n",
       "L 70.901621 122.282391 \n",
       "L 70.92445 122.1503 \n",
       "L 70.970109 122.397086 \n",
       "L 71.038598 122.764601 \n",
       "L 71.084257 122.501682 \n",
       "L 71.152746 122.110125 \n",
       "L 71.198405 122.353509 \n",
       "L 71.518019 123.526391 \n",
       "L 71.563678 123.269044 \n",
       "L 71.609337 123.503123 \n",
       "L 71.700655 123.967406 \n",
       "L 71.769144 123.826983 \n",
       "L 71.791973 123.699666 \n",
       "L 71.837632 123.92936 \n",
       "L 71.860462 123.802422 \n",
       "L 71.883292 123.916812 \n",
       "L 71.928951 123.664012 \n",
       "L 72.020269 123.401539 \n",
       "L 72.043098 123.515393 \n",
       "L 72.065928 123.628936 \n",
       "L 72.134417 123.492903 \n",
       "L 72.157246 123.605868 \n",
       "L 72.225735 123.23451 \n",
       "L 72.271394 123.45962 \n",
       "L 72.431201 124.00479 \n",
       "L 72.45403 123.882115 \n",
       "L 72.522519 123.980228 \n",
       "L 72.591008 123.615189 \n",
       "L 72.613837 123.725037 \n",
       "L 72.682326 123.592883 \n",
       "L 72.705156 123.702189 \n",
       "L 72.750815 123.46176 \n",
       "L 72.796474 123.679578 \n",
       "L 72.910622 124.219207 \n",
       "L 73.00194 124.194209 \n",
       "L 73.161747 123.815281 \n",
       "L 73.298724 124.225784 \n",
       "L 73.344383 124.213503 \n",
       "L 73.549849 123.39204 \n",
       "L 73.572679 123.496436 \n",
       "L 73.663997 123.91146 \n",
       "L 73.709656 123.682953 \n",
       "L 73.846633 123.435437 \n",
       "L 73.915122 123.742753 \n",
       "L 73.960781 123.517711 \n",
       "L 74.074929 123.385952 \n",
       "L 74.143418 123.477473 \n",
       "L 74.166247 123.36649 \n",
       "L 74.326054 123.017506 \n",
       "L 74.463031 123.200139 \n",
       "L 74.55435 122.974166 \n",
       "L 74.577179 123.073652 \n",
       "L 74.668497 123.262714 \n",
       "L 74.691327 123.154969 \n",
       "L 74.714156 123.047472 \n",
       "L 74.759816 123.244419 \n",
       "L 74.828304 123.538125 \n",
       "L 74.873963 123.323986 \n",
       "L 74.988111 123.199413 \n",
       "L 75.03377 123.393296 \n",
       "L 75.102259 123.278333 \n",
       "L 75.170748 122.962784 \n",
       "L 75.239236 123.050752 \n",
       "L 75.284895 123.242553 \n",
       "L 75.353384 123.12953 \n",
       "L 75.467532 122.810564 \n",
       "L 75.490361 122.905766 \n",
       "L 75.604509 122.984381 \n",
       "L 75.627339 122.881877 \n",
       "L 75.672998 123.070419 \n",
       "L 75.695827 122.968157 \n",
       "L 75.764316 122.858304 \n",
       "L 75.992612 123.786808 \n",
       "L 76.175248 123.364645 \n",
       "L 76.380714 123.80034 \n",
       "L 76.449203 123.502071 \n",
       "L 76.517691 123.583047 \n",
       "L 76.677498 123.832393 \n",
       "L 76.860135 123.423178 \n",
       "L 76.882964 123.511629 \n",
       "L 76.928623 123.317767 \n",
       "L 76.951453 123.40605 \n",
       "L 77.042771 123.204933 \n",
       "L 77.065601 123.292869 \n",
       "L 77.08843 123.380626 \n",
       "L 77.134089 123.188852 \n",
       "L 77.156919 123.276441 \n",
       "L 77.339555 122.880658 \n",
       "L 77.408044 122.960303 \n",
       "L 77.430874 122.866127 \n",
       "L 77.476533 122.678353 \n",
       "L 77.545021 122.758124 \n",
       "L 77.818976 123.605868 \n",
       "L 77.841806 123.512749 \n",
       "L 78.024442 123.126938 \n",
       "L 78.047272 123.211179 \n",
       "L 78.092931 123.027768 \n",
       "L 78.11576 123.111856 \n",
       "L 78.252738 122.914981 \n",
       "L 78.412544 123.496867 \n",
       "L 78.458204 123.315774 \n",
       "L 78.526692 123.217892 \n",
       "L 78.549522 123.300234 \n",
       "L 78.61801 123.546305 \n",
       "L 78.686499 123.448417 \n",
       "L 78.732158 123.269522 \n",
       "L 78.777817 123.432514 \n",
       "L 78.800647 123.513779 \n",
       "L 78.846306 123.33562 \n",
       "L 78.869136 123.416738 \n",
       "L 78.891965 123.327924 \n",
       "L 78.937624 123.489712 \n",
       "L 78.960454 123.401082 \n",
       "L 79.234408 124.024273 \n",
       "L 79.348556 123.918862 \n",
       "L 79.371386 123.997745 \n",
       "L 79.417045 123.822872 \n",
       "L 79.439874 123.901624 \n",
       "L 79.554022 123.797674 \n",
       "L 79.66817 123.859094 \n",
       "L 79.713829 123.686591 \n",
       "L 79.759488 123.842302 \n",
       "L 79.827977 124.074794 \n",
       "L 79.896466 123.980228 \n",
       "L 79.987784 123.800866 \n",
       "L 80.010613 123.87783 \n",
       "L 80.079102 123.784505 \n",
       "L 80.17042 124.090455 \n",
       "L 80.353057 123.736129 \n",
       "L 80.512864 123.946772 \n",
       "L 80.672671 123.681008 \n",
       "L 80.6955 123.756012 \n",
       "L 80.741159 123.590622 \n",
       "L 80.809648 123.657803 \n",
       "L 80.855307 123.493323 \n",
       "L 80.923796 123.404084 \n",
       "L 81.106432 123.996578 \n",
       "L 81.289069 123.655606 \n",
       "L 81.357557 123.567417 \n",
       "L 81.471705 123.931873 \n",
       "L 81.563023 123.763382 \n",
       "L 81.585853 123.835794 \n",
       "L 81.608682 123.908074 \n",
       "L 81.654341 123.748126 \n",
       "L 81.814148 123.494937 \n",
       "L 81.882637 123.408894 \n",
       "L 81.928296 123.552461 \n",
       "L 81.996785 123.31651 \n",
       "L 82.042444 123.45962 \n",
       "L 82.24791 123.800182 \n",
       "L 82.270739 123.722119 \n",
       "L 82.316399 123.863105 \n",
       "L 82.384887 123.925707 \n",
       "L 82.407717 123.847933 \n",
       "L 82.430546 123.770285 \n",
       "L 82.476205 123.910366 \n",
       "L 82.499035 123.83286 \n",
       "L 82.544694 123.972485 \n",
       "L 82.613183 123.887545 \n",
       "L 82.681671 123.949411 \n",
       "L 82.727331 123.795624 \n",
       "L 82.795819 123.711678 \n",
       "L 82.841478 123.850004 \n",
       "L 82.932797 123.690098 \n",
       "L 82.955626 123.758998 \n",
       "L 83.115433 123.949889 \n",
       "L 83.389388 123.334243 \n",
       "L 83.435047 123.470276 \n",
       "L 83.480706 123.321352 \n",
       "L 83.503535 123.247069 \n",
       "L 83.549195 123.382692 \n",
       "L 83.617683 123.585318 \n",
       "L 83.686172 123.5045 \n",
       "L 83.823149 123.344021 \n",
       "L 83.868808 123.477983 \n",
       "L 83.914467 123.331293 \n",
       "L 84.074274 122.960876 \n",
       "L 84.097104 123.027626 \n",
       "L 84.30257 123.347217 \n",
       "L 84.439547 123.190855 \n",
       "L 84.462377 123.256595 \n",
       "L 84.508036 123.113223 \n",
       "L 84.599354 122.964656 \n",
       "L 84.622184 123.030218 \n",
       "L 84.690672 123.226293 \n",
       "L 84.736331 123.084072 \n",
       "L 84.80482 123.143362 \n",
       "L 84.850479 123.001819 \n",
       "L 84.918968 122.92569 \n",
       "L 85.010286 123.184646 \n",
       "L 85.215752 122.823234 \n",
       "L 85.238582 122.887555 \n",
       "L 85.284241 122.748436 \n",
       "L 85.30707 122.679036 \n",
       "L 85.352729 122.807415 \n",
       "L 85.581025 123.311096 \n",
       "L 85.603855 123.241949 \n",
       "L 85.649514 123.10397 \n",
       "L 85.695173 123.230272 \n",
       "L 85.85498 123.406875 \n",
       "L 86.060446 123.05387 \n",
       "L 86.106105 123.178569 \n",
       "L 86.151764 123.042914 \n",
       "L 86.174593 122.975239 \n",
       "L 86.220253 123.099596 \n",
       "L 86.243082 123.161635 \n",
       "L 86.288741 123.026606 \n",
       "L 86.311571 123.088567 \n",
       "L 86.402889 122.948653 \n",
       "L 86.425719 123.01044 \n",
       "L 86.608355 123.245313 \n",
       "L 86.790991 122.840651 \n",
       "L 86.813821 122.90176 \n",
       "L 86.836651 122.962784 \n",
       "L 86.88231 122.830568 \n",
       "L 86.905139 122.891508 \n",
       "L 87.087776 122.61881 \n",
       "L 87.316071 122.971364 \n",
       "L 87.338901 122.906186 \n",
       "L 87.38456 123.026149 \n",
       "L 87.544367 123.194545 \n",
       "L 87.658515 122.995047 \n",
       "L 87.681344 123.054416 \n",
       "L 87.749833 123.108412 \n",
       "L 87.772662 123.044007 \n",
       "L 87.841151 122.974603 \n",
       "L 87.863981 123.033656 \n",
       "L 87.90964 123.151515 \n",
       "L 87.955299 123.023362 \n",
       "L 88.023787 123.076969 \n",
       "L 88.137935 122.758624 \n",
       "L 88.229253 122.992824 \n",
       "L 88.297742 122.924481 \n",
       "L 88.343401 122.798136 \n",
       "L 88.38906 122.914619 \n",
       "L 88.640185 123.429255 \n",
       "L 88.663015 123.366348 \n",
       "L 88.731504 123.178127 \n",
       "L 88.777163 123.292743 \n",
       "L 88.845651 123.464089 \n",
       "L 88.91414 123.39604 \n",
       "L 88.93697 123.333664 \n",
       "L 88.982629 123.447376 \n",
       "L 89.005458 123.38509 \n",
       "L 89.051117 123.498502 \n",
       "L 89.096777 123.374197 \n",
       "L 89.142436 123.250223 \n",
       "L 89.210924 123.301507 \n",
       "L 89.302243 123.408894 \n",
       "L 89.325072 123.347217 \n",
       "L 89.484879 123.035133 \n",
       "L 89.507709 123.091316 \n",
       "L 89.530538 123.147425 \n",
       "L 89.576197 123.025318 \n",
       "L 89.599027 122.964383 \n",
       "L 89.644686 123.076402 \n",
       "L 89.667515 123.015556 \n",
       "L 89.713175 123.127285 \n",
       "L 89.781663 123.061608 \n",
       "L 89.872981 122.935758 \n",
       "L 89.895811 122.991378 \n",
       "L 90.078447 123.203004 \n",
       "L 90.146936 123.137863 \n",
       "L 90.169766 123.192921 \n",
       "L 90.192595 123.247905 \n",
       "L 90.238254 123.127969 \n",
       "L 90.46655 122.761153 \n",
       "L 90.672016 123.02494 \n",
       "L 90.786164 122.843511 \n",
       "L 90.808993 122.897764 \n",
       "L 90.831823 122.951955 \n",
       "L 90.877482 122.834542 \n",
       "L 91.014459 122.708823 \n",
       "L 91.082948 122.758466 \n",
       "L 91.105777 122.700259 \n",
       "L 91.128607 122.642126 \n",
       "L 91.174266 122.749792 \n",
       "L 91.197096 122.803525 \n",
       "L 91.242755 122.68749 \n",
       "L 91.334073 122.567669 \n",
       "L 91.356903 122.621281 \n",
       "L 91.379732 122.67482 \n",
       "L 91.425391 122.559536 \n",
       "L 91.448221 122.613017 \n",
       "L 91.516709 122.55144 \n",
       "L 91.539539 122.60479 \n",
       "L 91.608028 122.653912 \n",
       "L 91.630857 122.59661 \n",
       "L 91.653687 122.539375 \n",
       "L 91.699346 122.645627 \n",
       "L 91.790664 122.857326 \n",
       "L 91.859153 122.795871 \n",
       "L 91.881982 122.738873 \n",
       "L 91.927641 122.84421 \n",
       "L 91.950471 122.787286 \n",
       "L 91.973301 122.839862 \n",
       "L 92.01896 122.726229 \n",
       "L 92.041789 122.778743 \n",
       "L 92.224426 122.544412 \n",
       "L 92.315744 122.644949 \n",
       "L 92.338573 122.58874 \n",
       "L 92.452721 122.416753 \n",
       "L 92.475551 122.468846 \n",
       "L 92.544039 122.51699 \n",
       "L 92.566869 122.461202 \n",
       "L 92.681017 122.398016 \n",
       "L 92.703846 122.449804 \n",
       "L 92.749505 122.338853 \n",
       "L 92.932142 122.11104 \n",
       "L 92.977801 122.214211 \n",
       "L 93.04629 122.155847 \n",
       "L 93.114778 122.203828 \n",
       "L 93.160437 122.094375 \n",
       "L 93.183267 122.145695 \n",
       "L 93.228926 122.036505 \n",
       "L 93.365903 121.815947 \n",
       "L 93.388733 121.867157 \n",
       "L 93.411563 121.918303 \n",
       "L 93.457222 121.810038 \n",
       "L 93.480051 121.756005 \n",
       "L 93.52571 121.858125 \n",
       "L 93.594199 121.906038 \n",
       "L 93.617029 121.852137 \n",
       "L 93.639858 121.798304 \n",
       "L 93.685517 121.899951 \n",
       "L 93.799665 122.048764 \n",
       "L 93.822495 121.995068 \n",
       "L 93.845324 121.941429 \n",
       "L 93.890983 122.042371 \n",
       "L 93.959472 122.089507 \n",
       "L 93.982301 122.036005 \n",
       "L 94.210597 121.710757 \n",
       "L 94.393233 122.007743 \n",
       "L 94.416063 121.954877 \n",
       "L 94.438893 121.90208 \n",
       "L 94.484552 122.001539 \n",
       "L 94.644359 122.245817 \n",
       "L 94.667188 122.193156 \n",
       "L 94.826995 122.029318 \n",
       "L 95.055291 122.31683 \n",
       "L 95.07812 122.264669 \n",
       "L 95.123779 122.362126 \n",
       "L 95.146609 122.310028 \n",
       "L 95.215097 122.455797 \n",
       "L 95.260757 122.35179 \n",
       "L 95.397734 122.241417 \n",
       "L 95.58037 122.527279 \n",
       "L 95.6032 122.475675 \n",
       "L 95.717348 122.317856 \n",
       "L 95.740177 122.365811 \n",
       "L 95.763007 122.413714 \n",
       "L 95.808666 122.311158 \n",
       "L 95.831495 122.359014 \n",
       "L 96.014132 122.148297 \n",
       "L 96.173939 122.48111 \n",
       "L 96.219598 122.379506 \n",
       "L 96.379405 122.123389 \n",
       "L 96.402234 122.170682 \n",
       "L 96.493553 122.261883 \n",
       "L 96.516382 122.211567 \n",
       "L 96.539212 122.161304 \n",
       "L 96.584871 122.255432 \n",
       "L 96.790337 122.579703 \n",
       "L 96.813166 122.529571 \n",
       "L 97.13278 121.929422 \n",
       "L 97.15561 121.975974 \n",
       "L 97.201269 122.068925 \n",
       "L 97.246928 121.970249 \n",
       "L 97.315417 122.013746 \n",
       "L 97.429564 121.76827 \n",
       "L 97.543712 121.809244 \n",
       "L 97.726349 121.609368 \n",
       "L 97.908985 121.882355 \n",
       "L 97.931815 121.833905 \n",
       "L 98.000303 121.87693 \n",
       "L 98.091621 121.683872 \n",
       "L 98.18294 121.772518 \n",
       "L 98.205769 121.724436 \n",
       "L 98.251428 121.628425 \n",
       "L 98.297087 121.719384 \n",
       "L 98.502553 121.940441 \n",
       "L 98.68519 121.651872 \n",
       "L 98.708019 121.69691 \n",
       "L 98.730849 121.7419 \n",
       "L 98.776508 121.647025 \n",
       "L 98.890656 121.502827 \n",
       "L 98.913485 121.547728 \n",
       "L 99.073292 121.677285 \n",
       "L 99.278758 121.438128 \n",
       "L 99.529883 121.743993 \n",
       "L 99.644031 121.601987 \n",
       "L 99.666861 121.646079 \n",
       "L 99.963645 122.035374 \n",
       "L 100.009304 121.942807 \n",
       "L 100.054963 122.029886 \n",
       "L 100.123452 122.160168 \n",
       "L 100.169111 122.067805 \n",
       "L 100.306088 121.970296 \n",
       "L 100.420236 122.097156 \n",
       "L 100.443066 122.051288 \n",
       "L 100.465895 122.005461 \n",
       "L 100.511554 122.091599 \n",
       "L 100.534384 122.045825 \n",
       "L 100.694191 122.169016 \n",
       "L 100.71702 122.123389 \n",
       "L 100.76268 122.208933 \n",
       "L 100.785509 122.163349 \n",
       "L 100.876827 122.245817 \n",
       "L 100.899657 122.200332 \n",
       "L 101.036634 122.10398 \n",
       "L 101.105123 122.056019 \n",
       "L 101.196441 122.225624 \n",
       "L 101.219271 122.180466 \n",
       "L 101.26493 122.265021 \n",
       "L 101.310589 122.349409 \n",
       "L 101.356248 122.259233 \n",
       "L 101.424737 122.298441 \n",
       "L 101.493225 122.163653 \n",
       "L 101.675862 122.412352 \n",
       "L 101.698691 122.367567 \n",
       "L 101.76718 122.233468 \n",
       "L 101.835669 122.272371 \n",
       "L 101.881328 122.355723 \n",
       "L 101.926987 122.266641 \n",
       "L 101.995476 122.133346 \n",
       "L 102.041135 122.216545 \n",
       "L 102.246601 122.58895 \n",
       "L 102.29226 122.500336 \n",
       "L 102.383578 122.40892 \n",
       "L 102.406408 122.450062 \n",
       "L 102.429237 122.491167 \n",
       "L 102.474896 122.40299 \n",
       "L 102.497726 122.358966 \n",
       "L 102.543385 122.441067 \n",
       "L 102.566214 122.397086 \n",
       "L 102.703192 122.472993 \n",
       "L 102.79451 122.297857 \n",
       "L 102.862999 122.33583 \n",
       "L 102.931487 122.373692 \n",
       "L 102.954317 122.330099 \n",
       "L 103.159783 122.107486 \n",
       "L 103.228272 122.061639 \n",
       "L 103.273931 122.142777 \n",
       "L 103.410908 122.05133 \n",
       "L 103.433738 122.091767 \n",
       "L 103.479397 122.005798 \n",
       "L 103.570715 121.917557 \n",
       "L 103.593544 121.957926 \n",
       "L 103.730522 122.116402 \n",
       "L 103.753351 122.073651 \n",
       "L 103.79901 121.988265 \n",
       "L 103.867499 122.02589 \n",
       "L 103.890329 122.06596 \n",
       "L 103.935988 121.980821 \n",
       "L 103.958817 121.938312 \n",
       "L 104.004476 122.018352 \n",
       "L 104.027306 122.058311 \n",
       "L 104.072965 121.973419 \n",
       "L 104.095795 122.013347 \n",
       "L 104.255602 121.799518 \n",
       "L 104.278431 121.839378 \n",
       "L 104.34692 121.958736 \n",
       "L 104.392579 121.87449 \n",
       "L 104.461068 121.748409 \n",
       "L 104.506727 121.827807 \n",
       "L 104.712193 122.020707 \n",
       "L 104.803511 121.853488 \n",
       "L 104.84917 121.932245 \n",
       "L 104.940488 122.0084 \n",
       "L 104.963318 121.966737 \n",
       "L 105.054636 121.961922 \n",
       "L 105.237272 122.113227 \n",
       "L 105.328591 122.108175 \n",
       "L 105.35142 122.147041 \n",
       "L 105.397079 122.064304 \n",
       "L 105.488398 121.979323 \n",
       "L 105.511227 122.018126 \n",
       "L 105.625375 122.051971 \n",
       "L 105.648204 122.01085 \n",
       "L 105.693864 122.088145 \n",
       "L 105.716693 122.126743 \n",
       "L 105.762352 122.044622 \n",
       "L 105.967818 121.835472 \n",
       "L 106.036307 121.871699 \n",
       "L 106.059136 121.830993 \n",
       "L 106.150455 121.747531 \n",
       "L 106.173284 121.785934 \n",
       "L 106.424409 122.048948 \n",
       "L 106.538557 122.003726 \n",
       "L 106.607046 121.961028 \n",
       "L 106.652705 122.036925 \n",
       "L 106.766853 121.991929 \n",
       "L 106.835341 122.027389 \n",
       "L 106.858171 121.98724 \n",
       "L 107.109296 121.70305 \n",
       "L 107.132126 121.740759 \n",
       "L 107.177785 121.661214 \n",
       "L 107.200614 121.698897 \n",
       "L 107.269103 121.657145 \n",
       "L 107.291932 121.69476 \n",
       "L 107.314762 121.732348 \n",
       "L 107.360421 121.653086 \n",
       "L 107.451739 121.649044 \n",
       "L 107.680035 121.869081 \n",
       "L 107.794183 121.748798 \n",
       "L 107.817012 121.786002 \n",
       "L 107.90833 121.78176 \n",
       "L 108.182285 121.465254 \n",
       "L 108.205115 121.502312 \n",
       "L 108.250774 121.424575 \n",
       "L 108.43341 121.266198 \n",
       "L 108.593217 121.373512 \n",
       "L 108.775854 121.216319 \n",
       "L 108.821513 121.289787 \n",
       "L 108.867172 121.213128 \n",
       "L 108.95849 121.209942 \n",
       "L 108.98132 121.246568 \n",
       "L 109.026979 121.170172 \n",
       "L 109.163956 121.090936 \n",
       "L 109.278104 121.124456 \n",
       "L 109.437911 121.007879 \n",
       "L 109.620547 121.1502 \n",
       "L 109.711865 121.07333 \n",
       "L 109.734695 121.109504 \n",
       "L 109.826013 121.106545 \n",
       "L 110.00865 120.953778 \n",
       "L 110.259775 121.202277 \n",
       "L 110.396752 121.051807 \n",
       "L 110.419582 121.087545 \n",
       "L 110.533729 121.120313 \n",
       "L 110.602218 121.081783 \n",
       "L 110.625048 121.117374 \n",
       "L 110.762025 121.185433 \n",
       "L 111.01315 120.924716 \n",
       "L 111.03598 120.960112 \n",
       "L 111.081639 120.886754 \n",
       "L 111.218616 120.81112 \n",
       "L 111.309934 120.952195 \n",
       "L 111.355593 120.879205 \n",
       "L 111.446912 120.876703 \n",
       "L 111.5154 120.910575 \n",
       "L 111.53823 120.874211 \n",
       "L 111.675207 120.799218 \n",
       "L 111.766525 120.796858 \n",
       "L 111.857844 120.723463 \n",
       "L 111.880673 120.758417 \n",
       "L 112.01765 120.825835 \n",
       "L 112.04048 120.789829 \n",
       "L 112.086139 120.859423 \n",
       "L 112.177457 120.856989 \n",
       "L 112.268776 120.713495 \n",
       "L 112.314435 120.782874 \n",
       "L 112.474242 120.95454 \n",
       "L 112.497071 120.91877 \n",
       "L 112.519901 120.883027 \n",
       "L 112.56556 120.951969 \n",
       "L 112.588389 120.986393 \n",
       "L 112.634048 120.915001 \n",
       "L 112.793855 120.805795 \n",
       "L 112.953662 120.906279 \n",
       "L 113.113469 120.797699 \n",
       "L 113.296106 120.931682 \n",
       "L 113.318935 120.896428 \n",
       "L 113.364594 120.964408 \n",
       "L 113.478742 120.995761 \n",
       "L 113.638549 120.887911 \n",
       "L 113.661378 120.92173 \n",
       "L 113.707038 120.8517 \n",
       "L 113.844015 120.710888 \n",
       "L 113.866844 120.74466 \n",
       "L 113.958163 120.879484 \n",
       "L 114.003822 120.809837 \n",
       "L 114.140799 120.738125 \n",
       "L 114.277776 120.871151 \n",
       "L 114.300606 120.836502 \n",
       "L 114.483242 120.696094 \n",
       "L 114.643049 120.861736 \n",
       "L 114.665879 120.827302 \n",
       "L 114.688708 120.792899 \n",
       "L 114.734368 120.859396 \n",
       "L 114.825686 120.857067 \n",
       "L 115.053981 120.649527 \n",
       "L 115.12247 120.681611 \n",
       "L 115.1453 120.647529 \n",
       "L 115.168129 120.613468 \n",
       "L 115.213788 120.679571 \n",
       "L 115.327936 120.777443 \n",
       "L 115.350766 120.743435 \n",
       "L 115.64755 120.436881 \n",
       "L 115.830186 120.566353 \n",
       "L 115.944334 120.464649 \n",
       "L 115.967164 120.497343 \n",
       "L 116.104141 120.560828 \n",
       "L 116.263948 120.458751 \n",
       "L 116.286777 120.491282 \n",
       "L 116.332436 120.424574 \n",
       "L 116.515073 120.290044 \n",
       "L 116.629221 120.321035 \n",
       "L 116.789028 120.22045 \n",
       "L 116.857516 120.252114 \n",
       "L 116.880346 120.219146 \n",
       "L 116.903175 120.1862 \n",
       "L 116.948834 120.250763 \n",
       "L 117.1543 120.475142 \n",
       "L 117.17713 120.442248 \n",
       "L 117.336937 120.342237 \n",
       "L 117.405426 120.37349 \n",
       "L 117.428255 120.340765 \n",
       "L 117.633721 120.176285 \n",
       "L 117.725039 120.17506 \n",
       "L 117.816358 120.17384 \n",
       "L 117.839187 120.205667 \n",
       "L 117.998994 120.299607 \n",
       "L 118.113142 120.329856 \n",
       "L 118.272949 120.423076 \n",
       "L 118.318608 120.358513 \n",
       "L 118.387096 120.452968 \n",
       "L 118.478415 120.514976 \n",
       "L 118.501244 120.482755 \n",
       "L 118.683881 120.416052 \n",
       "L 118.775199 120.414507 \n",
       "L 119.049154 120.220755 \n",
       "L 119.186131 120.281775 \n",
       "L 119.323108 120.216986 \n",
       "L 119.345938 120.24805 \n",
       "L 119.482915 120.308733 \n",
       "L 119.642722 120.150162 \n",
       "L 119.688381 120.212012 \n",
       "L 119.916677 120.395528 \n",
       "L 120.076484 120.237809 \n",
       "L 120.122143 120.299181 \n",
       "L 120.28195 120.451448 \n",
       "L 120.304779 120.420142 \n",
       "L 120.464586 120.386654 \n",
       "L 120.624393 120.476388 \n",
       "L 120.647223 120.44524 \n",
       "L 120.807029 120.411862 \n",
       "L 120.966836 120.501065 \n",
       "L 120.989666 120.470069 \n",
       "L 121.012495 120.439094 \n",
       "L 121.080984 120.529606 \n",
       "L 121.195132 120.558042 \n",
       "L 121.217961 120.527135 \n",
       "L 121.377768 120.433022 \n",
       "L 121.400598 120.463046 \n",
       "L 121.674553 120.640079 \n",
       "L 121.7887 120.607627 \n",
       "L 121.81153 120.637404 \n",
       "L 121.971337 120.664441 \n",
       "L 122.131144 120.571059 \n",
       "L 122.153973 120.600704 \n",
       "L 122.405098 120.745732 \n",
       "L 122.610564 120.651871 \n",
       "L 122.793201 120.707875 \n",
       "L 123.089985 120.494362 \n",
       "L 123.112815 120.523608 \n",
       "L 123.181303 120.433595 \n",
       "L 123.272621 120.372991 \n",
       "L 123.318281 120.431392 \n",
       "L 123.500917 120.487407 \n",
       "L 123.615065 120.456069 \n",
       "L 123.637894 120.48511 \n",
       "L 123.729213 120.601061 \n",
       "L 123.797701 120.511779 \n",
       "L 123.934679 120.50944 \n",
       "L 123.980338 120.567189 \n",
       "L 124.048826 120.478265 \n",
       "L 124.117315 120.389514 \n",
       "L 124.185804 120.475999 \n",
       "L 124.322781 120.473749 \n",
       "L 124.436929 120.500944 \n",
       "L 124.87069 120.869275 \n",
       "L 125.076156 120.778358 \n",
       "L 125.304452 120.888516 \n",
       "L 125.4186 120.800001 \n",
       "L 125.464259 120.856347 \n",
       "L 125.715384 120.993658 \n",
       "L 125.943679 120.874511 \n",
       "L 125.989339 120.930389 \n",
       "L 126.057827 120.84363 \n",
       "L 126.308952 120.696788 \n",
       "L 126.400271 120.751588 \n",
       "L 126.44593 120.694181 \n",
       "L 126.560077 120.607391 \n",
       "L 126.605737 120.662958 \n",
       "L 126.788373 120.772044 \n",
       "L 126.811203 120.743477 \n",
       "L 126.879691 120.714058 \n",
       "L 126.92535 120.769305 \n",
       "L 126.971009 120.824484 \n",
       "L 127.039498 120.739013 \n",
       "L 127.290623 120.594537 \n",
       "L 127.518919 120.701898 \n",
       "L 127.747214 120.475652 \n",
       "L 127.792873 120.530389 \n",
       "L 127.998339 120.609977 \n",
       "L 128.135317 120.497201 \n",
       "L 128.180976 120.551633 \n",
       "L 128.340783 120.576505 \n",
       "L 128.614737 120.407383 \n",
       "L 128.797374 120.459429 \n",
       "L 128.911522 120.430383 \n",
       "L 128.934351 120.457347 \n",
       "L 129.071329 120.45527 \n",
       "L 129.231135 120.371293 \n",
       "L 129.253965 120.398157 \n",
       "L 129.436601 120.449777 \n",
       "L 129.596408 120.420331 \n",
       "L 129.756215 120.445014 \n",
       "L 129.870363 120.416362 \n",
       "L 129.893193 120.442984 \n",
       "L 129.984511 120.441633 \n",
       "L 130.00734 120.414391 \n",
       "L 130.121488 120.332154 \n",
       "L 130.167147 120.385251 \n",
       "L 130.235636 120.411116 \n",
       "L 130.281295 120.356846 \n",
       "L 130.509591 120.246851 \n",
       "L 130.692227 120.297982 \n",
       "L 130.874863 120.136073 \n",
       "L 130.920523 120.18876 \n",
       "L 131.125989 120.265987 \n",
       "L 131.331455 120.184171 \n",
       "L 131.514091 120.234897 \n",
       "L 131.58258 120.207738 \n",
       "L 131.628239 120.259894 \n",
       "L 131.810875 120.310242 \n",
       "L 131.925023 120.335029 \n",
       "L 131.970682 120.386875 \n",
       "L 132.039171 120.307356 \n",
       "L 132.198978 120.226922 \n",
       "L 132.221807 120.252792 \n",
       "L 132.427273 120.380677 \n",
       "L 132.450103 120.354312 \n",
       "L 132.541421 120.353114 \n",
       "L 132.564251 120.378832 \n",
       "L 132.815376 120.505134 \n",
       "L 132.998012 120.450649 \n",
       "L 133.11216 120.423186 \n",
       "L 133.340455 120.316982 \n",
       "L 133.660069 120.51823 \n",
       "L 133.865535 120.387212 \n",
       "L 133.888365 120.412488 \n",
       "L 134.11666 120.511406 \n",
       "L 134.322126 120.432039 \n",
       "L 134.344956 120.457158 \n",
       "L 134.413445 120.379957 \n",
       "L 134.550422 120.378159 \n",
       "L 134.710229 120.452016 \n",
       "L 134.733058 120.426388 \n",
       "L 134.870036 120.37399 \n",
       "L 134.892865 120.398951 \n",
       "L 135.098331 120.471799 \n",
       "L 135.189649 120.369852 \n",
       "L 135.258138 120.444399 \n",
       "L 135.349456 120.443137 \n",
       "L 135.372286 120.417713 \n",
       "L 135.395115 120.392306 \n",
       "L 135.463604 120.466641 \n",
       "L 135.577752 120.439998 \n",
       "L 135.6919 120.463445 \n",
       "L 135.874536 120.510796 \n",
       "L 135.943025 120.484873 \n",
       "L 135.988684 120.534059 \n",
       "L 136.011513 120.558625 \n",
       "L 136.080002 120.482933 \n",
       "L 136.308298 120.380446 \n",
       "L 136.331127 120.40496 \n",
       "L 136.399616 120.329693 \n",
       "L 136.559423 120.253523 \n",
       "L 136.582252 120.278 \n",
       "L 136.71923 120.325808 \n",
       "L 136.742059 120.300847 \n",
       "L 136.856207 120.274851 \n",
       "L 136.879037 120.299233 \n",
       "L 137.038843 120.37114 \n",
       "L 137.061673 120.346264 \n",
       "L 137.244309 120.294954 \n",
       "L 137.404116 120.366556 \n",
       "L 137.426946 120.34179 \n",
       "L 137.449775 120.317039 \n",
       "L 137.518264 120.389582 \n",
       "L 137.792219 120.532324 \n",
       "L 137.860707 120.506979 \n",
       "L 137.906367 120.555014 \n",
       "L 138.066173 120.576957 \n",
       "L 138.111833 120.527719 \n",
       "L 138.180321 120.59951 \n",
       "L 138.362958 120.645153 \n",
       "L 138.522765 120.618488 \n",
       "L 138.728231 120.784025 \n",
       "L 138.77389 120.735065 \n",
       "L 139.002185 120.635185 \n",
       "L 139.116333 120.609436 \n",
       "L 139.390288 120.461842 \n",
       "L 139.664242 120.648854 \n",
       "L 139.687072 120.624671 \n",
       "L 139.915368 120.478644 \n",
       "L 139.938197 120.50209 \n",
       "L 140.098004 120.523608 \n",
       "L 140.28064 120.473749 \n",
       "L 140.394788 120.495855 \n",
       "L 140.417618 120.471925 \n",
       "L 140.600254 120.422355 \n",
       "L 140.691572 120.421199 \n",
       "L 140.714402 120.397374 \n",
       "L 140.965527 120.276922 \n",
       "L 141.079675 120.34599 \n",
       "L 141.125334 120.298603 \n",
       "L 141.35363 120.202602 \n",
       "L 141.536266 120.294034 \n",
       "L 141.559096 120.270472 \n",
       "L 141.764562 120.198502 \n",
       "L 141.970028 120.266056 \n",
       "L 142.175494 120.148149 \n",
       "L 142.198323 120.171075 \n",
       "L 142.3353 120.215966 \n",
       "L 142.35813 120.19264 \n",
       "L 142.517937 120.168026 \n",
       "L 142.700573 120.212302 \n",
       "L 142.837551 120.164998 \n",
       "L 142.86038 120.187745 \n",
       "L 142.997358 120.232279 \n",
       "L 143.020187 120.209121 \n",
       "L 143.134335 120.230886 \n",
       "L 143.294142 120.252114 \n",
       "L 143.431119 120.205068 \n",
       "L 143.453949 120.227652 \n",
       "L 143.568096 120.203722 \n",
       "L 143.819222 120.087702 \n",
       "L 144.093176 120.22126 \n",
       "L 144.252983 120.197072 \n",
       "L 144.344301 120.15103 \n",
       "L 144.481279 120.149784 \n",
       "L 144.618256 120.148538 \n",
       "L 144.823722 120.079301 \n",
       "L 145.006358 120.122625 \n",
       "L 145.188995 120.076294 \n",
       "L 145.41729 120.163673 \n",
       "L 145.599927 120.117473 \n",
       "L 145.805393 120.182357 \n",
       "L 145.988029 120.136315 \n",
       "L 146.079348 120.091214 \n",
       "L 146.216325 120.090079 \n",
       "L 146.353302 120.088954 \n",
       "L 146.46745 120.110066 \n",
       "L 146.604427 120.10891 \n",
       "L 146.764234 120.085584 \n",
       "L 146.9697 120.149715 \n",
       "L 147.129507 120.126405 \n",
       "L 147.47195 120.31982 \n",
       "L 147.700246 120.230355 \n",
       "L 147.837223 120.229035 \n",
       "L 147.974201 120.227721 \n",
       "L 148.134008 120.24785 \n",
       "L 148.293814 120.224666 \n",
       "L 148.407962 120.201982 \n",
       "L 148.54494 120.200715 \n",
       "L 148.773235 120.284661 \n",
       "L 148.864553 120.326723 \n",
       "L 148.978701 120.304054 \n",
       "L 149.206997 120.216055 \n",
       "L 149.458122 120.320499 \n",
       "L 149.57227 120.340639 \n",
       "L 149.686417 120.318128 \n",
       "L 149.823395 120.316708 \n",
       "L 150.05169 120.39924 \n",
       "L 150.143008 120.440624 \n",
       "L 150.257156 120.418123 \n",
       "L 150.394134 120.416573 \n",
       "L 150.55394 120.435877 \n",
       "L 150.690918 120.4343 \n",
       "L 150.873554 120.474291 \n",
       "L 151.033361 120.451391 \n",
       "L 151.307316 120.573887 \n",
       "L 151.421464 120.593344 \n",
       "L 151.558441 120.591561 \n",
       "L 151.741077 120.547486 \n",
       "L 151.900884 120.566306 \n",
       "L 152.220498 120.396275 \n",
       "L 152.425964 120.456154 \n",
       "L 152.540112 120.475521 \n",
       "L 152.63143 120.433138 \n",
       "L 152.722748 120.473392 \n",
       "L 152.928214 120.532802 \n",
       "L 153.110851 120.489452 \n",
       "L 153.293487 120.528355 \n",
       "L 153.407635 120.54747 \n",
       "L 153.65876 120.646609 \n",
       "L 153.818567 120.624077 \n",
       "L 154.092522 120.742646 \n",
       "L 154.252328 120.720061 \n",
       "L 154.389306 120.718153 \n",
       "L 154.617601 120.633992 \n",
       "L 154.823067 120.691941 \n",
       "L 155.028533 120.628661 \n",
       "L 155.233999 120.686379 \n",
       "L 155.325318 120.725361 \n",
       "L 155.599272 120.841874 \n",
       "L 155.759079 120.819468 \n",
       "L 156.010204 120.915621 \n",
       "L 156.101522 120.954093 \n",
       "L 156.192841 120.912767 \n",
       "L 156.421136 120.829667 \n",
       "L 156.512454 120.788588 \n",
       "L 156.626602 120.806804 \n",
       "L 156.809239 120.843788 \n",
       "L 156.969046 120.82164 \n",
       "L 157.106023 120.819647 \n",
       "L 157.243 120.81766 \n",
       "L 157.402807 120.835045 \n",
       "L 157.539784 120.833042 \n",
       "L 157.653932 120.811725 \n",
       "L 157.882228 120.730034 \n",
       "L 158.019205 120.728178 \n",
       "L 158.201842 120.686631 \n",
       "L 158.430137 120.761651 \n",
       "L 158.704092 120.641189 \n",
       "L 158.978046 120.754138 \n",
       "L 159.115024 120.752272 \n",
       "L 159.29766 120.788467 \n",
       "L 159.457467 120.766934 \n",
       "L 159.685763 120.840876 \n",
       "L 159.799911 120.858482 \n",
       "L 159.936888 120.856494 \n",
       "L 160.34782 120.620828 \n",
       "L 160.461968 120.600309 \n",
       "L 160.827241 120.40537 \n",
       "L 160.964218 120.403987 \n",
       "L 161.078366 120.421851 \n",
       "L 161.283832 120.476677 \n",
       "L 161.489298 120.417661 \n",
       "L 161.694764 120.472288 \n",
       "L 161.831741 120.470831 \n",
       "L 162.128525 120.599468 \n",
       "L 162.333991 120.540683 \n",
       "L 162.539457 120.594642 \n",
       "L 162.722094 120.555066 \n",
       "L 162.90473 120.590384 \n",
       "L 163.224344 120.437596 \n",
       "L 163.384151 120.454582 \n",
       "L 163.475469 120.490824 \n",
       "L 163.635276 120.507689 \n",
       "L 163.772253 120.506212 \n",
       "L 164.069037 120.632467 \n",
       "L 164.228844 120.612106 \n",
       "L 164.43431 120.664993 \n",
       "L 164.708265 120.551381 \n",
       "L 164.890901 120.586068 \n",
       "L 165.096367 120.528781 \n",
       "L 165.210515 120.509245 \n",
       "L 165.530129 120.359885 \n",
       "L 165.781254 120.448589 \n",
       "L 165.918231 120.447216 \n",
       "L 166.146527 120.517509 \n",
       "L 166.283504 120.516059 \n",
       "L 166.466141 120.550309 \n",
       "L 166.603118 120.548821 \n",
       "L 166.740095 120.547333 \n",
       "L 166.899902 120.527582 \n",
       "L 167.082539 120.561627 \n",
       "L 167.219516 120.560129 \n",
       "L 167.310834 120.523224 \n",
       "L 167.424982 120.539957 \n",
       "L 167.676107 120.626763 \n",
       "L 167.881573 120.570817 \n",
       "L 168.087039 120.622074 \n",
       "L 168.360994 120.512226 \n",
       "L 168.452312 120.475731 \n",
       "L 168.634949 120.438405 \n",
       "L 168.726267 120.402058 \n",
       "L 168.886074 120.382853 \n",
       "L 169.09154 120.433995 \n",
       "L 169.205687 120.45056 \n",
       "L 169.479642 120.553584 \n",
       "L 169.753597 120.480384 \n",
       "L 169.890574 120.479022 \n",
       "L 170.141699 120.423985 \n",
       "L 170.301506 120.439967 \n",
       "L 170.438483 120.473597 \n",
       "L 170.62112 120.506685 \n",
       "L 170.758097 120.540141 \n",
       "L 170.895075 120.538717 \n",
       "L 171.12337 120.501622 \n",
       "L 171.328836 120.55157 \n",
       "L 171.534302 120.532119 \n",
       "L 171.716939 120.530253 \n",
       "L 172.059382 120.406174 \n",
       "L 172.333337 120.472419 \n",
       "L 172.515973 120.470653 \n",
       "L 172.858416 120.587124 \n",
       "L 173.223689 120.446806 \n",
       "L 173.520473 120.529096 \n",
       "L 173.771599 120.475642 \n",
       "L 173.999894 120.507347 \n",
       "L 174.273849 120.437033 \n",
       "L 174.456485 120.435351 \n",
       "L 174.684781 120.399555 \n",
       "L 174.867417 120.397936 \n",
       "L 175.141372 120.328384 \n",
       "L 175.278349 120.293724 \n",
       "L 175.438156 120.309196 \n",
       "L 175.575133 120.274646 \n",
       "L 175.73494 120.290102 \n",
       "L 176.100213 120.420437 \n",
       "L 176.374168 120.351537 \n",
       "L 176.579634 120.366404 \n",
       "L 176.7851 120.348114 \n",
       "L 177.013395 120.379273 \n",
       "L 177.241691 120.344334 \n",
       "L 177.538475 120.424169 \n",
       "L 177.81243 120.356068 \n",
       "L 177.972237 120.338346 \n",
       "L 178.200532 120.30376 \n",
       "L 178.383169 120.30233 \n",
       "L 178.634294 120.251441 \n",
       "L 178.771271 120.217843 \n",
       "L 179.090885 120.118083 \n",
       "L 179.387669 120.197266 \n",
       "L 179.547476 120.212354 \n",
       "L 179.752942 120.227074 \n",
       "L 179.958408 120.209473 \n",
       "L 180.118215 120.192246 \n",
       "L 180.414999 120.109835 \n",
       "L 180.597636 120.10871 \n",
       "L 180.780272 120.10759 \n",
       "L 180.91725 120.074728 \n",
       "L 181.145545 120.041424 \n",
       "L 181.533648 120.182678 \n",
       "L 181.647795 120.229676 \n",
       "L 181.830432 120.228394 \n",
       "L 182.013068 120.227111 \n",
       "L 182.150046 120.194438 \n",
       "L 182.469659 120.097381 \n",
       "L 182.720784 120.143244 \n",
       "L 182.94908 120.110287 \n",
       "L 183.200205 120.155956 \n",
       "L 183.656796 119.96499 \n",
       "L 183.839433 119.964102 \n",
       "L 184.044899 119.947479 \n",
       "L 184.318853 120.008551 \n",
       "L 184.50149 120.007605 \n",
       "L 184.638467 119.975789 \n",
       "L 184.866763 119.943615 \n",
       "L 185.049399 119.942763 \n",
       "L 185.277695 119.910753 \n",
       "L 185.483161 119.925299 \n",
       "L 185.711456 119.893425 \n",
       "L 185.916922 119.907951 \n",
       "L 186.213706 119.829835 \n",
       "L 186.487661 119.890139 \n",
       "L 186.715957 119.85857 \n",
       "L 187.104059 119.994399 \n",
       "L 187.378014 119.932118 \n",
       "L 187.994412 120.217396 \n",
       "L 188.222707 120.185622 \n",
       "L 188.58798 120.304038 \n",
       "L 188.747787 120.317959 \n",
       "L 188.953253 120.331502 \n",
       "L 189.13589 120.330151 \n",
       "L 189.364185 120.358471 \n",
       "L 189.523992 120.372244 \n",
       "L 189.729458 120.385629 \n",
       "L 190.026242 120.30867 \n",
       "L 190.208879 120.307356 \n",
       "L 190.368686 120.321103 \n",
       "L 190.688299 120.407935 \n",
       "L 190.802447 120.451575 \n",
       "L 191.030743 120.479343 \n",
       "L 191.281868 120.432859 \n",
       "L 191.510163 120.460564 \n",
       "L 191.715629 120.444125 \n",
       "L 191.852607 120.413555 \n",
       "L 192.058073 120.397232 \n",
       "L 192.309198 120.439341 \n",
       "L 192.560323 120.393357 \n",
       "L 192.811448 120.43532 \n",
       "L 192.994084 120.433869 \n",
       "L 193.176721 120.432418 \n",
       "L 193.382187 120.41622 \n",
       "L 193.564823 120.414801 \n",
       "L 193.793119 120.383973 \n",
       "L 194.067074 120.439898 \n",
       "L 194.27254 120.423796 \n",
       "L 194.455176 120.422371 \n",
       "L 194.706301 120.377128 \n",
       "L 194.888938 120.375772 \n",
       "L 195.071574 120.374416 \n",
       "L 195.29987 120.401469 \n",
       "L 195.482506 120.400086 \n",
       "L 195.756461 120.455307 \n",
       "L 196.076074 120.367029 \n",
       "L 196.235881 120.351589 \n",
       "L 196.464177 120.32145 \n",
       "L 196.692472 120.348319 \n",
       "L 196.852279 120.361394 \n",
       "L 197.012086 120.346043 \n",
       "L 197.171893 120.359091 \n",
       "L 197.582825 120.497538 \n",
       "L 197.742632 120.51036 \n",
       "L 198.062246 120.592287 \n",
       "L 198.244882 120.590683 \n",
       "L 198.473178 120.616796 \n",
       "L 198.632985 120.629402 \n",
       "L 198.929769 120.696772 \n",
       "L 199.249383 120.609904 \n",
       "L 199.454849 120.622047 \n",
       "L 199.568997 120.662869 \n",
       "L 199.728803 120.647476 \n",
       "L 199.91144 120.64582 \n",
       "L 200.116906 120.657859 \n",
       "L 200.322372 120.642119 \n",
       "L 200.619156 120.70868 \n",
       "L 200.847452 120.678888 \n",
       "L 201.144236 120.745133 \n",
       "L 201.326872 120.743372 \n",
       "L 201.486679 120.728079 \n",
       "L 201.669316 120.726344 \n",
       "L 201.851952 120.724614 \n",
       "L 202.103077 120.681132 \n",
       "L 202.308543 120.692945 \n",
       "L 202.46835 120.705142 \n",
       "L 202.719475 120.743755 \n",
       "L 202.924941 120.728173 \n",
       "L 203.176066 120.766629 \n",
       "L 203.427191 120.723463 \n",
       "L 203.586998 120.708406 \n",
       "L 203.792464 120.692966 \n",
       "L 204.157737 120.797762 \n",
       "L 204.317544 120.809701 \n",
       "L 204.52301 120.821156 \n",
       "L 204.659987 120.846737 \n",
       "L 204.819794 120.83167 \n",
       "L 205.185067 120.720655 \n",
       "L 205.413363 120.745359 \n",
       "L 205.595999 120.74365 \n",
       "L 205.801465 120.7551 \n",
       "L 206.029761 120.72626 \n",
       "L 206.303715 120.777038 \n",
       "L 206.440693 120.802357 \n",
       "L 206.646159 120.813665 \n",
       "L 206.942943 120.744444 \n",
       "L 207.171239 120.768827 \n",
       "L 207.582171 120.632851 \n",
       "L 207.924614 120.722222 \n",
       "L 208.061591 120.747325 \n",
       "L 208.244228 120.745643 \n",
       "L 208.495353 120.703938 \n",
       "L 208.700819 120.715225 \n",
       "L 208.837796 120.740207 \n",
       "L 209.043262 120.75142 \n",
       "L 209.271558 120.723189 \n",
       "L 209.499853 120.747236 \n",
       "L 209.728149 120.719099 \n",
       "L 209.865126 120.691846 \n",
       "L 210.024933 120.703449 \n",
       "L 210.321717 120.76573 \n",
       "L 210.504354 120.764053 \n",
       "L 210.68699 120.762376 \n",
       "L 210.983774 120.695048 \n",
       "L 211.257729 120.744271 \n",
       "L 211.486025 120.71645 \n",
       "L 211.759979 120.765478 \n",
       "L 212.011104 120.724677 \n",
       "L 212.2394 120.748297 \n",
       "L 212.467695 120.72065 \n",
       "L 212.787309 120.794497 \n",
       "L 213.061264 120.766466 \n",
       "L 213.198241 120.739744 \n",
       "L 213.632003 120.621543 \n",
       "L 214.020105 120.732489 \n",
       "L 214.27123 120.717633 \n",
       "L 214.636503 120.815489 \n",
       "L 214.933287 120.774935 \n",
       "L 215.207242 120.797641 \n",
       "L 215.526856 120.744502 \n",
       "L 215.800811 120.767176 \n",
       "L 216.143254 120.701593 \n",
       "L 216.32589 120.675055 \n",
       "L 216.485697 120.711177 \n",
       "L 216.691163 120.696967 \n",
       "L 216.919459 120.695048 \n",
       "L 217.170584 120.705373 \n",
       "L 217.558686 120.615308 \n",
       "L 217.764152 120.601308 \n",
       "L 218.038107 120.57446 \n",
       "L 218.449039 120.670003 \n",
       "L 218.722994 120.64315 \n",
       "L 218.996948 120.66555 \n",
       "L 219.270903 120.638791 \n",
       "L 219.750324 120.769584 \n",
       "L 220.161256 120.668389 \n",
       "L 220.503699 120.726528 \n",
       "L 220.754824 120.71226 \n",
       "L 221.028779 120.734271 \n",
       "L 221.234245 120.74467 \n",
       "L 221.439711 120.730823 \n",
       "L 221.622347 120.753486 \n",
       "L 221.941961 120.799071 \n",
       "L 222.147427 120.809333 \n",
       "L 222.581189 120.913771 \n",
       "L 223.060609 120.777343 \n",
       "L 223.357394 120.810721 \n",
       "L 223.813985 120.687331 \n",
       "L 224.04228 120.685512 \n",
       "L 224.476042 120.575017 \n",
       "L 224.704337 120.573351 \n",
       "L 224.955462 120.559666 \n",
       "L 225.229417 120.581378 \n",
       "L 225.480542 120.56772 \n",
       "L 225.754497 120.589359 \n",
       "L 225.937133 120.611602 \n",
       "L 226.188258 120.621506 \n",
       "L 226.416554 120.619792 \n",
       "L 226.895975 120.745196 \n",
       "L 227.1471 120.731433 \n",
       "L 227.352566 120.718079 \n",
       "L 227.67218 120.668831 \n",
       "L 227.946134 120.690027 \n",
       "L 228.197259 120.676427 \n",
       "L 228.516873 120.720424 \n",
       "L 228.790828 120.695048 \n",
       "L 229.110442 120.738861 \n",
       "L 229.384396 120.713543 \n",
       "L 229.567033 120.689008 \n",
       "L 229.909476 120.628745 \n",
       "L 230.411726 120.762928 \n",
       "L 230.913976 120.621369 \n",
       "L 231.096613 120.597144 \n",
       "L 231.370568 120.572331 \n",
       "L 231.598863 120.570733 \n",
       "L 231.73584 120.615392 \n",
       "L 231.941306 120.602517 \n",
       "L 232.306579 120.531709 \n",
       "L 232.489216 120.507768 \n",
       "L 232.740341 120.494772 \n",
       "L 232.922977 120.470926 \n",
       "L 233.28825 120.400775 \n",
       "L 233.425228 120.354775 \n",
       "L 233.676353 120.342063 \n",
       "L 233.973137 120.374184 \n",
       "L 234.247092 120.350107 \n",
       "L 234.498217 120.359922 \n",
       "L 234.772171 120.335939 \n",
       "L 235.068956 120.367871 \n",
       "L 235.34291 120.343956 \n",
       "L 235.548376 120.331644 \n",
       "L 235.913649 120.262791 \n",
       "L 236.164774 120.272638 \n",
       "L 236.461558 120.237783 \n",
       "L 236.598536 120.192713 \n",
       "L 236.804002 120.202833 \n",
       "L 237.123616 120.245579 \n",
       "L 237.39757 120.222111 \n",
       "L 237.625866 120.221007 \n",
       "L 237.831332 120.231038 \n",
       "L 238.036798 120.219025 \n",
       "L 238.196605 120.251262 \n",
       "L 238.516218 120.293598 \n",
       "L 238.744514 120.29241 \n",
       "L 239.041298 120.323721 \n",
       "L 239.315253 120.300385 \n",
       "L 239.566378 120.309995 \n",
       "L 239.771844 120.31982 \n",
       "L 239.954481 120.297057 \n",
       "L 240.159947 120.306877 \n",
       "L 240.433901 120.32718 \n",
       "L 240.753515 120.282079 \n",
       "L 241.050299 120.31307 \n",
       "L 241.438402 120.23537 \n",
       "L 241.598209 120.202197 \n",
       "L 241.803675 120.212033 \n",
       "L 242.0548 120.221633 \n",
       "L 242.305925 120.209689 \n",
       "L 242.625539 120.251168 \n",
       "L 242.808175 120.271744 \n",
       "L 243.173448 120.334188 \n",
       "L 243.493062 120.289734 \n",
       "L 243.698528 120.278016 \n",
       "L 243.903994 120.287657 \n",
       "L 244.132289 120.286511 \n",
       "L 244.337755 120.296126 \n",
       "L 244.58888 120.305484 \n",
       "L 244.840005 120.293587 \n",
       "L 245.13679 120.323895 \n",
       "L 245.524892 120.24784 \n",
       "L 245.730358 120.23629 \n",
       "L 245.958654 120.235217 \n",
       "L 246.14129 120.213269 \n",
       "L 246.460904 120.169703 \n",
       "L 246.712029 120.179124 \n",
       "L 246.985984 120.156928 \n",
       "L 247.19145 120.145568 \n",
       "L 247.419745 120.144611 \n",
       "L 247.67087 120.154016 \n",
       "L 247.876336 120.163594 \n",
       "L 248.058973 120.141935 \n",
       "L 248.401416 120.088407 \n",
       "L 248.675371 120.108158 \n",
       "L 248.972155 120.075811 \n",
       "L 249.383087 120.157191 \n",
       "L 249.565723 120.177137 \n",
       "L 249.953826 120.247829 \n",
       "L 250.25061 120.215482 \n",
       "L 250.570224 120.255263 \n",
       "L 250.77569 120.264594 \n",
       "L 251.026815 120.273689 \n",
       "L 251.163792 120.314132 \n",
       "L 251.323599 120.282537 \n",
       "L 251.78019 120.17793 \n",
       "L 252.008486 120.176958 \n",
       "L 252.30527 120.145052 \n",
       "L 252.556395 120.154226 \n",
       "L 252.967327 120.07109 \n",
       "L 253.149964 120.050072 \n",
       "L 253.446748 120.01854 \n",
       "L 253.697873 120.027824 \n",
       "L 253.948998 120.01682 \n",
       "L 254.38276 120.106313 \n",
       "L 254.679544 120.095078 \n",
       "L 255.044817 120.133991 \n",
       "L 255.478578 120.0619 \n",
       "L 255.843851 120.100719 \n",
       "L 256.072147 120.119897 \n",
       "L 256.346101 120.118835 \n",
       "L 256.688545 120.087529 \n",
       "L 257.053818 120.126069 \n",
       "L 257.259284 120.155162 \n",
       "L 257.46475 120.124471 \n",
       "L 257.898511 120.053258 \n",
       "L 258.263784 120.091635 \n",
       "L 258.560568 120.080631 \n",
       "L 258.743205 120.040404 \n",
       "L 259.245455 119.940003 \n",
       "L 259.565069 119.958766 \n",
       "L 260.067319 119.85897 \n",
       "L 260.478251 119.916777 \n",
       "L 260.797865 119.89629 \n",
       "L 261.094649 119.905264 \n",
       "L 261.505581 119.84558 \n",
       "L 261.733877 119.825524 \n",
       "L 261.985002 119.834671 \n",
       "L 262.464422 119.920946 \n",
       "L 262.784036 119.900648 \n",
       "L 263.217798 119.967225 \n",
       "L 263.537412 119.946932 \n",
       "L 263.948344 120.003604 \n",
       "L 264.222298 120.002731 \n",
       "L 264.701719 120.087702 \n",
       "L 264.998503 120.077046 \n",
       "L 265.249628 120.066574 \n",
       "L 265.592072 120.036682 \n",
       "L 265.934515 120.064208 \n",
       "L 266.231299 120.053647 \n",
       "L 266.68789 120.128261 \n",
       "L 267.030334 120.098469 \n",
       "L 267.304288 120.097486 \n",
       "L 267.760879 120.020085 \n",
       "L 268.126152 120.056738 \n",
       "L 268.514255 120.008236 \n",
       "L 268.833868 120.026084 \n",
       "L 269.039334 120.053668 \n",
       "L 269.313289 120.052753 \n",
       "L 269.610073 120.042375 \n",
       "L 269.952517 120.069376 \n",
       "L 270.386278 120.002411 \n",
       "L 270.705892 120.020106 \n",
       "L 271.162483 119.944088 \n",
       "L 271.550586 119.989531 \n",
       "L 271.801711 119.998068 \n",
       "L 272.189813 120.04328 \n",
       "L 272.463768 120.042391 \n",
       "L 272.943188 120.124055 \n",
       "L 273.194314 120.132388 \n",
       "L 273.513927 120.149668 \n",
       "L 273.787882 120.148653 \n",
       "L 274.153155 120.184081 \n",
       "L 274.472769 120.164483 \n",
       "L 274.838042 120.199774 \n",
       "L 275.089167 120.207949 \n",
       "L 275.40878 120.224971 \n",
       "L 275.796883 120.177778 \n",
       "L 276.253474 120.248907 \n",
       "L 276.687236 120.183492 \n",
       "L 276.915531 120.164462 \n",
       "L 277.212315 120.154289 \n",
       "L 277.668906 120.225013 \n",
       "L 278.034179 120.18742 \n",
       "L 278.285304 120.177436 \n",
       "L 278.627748 120.149116 \n",
       "L 278.993021 120.183782 \n",
       "L 279.221316 120.200894 \n",
       "L 279.56376 120.226496 \n",
       "L 279.974692 120.171128 \n",
       "L 280.248646 120.170118 \n",
       "L 280.613919 120.13304 \n",
       "L 280.865044 120.123235 \n",
       "L 281.390124 120.023502 \n",
       "L 281.778227 120.066758 \n",
       "L 282.166329 120.021158 \n",
       "L 282.62292 120.09061 \n",
       "L 282.805557 120.125391 \n",
       "L 283.033852 120.106928 \n",
       "L 283.307807 120.106002 \n",
       "L 283.467614 120.096645 \n",
       "L 283.467614 120.096645 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_27\">\n",
       "    <path d=\"M 43.78125 119.338125 \n",
       "L 294.88125 119.338125 \n",
       "\" clip-path=\"url(#p78e0a95d05)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 216.358125 \n",
       "L 43.78125 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 294.88125 216.358125 \n",
       "L 294.88125 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 216.358125 \n",
       "L 294.88125 216.358125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 22.318125 \n",
       "L 294.88125 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Coin Flip Probability Convergence -->\n",
       "    <g transform=\"translate(68.409375 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-46\" d=\"M 628 4666 \n",
       "L 3309 4666 \n",
       "L 3309 4134 \n",
       "L 1259 4134 \n",
       "L 1259 2759 \n",
       "L 3109 2759 \n",
       "L 3109 2228 \n",
       "L 1259 2228 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \n",
       "L 1259 2394 \n",
       "L 2053 2394 \n",
       "Q 2494 2394 2734 2622 \n",
       "Q 2975 2850 2975 3272 \n",
       "Q 2975 3691 2734 3919 \n",
       "Q 2494 4147 2053 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 2053 4666 \n",
       "Q 2838 4666 3239 4311 \n",
       "Q 3641 3956 3641 3272 \n",
       "Q 3641 2581 3239 2228 \n",
       "Q 2838 1875 2053 1875 \n",
       "L 1259 1875 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"69.824219\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"131.005859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"158.789062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"222.167969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-46\" x=\"253.955078\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"311.474609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"339.257812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-70\" x=\"367.041016\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"430.517578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-50\" x=\"462.304688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"520.857422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"559.720703\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"620.902344\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"684.378906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"745.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"809.134766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"836.917969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"864.701172\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"892.484375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-79\" x=\"931.693359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"990.873047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-43\" x=\"1022.660156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1092.484375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"1153.666016\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"1217.044922\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"1276.224609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"1337.748047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"1377.111328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"1440.587891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"1502.111328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"1565.490234\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"1620.470703\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 182.759375 59.674375 \n",
       "L 287.88125 59.674375 \n",
       "Q 289.88125 59.674375 289.88125 57.674375 \n",
       "L 289.88125 29.318125 \n",
       "Q 289.88125 27.318125 287.88125 27.318125 \n",
       "L 182.759375 27.318125 \n",
       "Q 180.759375 27.318125 180.759375 29.318125 \n",
       "L 180.759375 57.674375 \n",
       "Q 180.759375 59.674375 182.759375 59.674375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_28\">\n",
       "     <path d=\"M 184.759375 35.416562 \n",
       "L 194.759375 35.416562 \n",
       "L 204.759375 35.416562 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- P(coin=heads) -->\n",
       "     <g transform=\"translate(212.759375 38.916562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \n",
       "L 4684 2906 \n",
       "L 4684 2381 \n",
       "L 678 2381 \n",
       "L 678 2906 \n",
       "z\n",
       "M 678 1631 \n",
       "L 4684 1631 \n",
       "L 4684 1100 \n",
       "L 678 1100 \n",
       "L 678 1631 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"390.429688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"453.808594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"515.332031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"576.611328\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"640.087891\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" x=\"692.1875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_29\">\n",
       "     <path d=\"M 184.759375 50.094687 \n",
       "L 194.759375 50.094687 \n",
       "L 204.759375 50.094687 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- P(coin=tails) -->\n",
       "     <g transform=\"translate(212.759375 53.594687) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"390.429688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"429.638672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"490.917969\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"518.701172\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"546.484375\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" x=\"598.583984\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p78e0a95d05\">\n",
       "   <rect x=\"43.78125\" y=\"22.318125\" width=\"251.1\" height=\"194.04\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 450x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the probability convergence plot\n",
    "plt.figure(figsize=(4.5, 3.5))\n",
    "plt.plot(estimates[:, 0], label=\"P(coin=heads)\")\n",
    "plt.plot(estimates[:, 1], label=\"P(coin=tails)\")\n",
    "plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Estimated probability')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.title('Coin Flip Probability Convergence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59058d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ KEY DIFFERENCES SUMMARY:\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ EXPERIMENT STRUCTURE:\n",
      "   Method 1: ONE big experiment (100,000 flips)\n",
      "   Method 2: Many small experiments (10,000 √ó 1 flip each)\n",
      "\n",
      "2Ô∏è‚É£ OUTPUT FORMAT:\n",
      "   Method 1: Single vector [total_heads, total_tails]\n",
      "   Method 2: Matrix where each row is one coin flip result\n",
      "\n",
      "3Ô∏è‚É£ INFORMATION CONTENT:\n",
      "   Method 1: Only final totals (aggregated result)\n",
      "   Method 2: Individual flip results (detailed history)\n",
      "\n",
      "4Ô∏è‚É£ USE CASES:\n",
      "   Method 1: When you only need final statistics\n",
      "   Method 2: When you need to analyze the process over time\n",
      "\n",
      "üí° ANALOGY:\n",
      "Method 1: 'Tell me the final score of 100,000 coin flips'\n",
      "Method 2: 'Give me the result of each individual coin flip (10,000 times)'\n",
      "\n",
      "üîÑ RELATIONSHIP:\n",
      "method2.sum(dim=0) ‚âà method1 (if same total number of flips)\n",
      "Method 1 total flips: 100000.0\n",
      "Method 2 total flips: 10000.0\n",
      "They're different experiments, so results will vary!\n"
     ]
    }
   ],
   "source": [
    "# fair_probs = torch.tensor([0.5, 0.5])\n",
    "print(\"Method 1: Multinomial(100000, fair_probs).sample()\")\n",
    "print(\"Method 2: Multinomial(1, fair_probs).sample((10000,))\")\n",
    "\n",
    "print(\"1. EXPERIMENT STRUCTURE:\")\n",
    "print(\"   Method 1: ONE big experiment (100,000 flips)\")\n",
    "print(\"   Method 2: Many small experiments (10,000 * 1 flip each)\")\n",
    "\n",
    "print(\"2. OUTPUT FORMAT:\")\n",
    "print(\"   Method 1: Single vector [total_heads, total_tails]\")\n",
    "print(\"   Method 2: Matrix where each row is one coin flip result\")\n",
    "\n",
    "print(\"3. INFORMATION CONTENT:\")\n",
    "print(\"   Method 1: Only final totals (aggregated result)\")\n",
    "print(\"   Method 2: Individual flip results (detailed history)\")\n",
    "\n",
    "print(\"4. USE CASES:\")\n",
    "print(\"   Method 1: When you only need final statistics\")\n",
    "print(\"   Method 2: When you need to analyze the process over time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1a3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéØ WHAT IS A COVARIANCE MATRIX?\n",
      "================================================================================\n",
      "üîç DEFINITION:\n",
      "A covariance matrix measures how different variables change together.\n",
      "‚Ä¢ Diagonal elements: Variance of each variable (spread)\n",
      "‚Ä¢ Off-diagonal elements: Covariance between pairs of variables (relationship)\n",
      "\n",
      "üìä MATHEMATICAL FORM:\n",
      "For variables X‚ÇÅ, X‚ÇÇ, ..., X‚Çô, the covariance matrix C is:\n",
      "    ‚îå                           ‚îê\n",
      "    ‚îÇ Var(X‚ÇÅ)   Cov(X‚ÇÅ,X‚ÇÇ) ... ‚îÇ\n",
      "C = ‚îÇ Cov(X‚ÇÇ,X‚ÇÅ) Var(X‚ÇÇ)  ... ‚îÇ\n",
      "    ‚îÇ    ...       ...     ... ‚îÇ\n",
      "    ‚îî                           ‚îò\n",
      "\n",
      "üí° KEY INSIGHTS:\n",
      "‚Ä¢ Symmetric: C[i,j] = C[j,i]\n",
      "‚Ä¢ Diagonal = variance (how much each variable spreads)\n",
      "‚Ä¢ Off-diagonal = covariance (how variables move together)\n",
      "\n",
      "============================================================\n",
      "üî¨ PRACTICAL EXAMPLE: Height, Weight, and Age Data\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# UNDERSTANDING COVARIANCE MATRIX: \"How Variables Dance Together\"\n",
    "print(\"=\"*80)\n",
    "print(\"üéØ WHAT IS A COVARIANCE MATRIX?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"üîç DEFINITION:\")\n",
    "print(\"A covariance matrix measures how different variables change together.\")\n",
    "print(\"‚Ä¢ Diagonal elements: Variance of each variable (spread)\")\n",
    "print(\"‚Ä¢ Off-diagonal elements: Covariance between pairs of variables (relationship)\")\n",
    "\n",
    "print(\"\\nüìä MATHEMATICAL FORM:\")\n",
    "print(\"For variables X‚ÇÅ, X‚ÇÇ, ..., X‚Çô, the covariance matrix C is:\")\n",
    "print(\"    ‚îå                           ‚îê\")\n",
    "print(\"    ‚îÇ Var(X‚ÇÅ)   Cov(X‚ÇÅ,X‚ÇÇ) ... ‚îÇ\")\n",
    "print(\"C = ‚îÇ Cov(X‚ÇÇ,X‚ÇÅ) Var(X‚ÇÇ)  ... ‚îÇ\")\n",
    "print(\"    ‚îÇ    ...       ...     ... ‚îÇ\")\n",
    "print(\"    ‚îî                           ‚îò\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"‚Ä¢ Symmetric: C[i,j] = C[j,i]\")\n",
    "print(\"‚Ä¢ Diagonal = variance (how much each variable spreads)\")\n",
    "print(\"‚Ä¢ Off-diagonal = covariance (how variables move together)\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create sample data to demonstrate\n",
    "torch.manual_seed(42)  # For reproducible results\n",
    "n_samples = 1000\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî¨ PRACTICAL EXAMPLE: Height, Weight, and Age Data\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b28f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([1000, 3])\n",
      "Variables: [Height(cm), Weight(kg), Age(years)]\n",
      "\n",
      "First 5 samples:\n",
      "Person 1: Height=189.3cm, Weight=208.8kg, Age=43years\n",
      "Person 2: Height=184.9cm, Weight=200.5kg, Age=48years\n",
      "Person 3: Height=179.0cm, Weight=207.9kg, Age=69years\n",
      "Person 4: Height=148.9cm, Weight=115.8kg, Age=42years\n",
      "Person 5: Height=176.8cm, Weight=177.2kg, Age=60years\n",
      "\n",
      "Data statistics:\n",
      "Height - Mean: 170.0, Std: 10.0\n",
      "Weight - Mean: 175.3, Std: 29.5\n",
      "Age    - Mean: 43.0, Std: 15.3\n"
     ]
    }
   ],
   "source": [
    "# Generate correlated data to show relationships\n",
    "# Let's simulate: Height, Weight, Age for 1000 people\n",
    "\n",
    "# Start with independent random variables\n",
    "height_base = torch.randn(n_samples) * 10 + 170  # Average 170cm, std 10cm\n",
    "age = torch.randint(18, 70, (n_samples,)).float()  # Age between 18-70\n",
    "\n",
    "# Make weight correlated with height (taller people tend to be heavier)\n",
    "weight = 2.5 * height_base + torch.randn(n_samples) * 15 + (-250)  # Some correlation + noise\n",
    "\n",
    "# Stack into data matrix (each column is a variable)\n",
    "data = torch.stack([height_base, weight, age], dim=1)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Variables: [Height(cm), Weight(kg), Age(years)]\")\n",
    "\n",
    "print(f\"\\nFirst 5 samples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Person {i+1}: Height={data[i,0]:.1f}cm, Weight={data[i,1]:.1f}kg, Age={data[i,2]:.0f}years\")\n",
    "\n",
    "print(f\"\\nData statistics:\")\n",
    "print(f\"Height - Mean: {data[:,0].mean():.1f}, Std: {data[:,0].std():.1f}\")\n",
    "print(f\"Weight - Mean: {data[:,1].mean():.1f}, Std: {data[:,1].std():.1f}\")\n",
    "print(f\"Age    - Mean: {data[:,2].mean():.1f}, Std: {data[:,2].std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üßÆ CALCULATING COVARIANCE MATRIX\n",
      "============================================================\n",
      "üìù METHOD 1: Manual calculation\n",
      "Centered data shape: torch.Size([1000, 3])\n",
      "\n",
      "Covariance Matrix (manual calculation):\n",
      "tensor([[ 1.0069e+02,  2.5523e+02, -4.5648e-01],\n",
      "        [ 2.5523e+02,  8.7283e+02, -3.3532e+00],\n",
      "        [-4.5648e-01, -3.3532e+00,  2.3311e+02]])\n",
      "\n",
      "üîç INTERPRETING THE MATRIX:\n",
      "[0,0] = Variance of Height = 100.69\n",
      "[1,1] = Variance of Weight = 872.83\n",
      "[2,2] = Variance of Age = 233.11\n",
      "[0,1] = Covariance(Height,Weight) = 255.23\n",
      "[0,2] = Covariance(Height,Age) = -0.46\n",
      "[1,2] = Covariance(Weight,Age) = -3.35\n",
      "\n",
      "üìù METHOD 2: Using NumPy's built-in function\n",
      "Covariance Matrix (NumPy):\n",
      "[[ 1.00693431e+02  2.55229377e+02 -4.56483287e-01]\n",
      " [ 2.55229377e+02  8.72828428e+02 -3.35317601e+00]\n",
      " [-4.56483287e-01 -3.35317601e+00  2.33115490e+02]]\n",
      "\n",
      "‚úÖ VERIFICATION: Manual vs NumPy\n",
      "Matrices are close: True\n"
     ]
    }
   ],
   "source": [
    "# üìä COMPUTING THE COVARIANCE MATRIX\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üßÆ CALCULATING COVARIANCE MATRIX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Method 1: Manual calculation (educational)\n",
    "print(\"üìù METHOD 1: Manual calculation\")\n",
    "\n",
    "# Center the data (subtract mean from each variable)\n",
    "data_centered = data - data.mean(dim=0)\n",
    "print(f\"Centered data shape: {data_centered.shape}\")\n",
    "\n",
    "# Covariance matrix = (X^T @ X) / (n-1)\n",
    "cov_matrix_manual = (data_centered.T @ data_centered) / (n_samples - 1)\n",
    "print(f\"\\nCovariance Matrix (manual calculation):\")\n",
    "print(cov_matrix_manual)\n",
    "\n",
    "print(f\"\\nüîç INTERPRETING THE MATRIX:\")\n",
    "print(f\"[0,0] = Variance of Height = {cov_matrix_manual[0,0]:.2f}\")\n",
    "print(f\"[1,1] = Variance of Weight = {cov_matrix_manual[1,1]:.2f}\")  \n",
    "print(f\"[2,2] = Variance of Age = {cov_matrix_manual[2,2]:.2f}\")\n",
    "print(f\"[0,1] = Covariance(Height,Weight) = {cov_matrix_manual[0,1]:.2f}\")\n",
    "print(f\"[0,2] = Covariance(Height,Age) = {cov_matrix_manual[0,2]:.2f}\")\n",
    "print(f\"[1,2] = Covariance(Weight,Age) = {cov_matrix_manual[1,2]:.2f}\")\n",
    "\n",
    "# Method 2: Using NumPy (built-in function)\n",
    "print(f\"\\nüìù METHOD 2: Using NumPy's built-in function\")\n",
    "data_np = data.numpy()\n",
    "cov_matrix_numpy = np.cov(data_np.T)  # Note: transpose needed for np.cov\n",
    "print(f\"Covariance Matrix (NumPy):\")\n",
    "print(cov_matrix_numpy)\n",
    "\n",
    "print(f\"\\n‚úÖ VERIFICATION: Manual vs NumPy\")\n",
    "print(f\"Matrices are close: {torch.allclose(cov_matrix_manual, torch.tensor(cov_matrix_numpy, dtype=torch.float32))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ac8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç WHAT DO THE COVARIANCE VALUES MEAN?\n",
      "======================================================================\n",
      "üìä COVARIANCE INTERPRETATION:\n",
      "Height-Weight covariance: 255.23\n",
      "   ‚úÖ POSITIVE: As height increases, weight tends to increase\n",
      "\n",
      "Height-Age covariance: -0.46\n",
      "   ‚ö™ NEAR ZERO: Little to no linear relationship (as expected)\n",
      "\n",
      "Weight-Age covariance: -3.35\n",
      "   ‚ö™ NEAR ZERO: Little to no linear relationship (as expected)\n",
      "\n",
      "üí° MAGNITUDE INTERPRETATION:\n",
      "‚Ä¢ Large positive: Strong positive relationship\n",
      "‚Ä¢ Large negative: Strong negative relationship\n",
      "‚Ä¢ Near zero: Weak/no linear relationship\n",
      "‚Ä¢ Magnitude depends on units! (cm√ókg vs m√óg gives different values)\n",
      "\n",
      "üéØ KEY INSIGHT:\n",
      "Covariance magnitude is hard to interpret because it depends on units.\n",
      "That's why we often use CORRELATION instead (normalized covariance).\n"
     ]
    }
   ],
   "source": [
    "# üéØ UNDERSTANDING COVARIANCE VALUES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç WHAT DO THE COVARIANCE VALUES MEAN?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cov_hw = cov_matrix_manual[0,1].item()  # Height-Weight covariance\n",
    "cov_ha = cov_matrix_manual[0,2].item()  # Height-Age covariance  \n",
    "cov_wa = cov_matrix_manual[1,2].item()  # Weight-Age covariance\n",
    "\n",
    "print(\"üìä COVARIANCE INTERPRETATION:\")\n",
    "print(f\"Height-Weight covariance: {cov_hw:.2f}\")\n",
    "if cov_hw > 0:\n",
    "    print(\"   ‚úÖ POSITIVE: As height increases, weight tends to increase\")\n",
    "elif cov_hw < 0:\n",
    "    print(\"   ‚ùå NEGATIVE: As height increases, weight tends to decrease\")\n",
    "else:\n",
    "    print(\"   ‚ö™ ZERO: No linear relationship\")\n",
    "\n",
    "print(f\"\\nHeight-Age covariance: {cov_ha:.2f}\")\n",
    "if abs(cov_ha) < 10:\n",
    "    print(\"   ‚ö™ NEAR ZERO: Little to no linear relationship (as expected)\")\n",
    "\n",
    "print(f\"\\nWeight-Age covariance: {cov_wa:.2f}\")\n",
    "if abs(cov_wa) < 20:\n",
    "    print(\"   ‚ö™ NEAR ZERO: Little to no linear relationship (as expected)\")\n",
    "\n",
    "print(\"\\nüí° MAGNITUDE INTERPRETATION:\")\n",
    "print(\"‚Ä¢ Large positive: Strong positive relationship\")\n",
    "print(\"‚Ä¢ Large negative: Strong negative relationship\") \n",
    "print(\"‚Ä¢ Near zero: Weak/no linear relationship\")\n",
    "print(\"‚Ä¢ Magnitude depends on units! (cm√ókg vs m√óg gives different values)\")\n",
    "\n",
    "print(\"\\nüéØ KEY INSIGHT:\")\n",
    "print(\"Covariance magnitude is hard to interpret because it depends on units.\")\n",
    "print(\"That's why we often use CORRELATION instead (normalized covariance).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a236174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ FROM COVARIANCE TO CORRELATION\n",
      "======================================================================\n",
      "Standard deviations: tensor([10.0346, 29.5437, 15.2681])\n",
      "\n",
      "Correlation Matrix:\n",
      "tensor([[ 1.0000,  0.8609, -0.0030],\n",
      "        [ 0.8609,  1.0000, -0.0074],\n",
      "        [-0.0030, -0.0074,  1.0000]])\n",
      "\n",
      "üîç INTERPRETING CORRELATIONS:\n",
      "Height-Weight correlation: 0.861\n",
      "   üí™ STRONG positive correlation\n",
      "Height-Age correlation: -0.003\n",
      "Weight-Age correlation: -0.007\n",
      "\n",
      "üìä CORRELATION RANGE:\n",
      "‚Ä¢ Correlation values always range from -1 to +1\n",
      "‚Ä¢ +1: Perfect positive correlation\n",
      "‚Ä¢ -1: Perfect negative correlation\n",
      "‚Ä¢ 0: No linear correlation\n",
      "‚Ä¢ Unlike covariance, correlation is unit-free!\n"
     ]
    }
   ],
   "source": [
    "# üìà CORRELATION MATRIX: The Normalized Version\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ FROM COVARIANCE TO CORRELATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate correlation matrix: Corr(X,Y) = Cov(X,Y) / (std(X) * std(Y))\n",
    "std_devs = torch.sqrt(torch.diag(cov_matrix_manual))  # Standard deviations\n",
    "print(f\"Standard deviations: {std_devs}\")\n",
    "\n",
    "# Create correlation matrix\n",
    "correlation_matrix = torch.zeros_like(cov_matrix_manual)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        correlation_matrix[i,j] = cov_matrix_manual[i,j] / (std_devs[i] * std_devs[j])\n",
    "\n",
    "print(f\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "print(f\"\\nüîç INTERPRETING CORRELATIONS:\")\n",
    "print(f\"Height-Weight correlation: {correlation_matrix[0,1]:.3f}\")\n",
    "if correlation_matrix[0,1] > 0.7:\n",
    "    print(\"   üí™ STRONG positive correlation\")\n",
    "elif correlation_matrix[0,1] > 0.3:\n",
    "    print(\"   üëç MODERATE positive correlation\")\n",
    "elif correlation_matrix[0,1] > 0:\n",
    "    print(\"   ü§è WEAK positive correlation\")\n",
    "\n",
    "print(f\"Height-Age correlation: {correlation_matrix[0,2]:.3f}\")\n",
    "print(f\"Weight-Age correlation: {correlation_matrix[1,2]:.3f}\")\n",
    "\n",
    "print(f\"\\nüìä CORRELATION RANGE:\")\n",
    "print(\"‚Ä¢ Correlation values always range from -1 to +1\")\n",
    "print(\"‚Ä¢ +1: Perfect positive correlation\")\n",
    "print(\"‚Ä¢ -1: Perfect negative correlation\")  \n",
    "print(\"‚Ä¢ 0: No linear correlation\")\n",
    "print(\"‚Ä¢ Unlike covariance, correlation is unit-free!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä VISUAL REPRESENTATION\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VISUAL INTERPRETATION:\n",
      "‚Ä¢ Darker red: Strong positive relationship\n",
      "‚Ä¢ Darker blue: Strong negative relationship\n",
      "‚Ä¢ White/light: Weak relationship\n",
      "‚Ä¢ Diagonal is always strongest (variable with itself)\n"
     ]
    }
   ],
   "source": [
    "# üé® VISUALIZING THE COVARIANCE MATRIX\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä VISUAL REPRESENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create a heatmap to visualize the covariance matrix\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Covariance Matrix Heatmap\n",
    "im1 = ax1.imshow(cov_matrix_manual.numpy(), cmap='RdBu', aspect='auto')\n",
    "ax1.set_title('Covariance Matrix')\n",
    "ax1.set_xticks([0, 1, 2])\n",
    "ax1.set_yticks([0, 1, 2])\n",
    "ax1.set_xticklabels(['Height', 'Weight', 'Age'])\n",
    "ax1.set_yticklabels(['Height', 'Weight', 'Age'])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = ax1.text(j, i, f'{cov_matrix_manual[i, j]:.1f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im1, ax=ax1, label='Covariance')\n",
    "\n",
    "# Plot 2: Correlation Matrix Heatmap  \n",
    "im2 = ax2.imshow(correlation_matrix.numpy(), cmap='RdBu', vmin=-1, vmax=1, aspect='auto')\n",
    "ax2.set_title('Correlation Matrix')\n",
    "ax2.set_xticks([0, 1, 2])\n",
    "ax2.set_yticks([0, 1, 2])\n",
    "ax2.set_xticklabels(['Height', 'Weight', 'Age'])\n",
    "ax2.set_yticklabels(['Height', 'Weight', 'Age'])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = ax2.text(j, i, f'{correlation_matrix[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im2, ax=ax2, label='Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç VISUAL INTERPRETATION:\")\n",
    "print(\"‚Ä¢ Darker red: Strong positive relationship\")\n",
    "print(\"‚Ä¢ Darker blue: Strong negative relationship\")\n",
    "print(\"‚Ä¢ White/light: Weak relationship\")\n",
    "print(\"‚Ä¢ Diagonal is always strongest (variable with itself)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b198dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üåç WHERE ARE COVARIANCE MATRICES USED?\n",
      "================================================================================\n",
      "1Ô∏è‚É£ MACHINE LEARNING:\n",
      "   ‚Ä¢ Principal Component Analysis (PCA) - dimensionality reduction\n",
      "   ‚Ä¢ Gaussian distributions - modeling data probability\n",
      "   ‚Ä¢ Feature correlation analysis - understanding relationships\n",
      "\n",
      "2Ô∏è‚É£ FINANCE:\n",
      "   ‚Ä¢ Portfolio optimization - balancing risk and return\n",
      "   ‚Ä¢ Risk management - understanding asset correlations\n",
      "   ‚Ä¢ Market analysis - how stocks move together\n",
      "\n",
      "3Ô∏è‚É£ STATISTICS:\n",
      "   ‚Ä¢ Multivariate analysis - studying multiple variables\n",
      "   ‚Ä¢ Hypothesis testing - comparing groups of variables\n",
      "   ‚Ä¢ Regression analysis - understanding variable relationships\n",
      "\n",
      "4Ô∏è‚É£ COMPUTER VISION:\n",
      "   ‚Ä¢ Image processing - pixel correlation patterns\n",
      "   ‚Ä¢ Feature detection - understanding visual relationships\n",
      "   ‚Ä¢ Pattern recognition - identifying similar structures\n",
      "\n",
      "5Ô∏è‚É£ SIGNAL PROCESSING:\n",
      "   ‚Ä¢ Noise reduction - understanding signal correlations\n",
      "   ‚Ä¢ Data compression - removing redundant information\n",
      "   ‚Ä¢ Communication systems - optimizing data transmission\n",
      "\n",
      "üîë KEY TAKEAWAY:\n",
      "Covariance matrices help us understand how multiple variables\n",
      "relate to each other, which is fundamental in data science!\n"
     ]
    }
   ],
   "source": [
    "# üéØ REAL-WORLD APPLICATIONS OF COVARIANCE MATRICES\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üåç WHERE ARE COVARIANCE MATRICES USED?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"1Ô∏è‚É£ MACHINE LEARNING:\")\n",
    "print(\"   ‚Ä¢ Principal Component Analysis (PCA) - dimensionality reduction\")\n",
    "print(\"   ‚Ä¢ Gaussian distributions - modeling data probability\")\n",
    "print(\"   ‚Ä¢ Feature correlation analysis - understanding relationships\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ FINANCE:\")\n",
    "print(\"   ‚Ä¢ Portfolio optimization - balancing risk and return\")\n",
    "print(\"   ‚Ä¢ Risk management - understanding asset correlations\")\n",
    "print(\"   ‚Ä¢ Market analysis - how stocks move together\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ STATISTICS:\")\n",
    "print(\"   ‚Ä¢ Multivariate analysis - studying multiple variables\")\n",
    "print(\"   ‚Ä¢ Hypothesis testing - comparing groups of variables\")\n",
    "print(\"   ‚Ä¢ Regression analysis - understanding variable relationships\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ COMPUTER VISION:\")\n",
    "print(\"   ‚Ä¢ Image processing - pixel correlation patterns\")\n",
    "print(\"   ‚Ä¢ Feature detection - understanding visual relationships\")\n",
    "print(\"   ‚Ä¢ Pattern recognition - identifying similar structures\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ SIGNAL PROCESSING:\")\n",
    "print(\"   ‚Ä¢ Noise reduction - understanding signal correlations\")\n",
    "print(\"   ‚Ä¢ Data compression - removing redundant information\")\n",
    "print(\"   ‚Ä¢ Communication systems - optimizing data transmission\")\n",
    "\n",
    "print(\"\\nüîë KEY TAKEAWAY:\")\n",
    "print(\"Covariance matrices help us understand how multiple variables\")\n",
    "print(\"relate to each other, which is fundamental in data science!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5afdab",
   "metadata": {},
   "source": [
    "### =======================loopup-api.md===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa898535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.pytorch.org/docs/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17057cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'CumulativeDistributionTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'GeneralizedPareto', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'InverseGamma', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PositiveDefiniteTransform', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'SoftplusTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'generalized_pareto', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'inverse_gamma', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n"
     ]
    }
   ],
   "source": [
    "# To know which functions and classes can be called in a module\n",
    "print(dir(torch.distributions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd84a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function ones in module torch:\n",
      "\n",
      "ones(...)\n",
      "    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "\n",
      "    Returns a tensor filled with the scalar value `1`, with the shape defined\n",
      "    by the variable argument :attr:`size`.\n",
      "\n",
      "    Args:\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "            Can be a variable number of arguments or a collection like a list or tuple.\n",
      "\n",
      "    Keyword arguments:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_dtype`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_device`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.ones(2, 3)\n",
      "        tensor([[ 1.,  1.,  1.],\n",
      "                [ 1.,  1.,  1.]])\n",
      "\n",
      "        >>> torch.ones(5)\n",
      "        tensor([ 1.,  1.,  1.,  1.,  1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78541cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33727356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
