{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad96b6b",
   "metadata": {},
   "source": [
    "================================================Word Embedding (word2vec)======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b5728",
   "metadata": {},
   "source": [
    "Word vectors are vectors used to represent words, and can also be considered as feature vectors or representations of words. The technique of mapping words to real vectors is called word embedding.\n",
    "\n",
    "The word2vec tool contains both the skip-gram and continuous bag of words models.\n",
    "\n",
    "The skip-gram model assumes that a word can be used to generate its surrounding words in a text sequence; while the continuous bag of words model assumes that a center word is generated based on its surrounding context words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775b128",
   "metadata": {},
   "source": [
    "#### The Skip-Gram Model\n",
    "\n",
    "##### Overview\n",
    "\n",
    "The **Skip-Gram model** learns word representations by predicting the **surrounding context words** given **a center word** in a sentence.\n",
    "The Skip-Gram model forms the basis of **Word2Vec**, producing dense word vectors that capture semantic similarity through context prediction.\n",
    "\n",
    "Example: For the sequence *\"the man loves his son\"*, if we choose *\"loves\"* as the center word and set the context window size to 2, the model predicts: *\"the\"*, *\"man\"*, *\"his\"*, *\"son\"*.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1Ô∏è‚É£ Conditional Probability of Context Words\n",
    "\n",
    "The model assumes **context words are conditionally independent** given the center word. Thus, the joint probability can be written as:\n",
    "\n",
    "$$\n",
    "P(w_{t-2}, w_{t-1}, w_{t+1}, w_{t+2} | w_t) = \\prod_{-m \\le j \\le m, j \\ne 0} P(w_{t+j} | w_t)\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 2Ô∏è‚É£ Probability Model (Softmax)\n",
    "\n",
    "Each word is represented by two vectors:\n",
    "\n",
    "-   $\\mathbf{v}_w$: center (input) word vector\n",
    "-   $\\mathbf{u}_w$: context (output) word vector\n",
    "\n",
    "The conditional probability of a context word $w_o$ given a center word $w_c$ is modeled as:\n",
    "\n",
    "$$\n",
    "P(w_o | w_c) = \\frac{\\exp(\\mathbf{u}_{w_o}^T \\mathbf{v}_{w_c})}{\\sum_{w \\in V} \\exp(\\mathbf{u}_w^T \\mathbf{v}_{w_c})}\n",
    "$$\n",
    "\n",
    "where $V$ is the vocabulary.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 3Ô∏è‚É£ Objective Function\n",
    "\n",
    "Given a sequence of words of length $T$, and window size $m$, the Skip-Gram model maximizes the likelihood of generating all context words given their center word:\n",
    "\n",
    "$$\n",
    "\\prod_{t=1}^{T} \\prod_{-m \\le j \\le m, j \\ne 0} P(w_{t+j} | w_t)\n",
    "$$\n",
    "\n",
    "Equivalently, minimize the **negative log-likelihood**:\n",
    "\n",
    "$$\n",
    "-\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\le j \\le m, j \\ne 0} \\log P(w_{t+j} | w_t)\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 4Ô∏è‚É£ Training\n",
    "\n",
    "The Skip-Gram model learns the parameters $\\mathbf{v}_w$ and $\\mathbf{u}_w$ for all words in the vocabulary by maximizing\n",
    "the log-likelihood using **stochastic gradient descent (SGD)**.\n",
    "\n",
    "At each step, a random subsequence of words is sampled to approximate\n",
    "the gradient and update model parameters.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 5Ô∏è‚É£ Gradient Derivation\n",
    "\n",
    "The log probability is given by:\n",
    "\n",
    "$$\n",
    "\\log P(w_o | w_c) = \\mathbf{u}_{w_o}^T \\mathbf{v}_{w_c} - \\log \\sum_{w \\in V} \\exp(\\mathbf{u}_w^T \\mathbf{v}_{w_c})\n",
    "$$\n",
    "\n",
    "Gradient with respect to the **center word vector** $\\mathbf{v}_{w_c}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log P(w_o | w_c)}{\\partial \\mathbf{v}_{w_c}} = \\mathbf{u}_{w_o} - \\sum_{w \\in V} P(w | w_c)\\mathbf{u}_w\n",
    "$$\n",
    "\n",
    "Gradient with respect to the **context word vector** $\\mathbf{u}_{w_o}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log P(w_o | w_c)}{\\partial \\mathbf{u}_{w_o}} = \\mathbf{v}_{w_c} (1 - P(w_o | w_c))\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 6Ô∏è‚É£ Intuition\n",
    "\n",
    "-   Skip-Gram predicts **context words** from a **center word**.\n",
    "-   The embeddings $\\mathbf{v}_w$ and $\\mathbf{u}_w$ are learned so that words appearing in similar contexts have\n",
    "    **similar vector representations**.\n",
    "-   After training:\n",
    "    -   $\\mathbf{v}_w$: used as **word embeddings** (center representation).\n",
    "    -   $\\mathbf{u}_w$: used as **context embeddings**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956acd5e",
   "metadata": {},
   "source": [
    "#### The Continuous Bag of Words (CBOW) Model\n",
    "\n",
    "##### üß† Overview\n",
    "\n",
    "The **Continuous Bag of Words (CBOW)** model predicts the **center word** given its **surrounding context words**. This is the reverse of the Skip-Gram model, which predicts context words from a center word.\n",
    "\n",
    "Example: For the sentence *\"the man loves his son\"* with center word \"loves\" and window size 2, the context words are: \"the\", \"man\", \"his\", \"son\". The CBOW model predicts: $P(\"loves\" \\mid \"the\", \"man\", \"his\", \"son\")$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1Ô∏è‚É£ Conditional Probability\n",
    "\n",
    "Context words are assumed to be conditionally independent contributors to predicting the center word.\n",
    "\n",
    "Each word is represented by:\n",
    "\n",
    "-   $\\mathbf{v}_w$: context (input) vector\n",
    "-   $\\mathbf{u}_w$: center (output) vector\n",
    "\n",
    "CBOW **averages context vectors**:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_{W_c} = \\frac{1}{2m} \\sum_{j=-m, j \\ne 0}^{m} \\mathbf{v}_{w_{t+j}}\n",
    "$$\n",
    "\n",
    "Probability of predicting center word $w_t$:\n",
    "\n",
    "$$\n",
    "P(w_t \\mid W_c) = \\frac{\\exp(\\mathbf{u}_{w_t}^ T \\mathbf{v}_{W_c})}\n",
    "{\\sum_{w \\in V} \\exp(\\mathbf{u}_w^  T \\mathbf{v}_{W_c})}\n",
    "$$\n",
    "\n",
    "This is a softmax over all vocabulary words. $W_c$ refers to the set of context words surrounding the center word.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 2Ô∏è‚É£ Objective Function\n",
    "\n",
    "Given a sequence of length $T$, the CBOW likelihood is:\n",
    "\n",
    "$$\n",
    "\\prod_{t=1}^{T}\n",
    "P(w_t \\mid w_{t-m}, \\ldots, w_{t+m})\n",
    "$$\n",
    "\n",
    "Training minimizes the **negative log-likelihood**:\n",
    "\n",
    "$$\n",
    "- \\sum_{t=1}^{T} \\log P(w_t \\mid w_{t-m}, \\ldots, w_{t+m})\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 3Ô∏è‚É£ Training\n",
    "\n",
    "CBOW uses **stochastic gradient descent (SGD)**. A random subsequence of words is sampled in each iteration to estimate gradients and update parameters.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 4Ô∏è‚É£ Gradient Derivation\n",
    "\n",
    "Log probability:\n",
    "\n",
    "$$\n",
    "\\log P(w_t \\mid W_c) =\n",
    "\\mathbf{u}_{w_t}^ T \\mathbf{v}_{W_c}\n",
    "-\n",
    "\\log \\sum_{w \\in V} \\exp(\\mathbf{u}_{w}^ T \\mathbf{v}_{W_c})\n",
    "$$\n",
    "\n",
    "Gradient w.r.t. each context vector $\\mathbf{v}_{w_i}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log P(w_t \\mid W_c)}{\\partial \\mathbf{v}_{w_i}}\n",
    "=\n",
    "\\frac{1}{2m}\n",
    "\\left[\n",
    "\\mathbf{u}_{w_t}\n",
    "-\n",
    "\\sum_{w \\in V} P(w \\mid W_c)\\mathbf{u}_w\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### ‚úÖ Key Takeaways\n",
    "\n",
    "-   CBOW predicts **one center word** from **multiple context words**.\n",
    "-   It **averages** context vectors ‚Üí computationally efficient.\n",
    "-   Learned embeddings capture semantic similarity.\n",
    "-   Forms half of the foundational **Word2Vec** framework (with Skip-Gram).\n",
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36995a",
   "metadata": {},
   "source": [
    "Due to the nature of the softmax operation, since a context word may be anyone in the dictionary, the opposite of avove algorithm contains the summation of items as many as the entire size of the vocabulary. Consequently, the gradient calculation for the skip-gram model and that for the continuous bag-of-words model both contain the summation. Unfortunately, the computational cost for such gradients that sum over a large dictionary (often with hundreds of thousands or millions of words) is huge!\n",
    "In order to reduce the computational complexity, this section will introduce two approximate training methods: **negative sampling** and **hierarchical softmax**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fecd00",
   "metadata": {},
   "source": [
    "#### Negative Sampling\n",
    "\n",
    "##### üß† Overview\n",
    "\n",
    "The original Skip-Gram objective uses a full softmax over the entire vocabulary $‚à£ùëâ‚à£$, which is computationally expensive because it requires updating gradients for all words.\n",
    "\n",
    "Instead of updating **all word vectors**, it updates only: - the **positive example** (true context word)\\- **K negative samples** (noise words). This makes training fast and scalable.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1Ô∏è‚É£ Positive Example Probability\n",
    "\n",
    "Given a center word $w_c$ and true context word $w_o$:\n",
    "\n",
    "$$\n",
    "P(D = 1 \\mid w_c, w_o) = \\sigma(\\mathbf{u}_{w_o}^ T \\mathbf{v}_{w_c})\n",
    "$$\n",
    "\n",
    "Sigmoid:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 2Ô∏è‚É£ Why Negative Sampling?\n",
    "\n",
    "The original Skip-Gram objective considers only **positive examples**, which leads to:\n",
    "- $\\prod_{t=1}^{T} \\prod_{-m<=j<=m, j \\ne 0}P(D = 1 \\mid w^{(t)}, w^{(t+j)})$ Only maximizes when all word vectors grow to infinity ‚Üí meaningless maximization (vectors blow up to infinity) \n",
    "- extremely expensive softmax (needs $|V|$ updates)\n",
    "\n",
    "Negative sampling fixes both.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 3Ô∏è‚É£ How Negative Sampling Works\n",
    "\n",
    "For each positive pair ($w_c$, $w_o$):\n",
    "- Draw **K negative samples** $w_k$ from noise distribution $P(w)$\n",
    "- Treat them as \"fake context words\" with label $D=0$\n",
    "\n",
    "The new objective approximation:\n",
    "\n",
    "$$\n",
    "P(w_o \\mid w_c) \\approx \n",
    "P(D = 1 \\mid w_c, w_o)\n",
    "\\prod_{k=1}^{K} P(D = 0 \\mid w_c, w_k)\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 4Ô∏è‚É£ Loss Function\n",
    "\n",
    "Let $i$ = index of center word, $h$ = index of true context word:\n",
    "\n",
    "$$\n",
    "-\\log \\sigma(\\mathbf{u}_{h}^ T \\mathbf{v}_{i})\n",
    "-\n",
    "\\sum_{k=1}^{K} \\log(1 - \\sigma(\\mathbf{u}_{k}^ T \\mathbf{v}_{i}))\n",
    "$$\n",
    "\n",
    "Equivalent form:\n",
    "\n",
    "$$\n",
    "-\\log \\sigma(\\mathbf{u}_{h}^ T \\mathbf{v}_{i})\n",
    "+\n",
    "\\sum_{k=1}^{K} \\log \\sigma(-\\mathbf{u}_{k}^ T \\mathbf{v}_{i})\n",
    "$$\n",
    "\n",
    "**Meaning:** \n",
    "- Positive pair ‚Üí push dot product higher\n",
    "- Negative pairs ‚Üí push dot products lower\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 5Ô∏è‚É£ Computational Efficiency\n",
    "\n",
    "With negative sampling: - Computation depends only on **K**, not vocabulary size\n",
    "- Typical K = 5 to 20\n",
    "- Enables training on large corpora quickly\n",
    "\n",
    "Negative sampling reduces training to a scalable binary classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b9369",
   "metadata": {},
   "source": [
    "#### Hierarchical Softmax\n",
    "\n",
    "##### üß† Overview\n",
    "\n",
    "Hierarchical softmax is an efficient alternative to the traditional softmax used in Word2Vec. Instead of computing probabilities over the entire vocabulary $|V|$,\n",
    "it organizes all words into a **binary tree**, where each **leaf node** corresponds to a word.\n",
    "\n",
    "Predicting a word becomes making a sequence of **binary decisions** along the path from the root to that word's leaf node.\n",
    "\n",
    "This reduces computational cost from:\n",
    "\n",
    "$$\n",
    "O(|V|) \\quad \\rightarrow \\quad O(\\log |V|)\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1Ô∏è‚É£ Tree Structure\n",
    "\n",
    "-   Each word $w$ is represented as a **leaf node**.\n",
    "-   There is a unique path from the **root** to each leaf.\n",
    "-   The number of nodes on this path is $L(w)$.\n",
    "-   Let $n(w, j)$ denote the $j$-th node on the path.\n",
    "-   Each internal node has a vector $\\mathbf{u}_{n(w, j)}$.\n",
    "\n",
    "A node can have a **left** or **right** child, and each decision is a binary classification.\n",
    "\n",
    "![Hierarchical softmax](./Images/hierarchicalSoftmax.png)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 2Ô∏è‚É£ Probability of a Word\n",
    "\n",
    "Hierarchical softmax computes the probability of generating word $w_o$ given center word $w_c$ as:\n",
    "\n",
    "$$\n",
    "P(w_o \\mid w_c)\n",
    "=\n",
    "\\prod_{j = 1}^{L(w_o)-1}\n",
    "\\sigma\\left(\n",
    "\\big[ n(w_o, j+1) = \\text{leftChild}(n(w_o, j)) \\big]\n",
    "\\cdot\n",
    "\\mathbf{u}_{n(w_o, j)}^\\top \\mathbf{v}_{w_c}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "-   The bracket equals **+1** if the next node is the left child\n",
    "-   Equals **-1** if the next node is the right child\n",
    "\n",
    "So the model learns to output a correct sequence of binary choices leading to the target word‚Äôs leaf.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 3Ô∏è‚É£ Example\n",
    "\n",
    "For word $w_3$, suppose the path is:\n",
    "\n",
    "-   root ‚Üí left ‚Üí right ‚Üí leaf\n",
    "\n",
    "Probability becomes:\n",
    "\n",
    "$$\n",
    "P(w_3 \\mid w_c)\n",
    "=\n",
    "\\sigma(\\mathbf{u}_{n_1}^T \\mathbf{v}_{w_c})\n",
    "\\cdot\n",
    "\\sigma(-\\mathbf{u}_{n_2}^T \\mathbf{v}_{w_c})\n",
    "\\cdot\n",
    "\\sigma(\\mathbf{u}_{n_3}^T \\mathbf{v}_{w_c})\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 4Ô∏è‚É£ Valid Probability Distribution\n",
    "\n",
    "Hierarchical softmax ensures that:\n",
    "\n",
    "$$\n",
    "\\sum_{w \\in V} P(w \\mid w_c) = 1\n",
    "$$\n",
    "\n",
    "even though it bypasses the full softmax.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### ‚úÖ Key Takeaways\n",
    "\n",
    "-   Converts predicting a word into making $\\log |V|$ binary decisions.\n",
    "-   Efficient for large vocabularies.\n",
    "-   Widely used in Word2Vec models.\n",
    "-   Provides a scalable alternative to full softmax.\n",
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdbae97",
   "metadata": {},
   "source": [
    "================================================The Dataset for Pretraining Word Embeddings======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab301ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd11399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data\\ptb.zip from http://d2l-data.s3-accelerate.amazonaws.com/ptb.zip...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# sentences: 42069'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['ptb'] = (d2l.DATA_URL + 'ptb.zip','319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "\n",
    "#@save\n",
    "def read_ptb():\n",
    "    \"\"\"Load the PTB dataset into a list of text lines.\"\"\"\n",
    "    data_dir = d2l.download_extract('ptb')\n",
    "    # Read the training set\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "sentences = read_ptb()\n",
    "f'# sentences: {len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391edb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f9ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def subsample(sentences, vocab):\n",
    "    \"\"\"Subsample high-frequency words.\"\"\"\n",
    "    # Exclude unknown tokens ('<unk>')\n",
    "    sentences = [[token for token in line if vocab[token] != vocab.unk] for line in sentences]\n",
    "    counter = collections.Counter([token for line in sentences for token in line])\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # Return True if `token` is kept during subsampling\n",
    "    def keep(token):\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    return ([[token for token in line if keep(token)] for line in sentences],\n",
    "            counter)\n",
    "\n",
    "subsampled, counter = subsample(sentences, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5cf97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"262.190625pt\" height=\"185.405431pt\" viewBox=\"0 0 262.190625 185.405431\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-11-07T23:15:29.297039</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 185.405431 \n",
       "L 262.190625 185.405431 \n",
       "L 262.190625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 59.690625 147.849181 \n",
       "L 254.990625 147.849181 \n",
       "L 254.990625 9.249181 \n",
       "L 59.690625 9.249181 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 68.567898 147.849181 \n",
       "L 75.814651 147.849181 \n",
       "L 75.814651 126.144777 \n",
       "L 68.567898 126.144777 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 86.684781 147.849181 \n",
       "L 93.931534 147.849181 \n",
       "L 93.931534 87.673516 \n",
       "L 86.684781 87.673516 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 104.801664 147.849181 \n",
       "L 112.048417 147.849181 \n",
       "L 112.048417 78.3294 \n",
       "L 104.801664 78.3294 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 122.918547 147.849181 \n",
       "L 130.1653 147.849181 \n",
       "L 130.1653 98.637935 \n",
       "L 122.918547 98.637935 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 141.03543 147.849181 \n",
       "L 148.282183 147.849181 \n",
       "L 148.282183 127.332635 \n",
       "L 141.03543 127.332635 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 159.152313 147.849181 \n",
       "L 166.399067 147.849181 \n",
       "L 166.399067 140.880781 \n",
       "L 159.152313 140.880781 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 177.269196 147.849181 \n",
       "L 184.51595 147.849181 \n",
       "L 184.51595 146.27267 \n",
       "L 177.269196 146.27267 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 195.38608 147.849181 \n",
       "L 202.632833 147.849181 \n",
       "L 202.632833 147.44958 \n",
       "L 195.38608 147.44958 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 213.502963 147.849181 \n",
       "L 220.749716 147.849181 \n",
       "L 220.749716 147.712331 \n",
       "L 213.502963 147.712331 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 231.619846 147.849181 \n",
       "L 238.866599 147.849181 \n",
       "L 238.866599 147.772545 \n",
       "L 231.619846 147.772545 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 75.814651 147.849181 \n",
       "L 83.061404 147.849181 \n",
       "L 83.061404 15.849181 \n",
       "L 75.814651 15.849181 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 93.931534 147.849181 \n",
       "L 101.178287 147.849181 \n",
       "L 101.178287 60.073615 \n",
       "L 93.931534 60.073615 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 112.048417 147.849181 \n",
       "L 119.29517 147.849181 \n",
       "L 119.29517 137.946718 \n",
       "L 112.048417 137.946718 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 130.1653 147.849181 \n",
       "L 137.412054 147.849181 \n",
       "L 137.412054 147.263464 \n",
       "L 130.1653 147.263464 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 148.282183 147.849181 \n",
       "L 155.528937 147.849181 \n",
       "L 155.528937 147.832759 \n",
       "L 148.282183 147.832759 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 166.399067 147.849181 \n",
       "L 173.64582 147.849181 \n",
       "L 173.64582 147.843707 \n",
       "L 166.399067 147.843707 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 184.51595 147.849181 \n",
       "L 191.762703 147.849181 \n",
       "L 191.762703 147.849181 \n",
       "L 184.51595 147.849181 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 202.632833 147.849181 \n",
       "L 209.879586 147.849181 \n",
       "L 209.879586 147.849181 \n",
       "L 202.632833 147.849181 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 220.749716 147.849181 \n",
       "L 227.996469 147.849181 \n",
       "L 227.996469 147.849181 \n",
       "L 220.749716 147.849181 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 238.866599 147.849181 \n",
       "L 246.113352 147.849181 \n",
       "L 246.113352 147.849181 \n",
       "L 238.866599 147.849181 \n",
       "z\n",
       "\" clip-path=\"url(#p9412844b81)\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m2ff80618dd\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ff80618dd\" x=\"66.756209\" y=\"147.849181\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(63.574959 162.447619) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ff80618dd\" x=\"110.943729\" y=\"147.849181\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(104.581229 162.447619) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ff80618dd\" x=\"155.131249\" y=\"147.849181\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(148.768749 162.447619) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ff80618dd\" x=\"199.318769\" y=\"147.849181\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(192.956269 162.447619) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2ff80618dd\" x=\"243.506289\" y=\"147.849181\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(237.143789 162.447619) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- # tokens per sentence -->\n",
       "     <g transform=\"translate(100.6125 176.125744) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-23\" d=\"M 3272 2816 \n",
       "L 2363 2816 \n",
       "L 2100 1772 \n",
       "L 3016 1772 \n",
       "L 3272 2816 \n",
       "z\n",
       "M 2803 4594 \n",
       "L 2478 3297 \n",
       "L 3391 3297 \n",
       "L 3719 4594 \n",
       "L 4219 4594 \n",
       "L 3897 3297 \n",
       "L 4872 3297 \n",
       "L 4872 2816 \n",
       "L 3775 2816 \n",
       "L 3519 1772 \n",
       "L 4513 1772 \n",
       "L 4513 1294 \n",
       "L 3397 1294 \n",
       "L 3072 0 \n",
       "L 2572 0 \n",
       "L 2894 1294 \n",
       "L 1978 1294 \n",
       "L 1656 0 \n",
       "L 1153 0 \n",
       "L 1478 1294 \n",
       "L 494 1294 \n",
       "L 494 1772 \n",
       "L 1594 1772 \n",
       "L 1856 2816 \n",
       "L 850 2816 \n",
       "L 850 3297 \n",
       "L 1978 3297 \n",
       "L 2297 4594 \n",
       "L 2803 4594 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-23\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"83.789062\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"115.576172\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.785156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6b\" x=\"215.966797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"270.251953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"331.775391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"395.154297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"447.253906\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"479.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"542.517578\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"604.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"645.154297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"676.941406\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"729.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"790.564453\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"853.943359\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"893.152344\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"954.675781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"1018.054688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"1073.035156\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path id=\"m556c5e8158\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m556c5e8158\" x=\"59.690625\" y=\"147.849181\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(46.328125 151.6484) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m556c5e8158\" x=\"59.690625\" y=\"120.479189\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5000 -->\n",
       "      <g transform=\"translate(27.240625 124.278408) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m556c5e8158\" x=\"59.690625\" y=\"93.109196\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 10000 -->\n",
       "      <g transform=\"translate(20.878125 96.908415) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m556c5e8158\" x=\"59.690625\" y=\"65.739204\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 15000 -->\n",
       "      <g transform=\"translate(20.878125 69.538423) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m556c5e8158\" x=\"59.690625\" y=\"38.369211\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20000 -->\n",
       "      <g transform=\"translate(20.878125 42.16843) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m556c5e8158\" x=\"59.690625\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 25000 -->\n",
       "      <g transform=\"translate(20.878125 14.798438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- count -->\n",
       "     <g transform=\"translate(14.798438 92.655431) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"54.980469\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"116.162109\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"179.541016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"242.919922\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 59.690625 147.849181 \n",
       "L 59.690625 9.249181 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 254.990625 147.849181 \n",
       "L 254.990625 9.249181 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 59.690625 147.849181 \n",
       "L 254.990625 147.849181 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 59.690625 9.249181 \n",
       "L 254.990625 9.249181 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_27\">\n",
       "     <path d=\"M 155.389063 46.605431 \n",
       "L 247.990625 46.605431 \n",
       "Q 249.990625 46.605431 249.990625 44.605431 \n",
       "L 249.990625 16.249181 \n",
       "Q 249.990625 14.249181 247.990625 14.249181 \n",
       "L 155.389063 14.249181 \n",
       "Q 153.389063 14.249181 153.389063 16.249181 \n",
       "L 153.389063 44.605431 \n",
       "Q 153.389063 46.605431 155.389063 46.605431 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"patch_28\">\n",
       "     <path d=\"M 157.389063 25.847619 \n",
       "L 177.389063 25.847619 \n",
       "L 177.389063 18.847619 \n",
       "L 157.389063 18.847619 \n",
       "z\n",
       "\" style=\"fill: #1f77b4\"/>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- origin -->\n",
       "     <g transform=\"translate(185.389063 25.847619) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"61.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"102.294922\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" x=\"130.078125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"193.554688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"221.337891\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_29\">\n",
       "     <path d=\"M 157.389063 40.525744 \n",
       "L 177.389063 40.525744 \n",
       "L 177.389063 33.525744 \n",
       "L 157.389063 33.525744 \n",
       "z\n",
       "\" style=\"fill: url(#hc4cddec5f4)\"/>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- subsampled -->\n",
       "     <g transform=\"translate(185.389063 40.525744) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"52.099609\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"115.478516\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"178.955078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"231.054688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\" x=\"292.333984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"389.746094\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"453.222656\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"481.005859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"542.529297\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p9412844b81\">\n",
       "   <rect x=\"59.690625\" y=\"9.249181\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       " <defs>\n",
       "  <pattern id=\"hc4cddec5f4\" patternUnits=\"userSpaceOnUse\" x=\"0\" y=\"0\" width=\"72\" height=\"72\">\n",
       "   <rect x=\"0\" y=\"0\" width=\"73\" height=\"73\" fill=\"#ff7f0e\"/>\n",
       "   <path d=\"M -36 36 \n",
       "L 36 -36 \n",
       "M -24 48 \n",
       "L 48 -24 \n",
       "M -12 60 \n",
       "L 60 -12 \n",
       "M 0 72 \n",
       "L 72 0 \n",
       "M 12 84 \n",
       "L 84 12 \n",
       "M 24 96 \n",
       "L 96 24 \n",
       "M 36 108 \n",
       "L 108 36 \n",
       "\" style=\"fill: #000000; stroke: #000000; stroke-width: 1.0; stroke-linecap: butt; stroke-linejoin: miter\"/>\n",
       "  </pattern>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2l.show_list_len_pair_hist(['origin', 'subsampled'], '# tokens per sentence',\n",
    "                            'count', sentences, subsampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af37761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"the\": before=50770, after=2020'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return (f'# of \"{token}\": '\n",
    "            f'before={sum([l.count(token) for l in sentences])}, '\n",
    "            f'after={sum([l.count(token) for l in subsampled])}')\n",
    "\n",
    "compare_counts('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4613068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"join\": before=45, after=45'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a50f08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [6697, 4127, 3228, 416, 1773, 27], [993, 3922, 1922, 4743]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2ef3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    \"\"\"Return center words and context words in skip-gram.\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # To form a \"center word--context word\" pair, each sentence needs to\n",
    "        # have at least 2 words\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # Context window centered at `i`\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # Exclude the center word from the context words\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe940111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "center 0 has contexts [1]\n",
      "center 1 has contexts [0, 2, 3]\n",
      "center 2 has contexts [1, 3]\n",
      "center 3 has contexts [1, 2, 4, 5]\n",
      "center 4 has contexts [3, 5]\n",
      "center 5 has contexts [3, 4, 6]\n",
      "center 6 has contexts [4, 5]\n",
      "center 7 has contexts [8, 9]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('dataset', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('center', center, 'has contexts', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc872271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# center-context pairs: 1501304'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# center-context pairs: {sum([len(contexts) for contexts in all_contexts])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ec791e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative sampling\n",
    "\n",
    "#@save\n",
    "class RandomGenerator:\n",
    "    \"\"\"Randomly draw among {1, ..., n} according to n sampling weights.\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        # Exclude\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # Cache `k` random sampling results\n",
    "            self.candidates = random.choices(self.population, self.sampling_weights, k=10000) # sample 10000 at a time\n",
    "            # print(self.candidates)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "453e911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 3, 2, 2, 3, 2, 1, 1, 2]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = RandomGenerator([2, 3, 4])\n",
    "[generator.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ed2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a pair of center word and context word, we randomly sample K (5 in the experiment) noise words. \n",
    "# In the word2vec paper, the sampling probability P(w) of a noise word is set to its relative frequency in the dictionary raised to the power of 0.75\n",
    "\n",
    "#@save\n",
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    \"\"\"Return noise words in negative sampling.\"\"\"\n",
    "    # Sampling weights for words with indices 1, 2, ... (index 0 is the\n",
    "    # excluded unknown token) in the vocabulary\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75 for i in range(1, len(vocab))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # Noise words cannot be context words\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, vocab, counter, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a734c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def batchify(data):\n",
    "    \"\"\"Return a minibatch of examples for skip-gram with negative sampling.\"\"\"\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "        contexts_negatives), torch.tensor(masks), torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "079aa4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = tensor([[1],\n",
      "        [1]])\n",
      "contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 3, 3, 0]])\n",
      "masks = tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])\n",
      "labels = tensor([[1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ead3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_ptb(batch_size, max_window_size, num_noise_words):\n",
    "    \"\"\"Download the PTB dataset and then load it into memory.\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    sentences = read_ptb()\n",
    "    vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "    subsampled, counter = subsample(sentences, vocab)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size)\n",
    "    all_negatives = get_negatives(\n",
    "        all_contexts, vocab, counter, num_noise_words)\n",
    "\n",
    "    class PTBDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, centers, contexts, negatives):\n",
    "            assert len(centers) == len(contexts) == len(negatives)\n",
    "            self.centers = centers\n",
    "            self.contexts = contexts\n",
    "            self.negatives = negatives\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return (self.centers[index], self.contexts[index],\n",
    "                    self.negatives[index])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.centers)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                                      collate_fn=batchify,\n",
    "                                      num_workers=num_workers)\n",
    "    return data_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64b27e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m data_iter, vocab = load_data_ptb(\u001b[32m512\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshape:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    387\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1036\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1045\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     94\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     97\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'"
     ]
    }
   ],
   "source": [
    "data_iter, vocab = load_data_ptb(512, 5, 5)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bf2382",
   "metadata": {},
   "source": [
    "======================================Pretraining word2vec============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32163f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, max_window_size, num_noise_words = 512, 5, 5\n",
    "data_iter, vocab = d2l.load_data_ptb(batch_size, max_window_size, num_noise_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "915dc322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter embedding_weight (torch.Size([20, 4]), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=20, embedding_dim=4) # (vocab_size, embed_size)\n",
    "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
    "      f'dtype={embed.weight.dtype})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bd181ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3018,  0.4162,  1.1194, -1.7517],\n",
       "         [ 0.2721, -2.0752, -1.4533,  0.1977],\n",
       "         [ 0.5588, -1.5292,  1.1404,  0.8593]],\n",
       "\n",
       "        [[ 0.6746, -0.9776, -0.0680,  0.6839],\n",
       "         [ 0.9648, -0.6881,  1.8089,  0.4572],\n",
       "         [ 0.5193,  0.3009, -0.1725,  0.5405]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]]) # (2, 3) -> (2, 3, 4)\n",
    "embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75158d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    # center: (batch size, 1)\n",
    "    # contexts_and_negatives: (batch size, max_len)\n",
    "    v = embed_v(center) # (batch size, 1, embed_size)\n",
    "    u = embed_u(contexts_and_negatives) # (batch size, max_len, embed_size)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1)) # (batch size, 1, max_len)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79247bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
    "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1352e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBCELoss(nn.Module):\n",
    "    # Binary cross-entropy loss with masking\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, target, mask=None):\n",
    "        out = nn.functional.binary_cross_entropy_with_logits(inputs, target, weight=mask, reduction=\"none\")\n",
    "        return out.mean(dim=1)\n",
    "\n",
    "loss = SigmoidBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7e850f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9352, 1.8462])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.tensor([[1.1, -2.2, 3.3, -4.4]] * 2)\n",
    "label = torch.tensor([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]])\n",
    "mask = torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])\n",
    "loss(pred, label, mask) * mask.shape[1] / mask.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d086ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9352\n",
      "1.8462\n"
     ]
    }
   ],
   "source": [
    "def sigmd(x):\n",
    "    return -math.log(1 / (1 + math.exp(-x)))\n",
    "\n",
    "print(f'{(sigmd(1.1) + sigmd(2.2) + sigmd(-3.3) + sigmd(4.4)) / 4:.4f}')\n",
    "print(f'{(sigmd(-1.1) + sigmd(-2.2)) / 2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cff6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two embedding layers for all the words in the vocabulary when they are used as center words and context words, respectively. \n",
    "\n",
    "embed_size = 100\n",
    "net = nn.Sequential(nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size),\n",
    "                    nn.Embedding(num_embeddings=len(vocab),\n",
    "                                 embedding_dim=embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a6ad19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_iter, lr, num_epochs, device=d2l.try_gpu()):\n",
    "    def init_weights(module):\n",
    "        if type(module) == nn.Embedding:\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[1, num_epochs])\n",
    "    # Sum of normalized losses, no. of normalized losses\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for epoch in range(num_epochs):\n",
    "        timer, num_batches = d2l.Timer(), len(data_iter)\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            center, context_negative, mask, label = [\n",
    "                data.to(device) for data in batch]\n",
    "\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            l = (loss(pred.reshape(label.shape).float(), label.float(), mask)\n",
    "                     / mask.sum(axis=1) * mask.shape[1])\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            metric.add(l.sum(), l.numel())\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, '\n",
    "          f'{metric[1] / timer.stop():.1f} tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a9591c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m lr, num_epochs = \u001b[32m0.002\u001b[39m, \u001b[32m5\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(net, data_iter, lr, num_epochs, device)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     13\u001b[39m     timer, num_batches = d2l.Timer(), \u001b[38;5;28mlen\u001b[39m(data_iter)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_iter\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     15\u001b[39m         optimizer.zero_grad()\n\u001b[32m     16\u001b[39m         center, context_negative, mask, label = [\n\u001b[32m     17\u001b[39m             data.to(device) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    387\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1036\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1045\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     94\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     97\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"240.554688pt\" height=\"173.477344pt\" viewBox=\"0 0 240.554688 173.477344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-11-08T08:32:43.711272</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 173.477344 \n",
       "L 240.554688 173.477344 \n",
       "L 240.554688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m2a3d2da9aa\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2a3d2da9aa\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(22.151563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2a3d2da9aa\" x=\"69.163125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(61.211563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2a3d2da9aa\" x=\"108.223125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(100.271563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2a3d2da9aa\" x=\"147.283125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(139.331563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2a3d2da9aa\" x=\"186.343125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(178.391563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2a3d2da9aa\" x=\"225.403125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(217.451563 164.197656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m0482409311\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0482409311\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 153.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0482409311\" x=\"30.103125\" y=\"121.879219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 125.678438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0482409311\" x=\"30.103125\" y=\"94.159219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 97.958438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0482409311\" x=\"30.103125\" y=\"66.439219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 70.238438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0482409311\" x=\"30.103125\" y=\"38.719219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 42.518438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0482409311\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs = 0.002, 5\n",
    "train(net, data_iter, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.weight.data\n",
    "    x = W[vocab[query_token]]\n",
    "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
    "    # torch.mv: matrix-vector product\n",
    "    cos = torch.mv(W, x) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      torch.sum(x * x) + 1e-9)\n",
    "    topk = torch.topk(cos, k=k+1)[1].cpu().numpy().astype('int32')\n",
    "    for i in topk[1:]:  # Remove the input words\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {vocab.to_tokens(i)}')\n",
    "\n",
    "get_similar_tokens('chip', 3, net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa94ad",
   "metadata": {},
   "source": [
    "=====================Word Embedding with Global Vectors (GloVe)========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355bc94",
   "metadata": {},
   "source": [
    "#### Skip-Gram with Global Corpus Statistics (SG-GCS)\n",
    "\n",
    "##### Overview\n",
    "- Defines $q_{ij} = P(w_j | w_i)$ as the conditional probability of context word $w_j$ given center word $w_i$.  \n",
    "- Computed as:  \n",
    "  $$ q_{ij} = \\frac{\\exp(u_j \\cdot v_i)}{\\sum_k \\exp(u_k \\cdot v_i)} $$\n",
    "\n",
    "##### Key Idea\n",
    "- The model uses **global co-occurrence counts** instead of local context windows.  \n",
    "- For each center word $w_i$, its context words $w_j$ have multiplicities $x_{ij}$, representing the number of times $w_j$ appears in the context of $w_i$.  \n",
    "- The skip-gram objective becomes: $ J = - \\sum_i \\sum_j x_{ij} \\log q_{ij} $\n",
    "- This is equivalent to:\n",
    "  $J = - \\sum_i x_i \\sum_j p_{ij} \\log q_{ij}$, where $p_{ij}$ is the conditional probability $x_{ij}/x_i$\n",
    "\n",
    "##### Interpretation\n",
    "- $\\sum_j p_{ij} \\log q_{ij}$ is the **cross-entropy** between the empirical distribution (from corpus statistics) and the model distribution. It is also weighted by $x_i$.\n",
    "- Minimizing this loss aligns the predicted distribution $q_{ij}$ with corpus co-occurrence data $p_{ij}$.  \n",
    "- Disadvantages:\n",
    "  - Computing softmax over all words is very expensive\n",
    "  - Rare words may dominate the loss / a large number of rare events from a large corpus are often modeled by the cross-entropy loss to be assigned with too much weight ÔºüÔºüÔºü\n",
    "    - The loss sums over all observed (w, c) pairs. And many rare words (‚Äúxenolith‚Äù, ‚Äúpterygium‚Äù) that appear only once or twice.\n",
    "\t - A rare event‚Äôs probability $\\hat{p}(c|w)$ is often very small, so $-\\log(\\hat{p}(c|w))$ becomes very large.\n",
    "\t - Therefore, even though the event is rare, it can produce a large gradient update.\n",
    "\t - When the corpus is huge, you accumulate many such rare pairs ‚Üí instability or skewed embeddings.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### The GloVe Model\n",
    "\n",
    "##### Motivation\n",
    "The **GloVe (Global Vectors)** model modifies the skip-gram approach by using a **squared loss** and directly modeling the **ratios of co-occurrence probabilities**.\n",
    "\n",
    "##### Main Changes\n",
    "1. Replace probabilities with raw co-occurrence counts:  \n",
    "   $$ f_{ij} = x_{ij}, \\quad \\hat{f}_{ij} = \\exp(u_j \\cdot v_i) $$\n",
    "\n",
    "2. Use a **squared loss function** instead of cross-entropy:  \n",
    "   $$ J = (u_j \\cdot v_i + b_i + c_j - \\log x_{ij})^2 $$\n",
    "\n",
    "3. Introduce a **weighting function** to control the influence of frequent/rare pairs:  \n",
    "   $$ h(x_{ij}) =\n",
    "   \\begin{cases}\n",
    "   (x_{ij}/a)^\\alpha, & \\text{if } x_{ij} < a \\\\\n",
    "   1, & \\text{otherwise}\n",
    "   \\end{cases} $$\n",
    "\n",
    "   Typical values: $a = 100$, $\\alpha = 0.75$.\n",
    "\n",
    "##### Final GloVe Loss Function\n",
    "$$ J = \\sum_{i,j} h(x_{ij}) (u_j \\cdot v_i + b_i + c_j - \\log x_{ij})^2 $$\n",
    "\n",
    "##### Intuition\n",
    "- GloVe learns embeddings where vector differences capture **meaningful relationships** between words.  \n",
    "- The weighting function keeps the model numerically stable by preventing overemphasis on very frequent or very rare co-occurrences.  \n",
    "- Training is symmetric ‚Äî swapping $(w_i, w_j)$ gives comparable embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57638bcb",
   "metadata": {},
   "source": [
    "#### Interpreting GloVe from the Ratio of Co-occurrence Probabilities\n",
    "\n",
    "##### Core Concept\n",
    "Let $p_{ij} = P(w_j | w_i)$ be the conditional probability of word $w_j$ occurring in the context of $w_i$.  \n",
    "The **ratio** $p_{ij} / p_{ik}$ reflects how words relate to each other.\n",
    "\n",
    "##### Example\n",
    "| Context Word | solid | gas | water | fashion |\n",
    "|---------------|-------|-----|--------|----------|\n",
    "| $p1 = P(w_j \\mid ice)$ | 0.00019 | 0.000066 | 0.003 | 0.000017 |\n",
    "| $p2 = P(w_j \\mid steam)$ | 0.000022 | 0.00078 | 0.0022 | 0.000018 |\n",
    "| Ratio ($p_1/p_2$) | 8.9 | 0.085 | 1.36 | 0.96 |\n",
    "\n",
    "Observations:\n",
    "- Words like **solid** relate more to *ice* ‚Üí high ratio (8.9).  \n",
    "- Words like **gas** relate more to *steam* ‚Üí low ratio (0.085).  \n",
    "- Words like **water** relate to both ‚Üí ratio ‚âà 1.  \n",
    "- Unrelated words like **fashion** ‚Üí ratio near 1 but meaningless.\n",
    "\n",
    "##### Mathematical View\n",
    "We want a function $f$ that can model this ratio: $f(w_i, w_j, w_k) \\approx \\frac{P_{ij}}{P_{ik}}$\n",
    "\n",
    "A natural exponential form that depends on vector differences: $f(w_i, w_j, w_k) = \\frac{\\exp(u_i^\\top v_j)}{\\exp(u_i^\\top v_k)} = \\exp\\!\\big((v_j - v_k)^\\top u_i\\big)$\n",
    "\n",
    "Equating both sides gives: $\\exp\\!\\big((v_j - v_k)^\\top u_i\\big) \\approx \\frac{P_{ij}}{P_{ik}}$\n",
    "\n",
    "Taking the log on both sides yields: $(v_j - v_k)^\\top u_i = \\log P_{ij} - \\log P_{ik}$\n",
    "\n",
    "This implies that each dot product $u_i^\\top v_j$ should correspond (up to bias) to the **log of the co-occurrence probability**: $u_i^\\top v_j + b_i + c_j \\approx \\log P_{ij}$\n",
    "\n",
    "Since $P_{ij} = \\frac{x_{ij}}{x_i}$, the normalization term $\\log x_i$ can be absorbed into the bias $b_i$, giving: $u_i^\\top v_j + b_i + c_j \\approx \\log x_{ij}$\n",
    "\n",
    "To learn embeddings that satisfy this relation across all word pairs, we minimize a **weighted least-squares loss**:\n",
    "\n",
    "$J = \\sum_{i,j} f(x_{ij}) \\, (u_i^\\top v_j + b_i + c_j - \\log x_{ij})^2$\n",
    "\n",
    "where the weighting function $f(x)$ limits the influence of very frequent or rare pairs, typically:\n",
    "\n",
    "$$\n",
    "f(x) =\n",
    "\\begin{cases}\n",
    "(x / x_{\\text{max}})^\\alpha, & x < x_{\\text{max}} \\\\\n",
    "1, & x \\ge x_{\\text{max}}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Common values: $x_{\\text{max}} = 100$, $\\alpha = 0.75$\n",
    "\n",
    "##### Intuition\n",
    "- It models **semantic relationships** directly through **ratios of co-occurrence probabilities**, making it interpretable and mathematically grounded.\n",
    "- GloVe learns embeddings so that vector differences reflect **log co-occurrence ratios**, e.g.\n",
    "$\\text{vector}(\\text{king}) - \\text{vector}(\\text{man}) + \\text{vector}(\\text{woman}) \\approx \\text{vector}(\\text{queen})$,\n",
    "$\\text{vector}(\\text{ice}) - \\text{vector}(\\text{steam}) + \\text{vector}(\\text{solid}) \\approx \\text{vector}(\\text{gas})$\n",
    "- **Why log ratios?** Logarithms linearize multiplicative relationships and stabilize large differences in probabilities.\n",
    "- **Why GloVe > SG-GCS:**  \n",
    "  - Weighted and smooth loss (robust to rare counts)  \n",
    "  - No costly global softmax normalization  \n",
    "  - Captures semantic regularities directly through statistics  \n",
    "  - Works directly from co-occurrence matrix ‚Üí faster and more interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabc470",
   "metadata": {},
   "source": [
    "=========================================Subword Embedding======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664fa22b",
   "metadata": {},
   "source": [
    "#### The fastText Model\n",
    "\n",
    "##### Key Idea\n",
    "- In **word2vec**, each *word* has a single vector.\n",
    "- In **fastText**, each *word* is represented by the **sum of its subword vectors** (character n-grams).\n",
    "\n",
    "This allows the model to capture **morphological information** (prefixes, suffixes, roots) and to represent **rare or unseen words** more effectively.\n",
    "\n",
    "##### How Subwords Are Built\n",
    "1. Add special boundary symbols `<` and `>` around the word to mark start and end.  \n",
    "   Example: `\"where\"` ‚Üí `\"<where>\"`.\n",
    "2. Extract all character n-grams (substrings) of lengths between 3 and 6: ‚Äúwhe‚Äù, ‚Äúher‚Äù, ‚Äúere‚Äù, ‚Äúwher‚Äù, ‚Äúhere‚Äù, ‚Äú<wh‚Äù, ‚Äúre>‚Äù, ‚Äú‚Äù, ‚Ä¶\n",
    "3. Each of these subwords gets its own embedding vector.\n",
    "\n",
    "##### Word Representation\n",
    "If a word $w$ has subwords $g \\in G_w$, the word vector is: $v_w = \\sum_{g \\in G_w} z_g$, where $z_g$ is the embedding vector for subword $g$.\n",
    "So the meaning of a word = **sum of its subword embeddings**.\n",
    "\n",
    "##### Advantages\n",
    "- **Handles rare words** and **out-of-vocabulary (OOV)** words:  \n",
    "If a word wasn‚Äôt seen before, its subwords likely were.\n",
    "- **Shares parameters** between related words:  \n",
    "e.g., *running*, *runner*, *runs* share many subwords ‚Üí better generalization.\n",
    "- **Drawback:** More parameters and computation ‚Äî you must sum all subword vectors for every word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e09d29",
   "metadata": {},
   "source": [
    "#### Byte Pair Encoding (BPE)\n",
    "\n",
    "##### Motivation\n",
    "FastText fixes subword length (e.g., 3‚Äì6 characters).  \n",
    "To allow *variable-length subwords* and a *controlled vocabulary size*, **Byte Pair Encoding (BPE)** is used.\n",
    "\n",
    "##### How BPE Works\n",
    "1. **Start** with all characters as basic symbols (e.g., `'a', 'b', ..., 'z', '_', [UNK]`).\n",
    "2. **Count frequencies** of all symbol pairs (like `'t'` + `'h'` ‚Üí `'th'`).\n",
    "3. **Merge the most frequent pair** into a new symbol.\n",
    "4. **Repeat** until you reach a target vocabulary size.\n",
    "\n",
    "The result is a vocabulary of subwords that frequently appear together, efficiently capturing both characters and common morphemes.\n",
    "\n",
    "##### Example (simplified)\n",
    "Initial symbols: `[\"l\", \"o\", \"w\", \"e\", \"r\"]`\n",
    "\n",
    "Frequent pairs:\n",
    "- merge `(\"l\", \"o\")` ‚Üí `\"lo\"`\n",
    "- merge `(\"lo\", \"w\")` ‚Üí `\"low\"`\n",
    "\n",
    "Final tokens may include `\"low\"`, `\"er\"`, `\"low_er\"` etc.\n",
    "\n",
    "##### Why BPE Matters\n",
    "- Produces a **compact, data-driven subword vocabulary**.  \n",
    "- Handles both **rare words** and **morphologically rich languages**.\n",
    "- Used in **modern NLP models** (e.g., GPT-2, RoBERTa) to segment text into efficient subword units.\n",
    "\n",
    "#### Insight\n",
    "Both **fastText** and **BPE** are subword-based solutions to the same problem:  \n",
    "> How to represent words that are rare, unseen, or morphologically complex.\n",
    "\n",
    "- **fastText**: Summation of character n-gram vectors ‚Üí captures morphology in embeddings.  \n",
    "- **BPE**: Learns optimal subword units via data compression ‚Üí efficient tokenization for large-scale NLP models.\n",
    "\n",
    "#### Intuitive Comparison\n",
    "\n",
    "| Feature | fastText | BPE |\n",
    "|----------|-----------|-----|\n",
    "| Subword type | Fixed-length character n-grams | Variable-length learned units |\n",
    "| Handles OOV words | Yes | Yes |\n",
    "| Vocabulary size | Larger, unbounded | Controlled, predefined |\n",
    "| Used in | Classical word embeddings | Modern Transformer tokenization |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c0e9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "           '_', '[UNK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb2527ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_token_freqs = {'fast_': 4, 'faster_': 3, 'tall_': 5, 'taller_': 4}\n",
    "token_freqs = {}\n",
    "for token, freq in raw_token_freqs.items():\n",
    "    token_freqs[' '.join(list(token))] = raw_token_freqs[token]\n",
    "token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f94d57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_freq_pair(token_freqs):\n",
    "    print(\"token_freqs passed down from get_max_freq_pair: \", token_freqs)\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for token, freq in token_freqs.items():\n",
    "        symbols = token.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            # Key of `pairs` is a tuple of two consecutive symbols\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    return max(pairs, key=pairs.get)  # Key of `pairs` with the max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0534ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_symbols(max_freq_pair, token_freqs, symbols):\n",
    "    symbols.append(''.join(max_freq_pair))\n",
    "    new_token_freqs = dict()\n",
    "    for token, freq in token_freqs.items():\n",
    "        new_token = token.replace(' '.join(max_freq_pair),\n",
    "                                  ''.join(max_freq_pair))\n",
    "        new_token_freqs[new_token] = token_freqs[token]\n",
    "    return new_token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61fda373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_freqs passed down from get_max_freq_pair:  {'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4}\n",
      "merge #1: ('t', 'a')\n",
      "token_freqs passed down from get_max_freq_pair:  {'f a s t _': 4, 'f a s t e r _': 3, 'ta l l _': 5, 'ta l l e r _': 4}\n",
      "merge #2: ('ta', 'l')\n",
      "token_freqs passed down from get_max_freq_pair:  {'f a s t _': 4, 'f a s t e r _': 3, 'tal l _': 5, 'tal l e r _': 4}\n",
      "merge #3: ('tal', 'l')\n",
      "token_freqs passed down from get_max_freq_pair:  {'f a s t _': 4, 'f a s t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
      "merge #4: ('f', 'a')\n",
      "token_freqs passed down from get_max_freq_pair:  {'fa s t _': 4, 'fa s t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
      "merge #5: ('fa', 's')\n",
      "token_freqs passed down from get_max_freq_pair:  {'fas t _': 4, 'fas t e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
      "merge #6: ('fas', 't')\n",
      "token_freqs passed down from get_max_freq_pair:  {'fast _': 4, 'fast e r _': 3, 'tall _': 5, 'tall e r _': 4}\n",
      "merge #7: ('e', 'r')\n",
      "token_freqs passed down from get_max_freq_pair:  {'fast _': 4, 'fast er _': 3, 'tall _': 5, 'tall er _': 4}\n",
      "merge #8: ('er', '_')\n",
      "token_freqs passed down from get_max_freq_pair:  {'fast _': 4, 'fast er_': 3, 'tall _': 5, 'tall er_': 4}\n",
      "merge #9: ('tall', '_')\n",
      "token_freqs passed down from get_max_freq_pair:  {'fast _': 4, 'fast er_': 3, 'tall_': 5, 'tall er_': 4}\n",
      "merge #10: ('fast', '_')\n"
     ]
    }
   ],
   "source": [
    "num_merges = 10\n",
    "for i in range(num_merges):\n",
    "    max_freq_pair = get_max_freq_pair(token_freqs)\n",
    "    token_freqs = merge_symbols(max_freq_pair, token_freqs, symbols)\n",
    "    print(f'merge #{i + 1}:', max_freq_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb042289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', '[UNK]', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_']\n"
     ]
    }
   ],
   "source": [
    "print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "076a1991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fast_', 'fast er_', 'tall_', 'tall er_']\n"
     ]
    }
   ],
   "source": [
    "print(list(token_freqs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcb4ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_BPE(tokens, symbols):\n",
    "    outputs = []\n",
    "    for token in tokens:\n",
    "        start, end = 0, len(token)\n",
    "        cur_output = []\n",
    "        # Segment token with the longest possible subwords from symbols\n",
    "        while start < len(token) and start < end:\n",
    "            if token[start: end] in symbols:\n",
    "                cur_output.append(token[start: end])\n",
    "                start = end\n",
    "                end = len(token)\n",
    "            else:\n",
    "                end -= 1\n",
    "        if start < len(token):\n",
    "            cur_output.append('[UNK]')\n",
    "        outputs.append(' '.join(cur_output))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21fe0dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tall e s t _', 'fa t t er_']\n"
     ]
    }
   ],
   "source": [
    "tokens = ['tallest_', 'fatter_']\n",
    "print(segment_BPE(tokens, symbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31e028",
   "metadata": {},
   "source": [
    "=================================================Word Similarity and Analogy================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a098d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b8bd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n",
    "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n",
    "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n",
    "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n",
    "                           'c1816da3821ae9f43899be655002f6c723e91b88')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8921aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TokenEmbedding:\n",
    "    \"\"\"Token Embedding.\"\"\"\n",
    "    def __init__(self, embedding_name):\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
    "            embedding_name)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        data_dir = d2l.download_extract(embedding_name)\n",
    "        # GloVe website: https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText website: https://fasttext.cc/\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # Skip header information, such as the top row in fastText\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38ea6f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data\\glove.6B.100d.zip from http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.100d.zip...\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 2776: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m glove_6b50d = \u001b[43mTokenEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mglove.6b.100d\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mTokenEmbedding.__init__\u001b[39m\u001b[34m(self, embedding_name)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, embedding_name):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28mself\u001b[39m.idx_to_token, \u001b[38;5;28mself\u001b[39m.idx_to_vec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mself\u001b[39m.unknown_idx = \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mself\u001b[39m.token_to_idx = {token: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, token \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m      9\u001b[39m                          \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.idx_to_token)}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mTokenEmbedding._load_embedding\u001b[39m\u001b[34m(self, embedding_name)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# GloVe website: https://nlp.stanford.edu/projects/glove/\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# fastText website: https://fasttext.cc/\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(data_dir, \u001b[33m'\u001b[39m\u001b[33mvec.txt\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43melems\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melems\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melems\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melems\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:23\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs.charmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m.errors,decoding_table)[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'charmap' codec can't decode byte 0x9d in position 2776: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "glove_6b50d = TokenEmbedding('glove.6b.100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e36e405",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove_6b50d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mglove_6b50d\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'glove_6b50d' is not defined"
     ]
    }
   ],
   "source": [
    "len(glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef814dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_6b50d.token_to_idx['beautiful'], glove_6b50d.idx_to_token[3367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_6b50d.token_to_idx['beautiful'], glove_6b50d.idx_to_token[3367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c19b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(W, x, k):\n",
    "    # Add 1e-9 for numerical stability\n",
    "    cos = torch.mv(W, x.reshape(-1,)) / (\n",
    "        torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\n",
    "        torch.sqrt((x * x).sum()))\n",
    "    _, topk = torch.topk(cos, k=k)\n",
    "    return topk, [cos[int(i)] for i in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f187d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\n",
    "    for i, c in zip(topk[1:], cos[1:]):  # Exclude the input word\n",
    "        print(f'cosine sim={float(c):.3f}: {embed.idx_to_token[int(i)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa34cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_tokens('chip', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_tokens('baby', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_tokens('beautiful', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86197d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    vecs = embed[[token_a, token_b, token_c]]\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    topk, cos = knn(embed.idx_to_vec, x, 1)\n",
    "    return embed.idx_to_token[int(topk[0])]  # Remove unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('man', 'woman', 'son', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba07e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('beijing', 'china', 'tokyo', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('bad', 'worst', 'big', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('do', 'did', 'go', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93387e",
   "metadata": {},
   "source": [
    "==============================================Bidirectional Encoder Representations from Transformers (BERT)==========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad0d36",
   "metadata": {},
   "source": [
    "#### From Context-Independent to Context-Sensitive\n",
    "Traditional models like word2vec and GloVe give each word a single vector, regardless of context (e.g., ‚Äúbank‚Äù has the same vector in ‚Äúriver bank‚Äù and ‚Äúbank loan‚Äù).\n",
    "\n",
    "Context-sensitive representations solve this by making each token‚Äôs vector depend on its surrounding words.\n",
    "Examples:\n",
    "- TagLM ‚Äì adds language-model embeddings to existing models.\n",
    "- CoVe ‚Äì uses encoder states from machine translation models.\n",
    "- ELMo ‚Äì uses deep bidirectional LSTMs; combines forward and backward context representations to produce embeddings that change with context. ELMo improves downstream tasks like sentiment analysis, NER, and question answering by adding context-aware information.\n",
    "\n",
    "#### From Task-Specific to Task-Agnostic\n",
    "ELMo improved many NLP tasks but still required integrating its embeddings into each specific task model.\n",
    "\n",
    "GPT introduced a task-agnostic pretraining architecture:\n",
    "\n",
    "It pretrains a transformer on large text data using next-token prediction (unsupervised).\n",
    "\n",
    "Then fine-tunes it on specific downstream tasks with minimal architecture changes.\n",
    "\n",
    "GPT uses a left-to-right (unidirectional) language model, so each token‚Äôs representation depends only on its left context.\n",
    "\n",
    "#### BERT: Combining the Best of Both Worlds\n",
    "BERT (Bidirectional Encoder Representations from Transformers) combines ELMo‚Äôs bidirectional context with GPT‚Äôs task-agnostic fine-tuning.\n",
    "Key ideas:\n",
    "- BERT uses a bidirectional Transformer encoder to capture both left and right context simultaneously.\n",
    "- Fine-tuning for tasks is done by adding a small output layer ‚Äî minimal task-specific modification.\n",
    "\n",
    "Compared to GPT, BERT differs by:\n",
    "- Using bidirectional context (vs GPT‚Äôs left-to-right).\n",
    "- Fine-tuning all Transformer parameters for each downstream task.\n",
    "\n",
    "This made BERT achieve state-of-the-art performance on a wide range of NLP tasks, such as classification, QA, and inference.\n",
    "\n",
    "In short:\n",
    "- ELMo ‚Üí adds contextual embeddings to existing models.\n",
    "- GPT ‚Üí pretrains a general left-to-right transformer, then fine-tunes per task.\n",
    "- BERT ‚Üí fully bidirectional transformer, pretrain once, fine-tune easily ‚Üí best of both worlds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab643686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_tokens_and_segments(tokens_a, tokens_b=None):\n",
    "    \"\"\"Get tokens of the BERT input sequence and their segment IDs.\"\"\"\n",
    "    tokens = ['<cls>'] + tokens_a + ['<sep>']\n",
    "    # 0 and 1 are marking segment A and B, respectively\n",
    "    segments = [0] * (len(tokens_a) + 2)\n",
    "    if tokens_b is not None:\n",
    "        tokens += tokens_b + ['<sep>']\n",
    "        segments += [1] * (len(tokens_b) + 1) # 0 0 0 0 1 1 1 1 1 1\n",
    "    return tokens, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0817a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BERTEncoder(nn.Module):\n",
    "    \"\"\"BERT encoder.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n",
    "                 num_blks, dropout, max_len=1000, **kwargs):\n",
    "        super(BERTEncoder, self).__init__(**kwargs)\n",
    "        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.segment_embedding = nn.Embedding(2, num_hiddens)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_blks):\n",
    "            self.blks.add_module(f\"{i}\", d2l.TransformerEncoderBlock(\n",
    "                num_hiddens, ffn_num_hiddens, num_heads, dropout, True))\n",
    "        # In BERT, positional embeddings are learnable, thus we create a\n",
    "        # parameter of positional embeddings that are long enough\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,\n",
    "                                                      num_hiddens))\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens):\n",
    "        # Shape of `X` remains unchanged in the following code snippet:\n",
    "        # (batch size, max sequence length, `num_hiddens`)\n",
    "        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n",
    "        X = X + self.pos_embedding[:, :X.shape[1], :]\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4\n",
    "ffn_num_input, num_blks, dropout = 768, 2, 0.2\n",
    "encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb02ba69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.randint(0, vocab_size, (2, 8))\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoded_X = encoder(tokens, segments, None)\n",
    "encoded_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803fed9",
   "metadata": {},
   "source": [
    "#### Masked Language Modeling (MLM) in BERT Pretraining\n",
    "\n",
    "##### 1. The Training Input: Masking Strategy\n",
    "\n",
    "BERT takes plain text (no labels) and creates its own supervised learning problem by masking.\n",
    "\n",
    "**Example sentence:**  \n",
    "> ‚ÄúThe quick brown fox jumps over the lazy dog.‚Äù\n",
    "\n",
    "BERT randomly picks **15% of tokens** for possible masking:\n",
    "\n",
    "| Tokens | [The] | [quick] | [brown] | [fox] | [jumps] | [over] | [the] | [lazy] | [dog] |\n",
    "|---------|-------|---------|---------|-------|---------|--------|-------|--------|-------|\n",
    "| Mask?   | -     | ‚úîÔ∏è      | -       | -     | ‚úîÔ∏è      | -      | -     | ‚úîÔ∏è     | -     |\n",
    "\n",
    "Then for those selected tokens (15%):\n",
    "\n",
    "- **80% of the time ‚Üí replace with `[MASK]`**  \n",
    "  e.g. ‚ÄúThe quick brown fox `[MASK]` over the `[MASK]` dog‚Äù\n",
    "\n",
    "- **10% of the time ‚Üí replace with a random word**  \n",
    "  e.g. ‚ÄúThe quick brown fox *eats* over the `[MASK]` dog‚Äù\n",
    "\n",
    "- **10% of the time ‚Üí keep the same word**  \n",
    "  (This keeps the model from relying on the presence of `[MASK]` too literally.)\n",
    "\n",
    "##### 2. Model Forward Pass\n",
    "\n",
    "Each token (wordpiece) is converted to an **embedding vector**, plus **position** and **segment embeddings**.  \n",
    "These go through multiple **Transformer encoder layers** (attention + feedforward blocks).\n",
    "\n",
    "The output is a **contextual embedding** for every token ‚Äî meaning each position‚Äôs vector encodes context from the *entire sentence* (both left and right).\n",
    "\n",
    "##### 3. The ‚ÄúSupervision‚Äù Signal\n",
    "\n",
    "Even though no human labels are provided, BERT **creates supervision automatically**:\n",
    "\n",
    "For every masked word, BERT knows the original word (since it masked it itself).  \n",
    "That becomes the **label**.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```\n",
    "Input tokens:  [The] [quick] [brown] [fox] [MASK] [over] [the] [MASK] [dog]\n",
    "True tokens:   [The] [quick] [brown] [fox] [jumps] [over] [the] [lazy] [dog]\n",
    "```\n",
    "\n",
    "**Training labels:**\n",
    "\n",
    "- `[MASK]_1` ‚Üí ‚Äújumps‚Äù  \n",
    "- `[MASK]_2` ‚Üí ‚Äúlazy‚Äù\n",
    "\n",
    "The model predicts a probability distribution over the entire vocabulary for each masked position:\n",
    "\n",
    "```\n",
    "P(jumps | context) = 0.92\n",
    "P(run   | context) = 0.03\n",
    "P(eats  | context) = 0.01\n",
    "...\n",
    "```\n",
    "\n",
    "Then it computes **cross-entropy loss** between predicted and true tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretraing Phase: Masked Language Modeling (MLM)\n",
    "\n",
    "# It extracts a subset of hidden states (masked_X) from a tensor X at specific prediction positions within each sequence in the batch, then passes them to a small MLP to predict masked tokens\n",
    "\n",
    "#@save\n",
    "class MaskLM(nn.Module):\n",
    "    \"\"\"The masked language model task of BERT.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, **kwargs):\n",
    "        super(MaskLM, self).__init__(**kwargs)\n",
    "\n",
    "        # MLM prediction head ‚Äî a small neural network that takes the hidden representation of masked tokens and predicts their original vocabulary word.\n",
    "        self.mlp = nn.Sequential(nn.LazyLinear(num_hiddens),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LayerNorm(num_hiddens),\n",
    "                                 nn.LazyLinear(vocab_size))\n",
    "\n",
    "    # X: output from BERT's encoder\n",
    "    def forward(self, X, pred_positions):\n",
    "        # shape of X: (batch size, max sequence length, num_hiddens)\n",
    "        # shape of pred_positions: (batch size, num pred positions)\n",
    "        num_pred_positions = pred_positions.shape[1] # how many masked tokens per sequence\n",
    "        # flatten the array into a 1-D vector: (batch size * num pred positions,)\n",
    "        pred_positions = pred_positions.reshape(-1)\n",
    "        batch_size = X.shape[0]\n",
    "        batch_idx = torch.arange(0, batch_size)\n",
    "        # Suppose that `batch_size` = 2, `num_pred_positions` = 3, then\n",
    "        # `batch_idx` is `torch.tensor([0, 0, 0, 1, 1, 1])`\n",
    "        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n",
    "\n",
    "        # gather hidden states from X at those batch/position pairs\n",
    "        # batch_idx ‚Üí which batch each row comes from\n",
    "        # pred_positions ‚Üí which token index (position) in that batch to pick\n",
    "        # masked_X: (batch_size * num_pred_positions, num_hiddens)\n",
    "        masked_X = X[batch_idx, pred_positions]\n",
    "        # masked_X: (batch_size, num_pred_positions, num_hiddens)\n",
    "        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n",
    "        mlm_Y_hat = self.mlp(masked_X)\n",
    "        return mlm_Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13fbe5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 7, 8])\n",
      "tensor([5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "# advanced indexing\n",
    "\n",
    "# Using Integer Tensors\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.arange(12).view(3, 4)\n",
    "# Select elements at (0,1), (1,3), (2,0)\n",
    "indices_rows = torch.tensor([0, 1, 2])\n",
    "indices_cols = torch.tensor([1, 3, 0])\n",
    "result = x[indices_rows, indices_cols]\n",
    "print(result)\n",
    "# Output: tensor([ 1,  7,  8])\n",
    "\n",
    "# Using Boolean Tensors (Masking)\n",
    "x = torch.arange(9).view(3, 3)\n",
    "mask = x > 4\n",
    "result = x[mask]\n",
    "print(result)\n",
    "# Output: tensor([5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01f39b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10000])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm = MaskLM(vocab_size, num_hiddens)\n",
    "mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])\n",
    "mlm_Y_hat = mlm(encoded_X, mlm_positions)\n",
    "mlm_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad76fe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_Y = torch.tensor([[7, 8, 9], [10, 20, 30]])\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))\n",
    "mlm_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab9fa7",
   "metadata": {},
   "source": [
    "##### Next Sentence Prediction (NSP)\n",
    "Masked Language Modeling (MLM) helps BERT learn word-level understanding. But MLM alone doesn‚Äôt teach BERT how two sentences relate to each other. To fill that gap, BERT adds Next Sentence Prediction (NSP) during pretraining.\n",
    "\n",
    "NSP teaches BERT to understand sentence relationships such as:\n",
    "- Does sentence B logically follow sentence A?\n",
    "- Is sentence B a random sentence?\n",
    "\n",
    "This is useful for downstream tasks like QA, NLI, and summarization.\n",
    "\n",
    "##### What NSP Does During Pretraining\n",
    "For every pair of sentences fed into BERT:\n",
    "\n",
    "- 50% of the time the second sentence is the actual continuation ‚Üí label = True (1)\n",
    "- 50% of the time it‚Äôs a random sentence from the corpus ‚Üí label = False (0)\n",
    "\n",
    "BERT must classify which case it is.\n",
    "\n",
    "All the information needed is stored in the **[CLS] token‚Äôs embedding**, because the Transformer encodes the meaning of the entire input sequence into that embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pretraining Phase: Next Sentence Prediction\n",
    "\n",
    "#@save\n",
    "class NextSentencePred(nn.Module):\n",
    "    \"\"\"The next sentence prediction task of BERT.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NextSentencePred, self).__init__(**kwargs)\n",
    "        # 0 -> not next sentence, 1 -> next sentence\n",
    "        self.output = nn.LazyLinear(2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # `X` is the embedding of the `<cls>` token\n",
    "        # `X` shape: (batch size, `num_hiddens`)\n",
    "        return self.output(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "510cadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch by default will not flatten the tensor as seen in mxnet where, if\n",
    "# flatten=True, all but the first axis of input data are collapsed together\n",
    "encoded_X = torch.flatten(encoded_X, start_dim=1)\n",
    "# input_shape for NSP: (batch size, `num_hiddens`)\n",
    "nsp = NextSentencePred()\n",
    "nsp_Y_hat = nsp(encoded_X)\n",
    "nsp_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "22916c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsp_y = torch.tensor([0, 1])\n",
    "nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "nsp_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BERTModel(nn.Module):\n",
    "    \"\"\"The BERT model.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n",
    "                 num_heads, num_blks, dropout, max_len=1000):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens,\n",
    "                                   num_heads, num_blks, dropout,\n",
    "                                   max_len=max_len)\n",
    "        self.hidden = nn.Sequential(nn.LazyLinear(num_hiddens),\n",
    "                                    nn.Tanh())\n",
    "        self.mlm = MaskLM(vocab_size, num_hiddens)\n",
    "        self.nsp = NextSentencePred()\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):\n",
    "        encoded_X = self.encoder(tokens, segments, valid_lens)\n",
    "        if pred_positions is not None:\n",
    "            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n",
    "        else:\n",
    "            mlm_Y_hat = None\n",
    "        # The hidden layer of the MLP classifier for next sentence prediction.\n",
    "        # 0 is the index of the '<cls>' token\n",
    "        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n",
    "        return encoded_X, mlm_Y_hat, nsp_Y_hat # When pretraining BERT, the final loss function is a linear combination of both the loss functions for masked language modeling and next sentence prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bc84f",
   "metadata": {},
   "source": [
    "======================================The Dataset for Pretraining BERT======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6dd80954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3660b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['wikitext-2'] = (\n",
    "    'https://s3.amazonaws.com/research.metamind.io/wikitext/'\n",
    "    'wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe')\n",
    "\n",
    "#@save\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # Uppercase letters are converted to lowercase ones\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35edff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_next_sentence(sentence, next_sentence, paragraphs):\n",
    "    if random.random() < 0.5:\n",
    "        is_next = True\n",
    "    else:\n",
    "        # `paragraphs` is a list of lists of lists\n",
    "        next_sentence = random.choice(random.choice(paragraphs))\n",
    "        is_next = False\n",
    "    return sentence, next_sentence, is_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c7d57276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):\n",
    "    nsp_data_from_paragraph = []\n",
    "    for i in range(len(paragraph) - 1):\n",
    "        tokens_a, tokens_b, is_next = _get_next_sentence(\n",
    "            paragraph[i], paragraph[i + 1], paragraphs)\n",
    "        # Consider 1 '<cls>' token and 2 '<sep>' tokens\n",
    "        if len(tokens_a) + len(tokens_b) + 3 > max_len:\n",
    "            continue\n",
    "        tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n",
    "        nsp_data_from_paragraph.append((tokens, segments, is_next))\n",
    "    return nsp_data_from_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the Masked Language Modeling Task\n",
    "\n",
    "def _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds, vocab):\n",
    "    # For the input of a masked language model, make a new copy of tokens and\n",
    "    # replace some of them by '<mask>' or random tokens\n",
    "    mlm_input_tokens = [token for token in tokens]\n",
    "    pred_positions_and_labels = []\n",
    "    # Shuffle for getting 15% random tokens for prediction in the masked\n",
    "    # language modeling task\n",
    "    random.shuffle(candidate_pred_positions)\n",
    "\n",
    "    for mlm_pred_position in candidate_pred_positions:\n",
    "        if len(pred_positions_and_labels) >= num_mlm_preds: # num_mlm_preds=15% * len(tokens)\n",
    "            break\n",
    "        masked_token = None\n",
    "        # 80% of the time: replace the word with the '<mask>' token\n",
    "        if random.random() < 0.8:\n",
    "            masked_token = '<mask>'\n",
    "        else:\n",
    "            # 10% of the time: keep the word unchanged\n",
    "            if random.random() < 0.5:\n",
    "                masked_token = tokens[mlm_pred_position]\n",
    "            # 10% of the time: replace the word with a random word\n",
    "            else:\n",
    "                masked_token = random.choice(vocab.idx_to_token)\n",
    "        mlm_input_tokens[mlm_pred_position] = masked_token\n",
    "        pred_positions_and_labels.append((mlm_pred_position, tokens[mlm_pred_position]))\n",
    "    return mlm_input_tokens, pred_positions_and_labels\n",
    "\n",
    "#@save\n",
    "def _get_mlm_data_from_tokens(tokens, vocab):\n",
    "    candidate_pred_positions = []\n",
    "    # `tokens` is a list of strings\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Special tokens are not predicted in the masked language modeling task\n",
    "        if token in ['<cls>', '<sep>']:\n",
    "            continue\n",
    "        candidate_pred_positions.append(i)\n",
    "    # 15% of random tokens are predicted in the masked language modeling task\n",
    "    num_mlm_preds = max(1, round(len(tokens) * 0.15))\n",
    "    mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds, vocab)\n",
    "    pred_positions_and_labels = sorted(pred_positions_and_labels, key=lambda x: x[0])\n",
    "    pred_positions = [v[0] for v in pred_positions_and_labels]\n",
    "    mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n",
    "    return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05cfb099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data\\wikitext-2-v1.zip from https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip...\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadZipFile\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_iter, train_set.vocab\n\u001b[32m     73\u001b[39m batch_size, max_len = \u001b[32m512\u001b[39m, \u001b[32m64\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m train_iter, vocab = \u001b[43mload_data_wiki\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X,\n\u001b[32m     77\u001b[39m      mlm_Y, nsp_y) \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tokens_X.shape, segments_X.shape, valid_lens_x.shape,\n\u001b[32m     79\u001b[39m           pred_positions_X.shape, mlm_weights_X.shape, mlm_Y.shape,\n\u001b[32m     80\u001b[39m           nsp_y.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mload_data_wiki\u001b[39m\u001b[34m(batch_size, max_len)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the WikiText-2 dataset.\"\"\"\u001b[39;00m\n\u001b[32m     65\u001b[39m num_workers = d2l.get_dataloader_workers()\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m data_dir = \u001b[43md2l\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwikitext-2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwikitext-2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m paragraphs = _read_wiki(data_dir)\n\u001b[32m     68\u001b[39m train_set = _WikiTextDataset(paragraphs, max_len)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\d2l\\torch.py:3247\u001b[39m, in \u001b[36mdownload_extract\u001b[39m\u001b[34m(name, folder)\u001b[39m\n\u001b[32m   3245\u001b[39m data_dir, ext = os.path.splitext(fname)\n\u001b[32m   3246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ext == \u001b[33m'\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3247\u001b[39m     fp = \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3248\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33m.tar\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.gz\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   3249\u001b[39m     fp = tarfile.open(fname, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1312\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1314\u001b[39m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[32m   1315\u001b[39m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[32m   1316\u001b[39m         \u001b[38;5;28mself\u001b[39m._didModify = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1379\u001b[39m, in \u001b[36mZipFile._RealGetContents\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug > \u001b[32m1\u001b[39m:\n\u001b[32m   1381\u001b[39m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[31mBadZipFile\u001b[39m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "# Transforming Text into the Pretraining Dataset\n",
    "\n",
    "#@save\n",
    "def _pad_bert_inputs(examples, max_len, vocab):\n",
    "    max_num_mlm_preds = round(max_len * 0.15)\n",
    "    all_token_ids, all_segments, valid_lens,  = [], [], []\n",
    "    all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []\n",
    "    nsp_labels = []\n",
    "    for (token_ids, pred_positions, mlm_pred_label_ids, segments,\n",
    "         is_next) in examples:\n",
    "        all_token_ids.append(torch.tensor(token_ids + [vocab['<pad>']] * (\n",
    "            max_len - len(token_ids)), dtype=torch.long))\n",
    "        all_segments.append(torch.tensor(segments + [0] * (\n",
    "            max_len - len(segments)), dtype=torch.long))\n",
    "        # `valid_lens` excludes count of '<pad>' tokens\n",
    "        valid_lens.append(torch.tensor(len(token_ids), dtype=torch.float32))\n",
    "        all_pred_positions.append(torch.tensor(pred_positions + [0] * (\n",
    "            max_num_mlm_preds - len(pred_positions)), dtype=torch.long))\n",
    "        # Predictions of padded tokens will be filtered out in the loss via\n",
    "        # multiplication of 0 weights\n",
    "        all_mlm_weights.append(\n",
    "            torch.tensor([1.0] * len(mlm_pred_label_ids) + [0.0] * (\n",
    "                max_num_mlm_preds - len(pred_positions)),\n",
    "                dtype=torch.float32))\n",
    "        all_mlm_labels.append(torch.tensor(mlm_pred_label_ids + [0] * (\n",
    "            max_num_mlm_preds - len(mlm_pred_label_ids)), dtype=torch.long))\n",
    "        nsp_labels.append(torch.tensor(is_next, dtype=torch.long))\n",
    "    return (all_token_ids, all_segments, valid_lens, all_pred_positions,\n",
    "            all_mlm_weights, all_mlm_labels, nsp_labels)\n",
    "\n",
    "#@save\n",
    "class _WikiTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paragraphs, max_len):\n",
    "        # Input `paragraphs[i]` is a list of sentence strings representing a paragraph;\n",
    "        # while output `paragraphs[i]` is a list of sentences representing a paragraph, where each sentence is a list of tokens\n",
    "        paragraphs = [d2l.tokenize(paragraph, token='word') for paragraph in paragraphs]\n",
    "        sentences = [sentence for paragraph in paragraphs for sentence in paragraph]\n",
    "        self.vocab = d2l.Vocab(sentences, min_freq=5, reserved_tokens=['<pad>', '<mask>', '<cls>', '<sep>'])\n",
    "        # Get data for the next sentence prediction task\n",
    "        examples = []\n",
    "        for paragraph in paragraphs:\n",
    "            examples.extend(_get_nsp_data_from_paragraph(\n",
    "                paragraph, paragraphs, self.vocab, max_len))\n",
    "        # Get data for the masked language model task\n",
    "        examples = [(_get_mlm_data_from_tokens(tokens, self.vocab)\n",
    "                      + (segments, is_next))\n",
    "                     for tokens, segments, is_next in examples]\n",
    "        # Pad inputs\n",
    "        (self.all_token_ids, self.all_segments, self.valid_lens,\n",
    "         self.all_pred_positions, self.all_mlm_weights,\n",
    "         self.all_mlm_labels, self.nsp_labels) = _pad_bert_inputs(examples, max_len, self.vocab)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.all_token_ids[idx], self.all_segments[idx],\n",
    "                self.valid_lens[idx], self.all_pred_positions[idx],\n",
    "                self.all_mlm_weights[idx], self.all_mlm_labels[idx],\n",
    "                self.nsp_labels[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_token_ids)\n",
    "    \n",
    "#@save\n",
    "def load_data_wiki(batch_size, max_len):\n",
    "    \"\"\"Load the WikiText-2 dataset.\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    data_dir = d2l.download_extract('wikitext-2', 'wikitext-2')\n",
    "    paragraphs = _read_wiki(data_dir)\n",
    "    train_set = _WikiTextDataset(paragraphs, max_len)\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
    "                                        shuffle=True, num_workers=num_workers)\n",
    "    return train_iter, train_set.vocab\n",
    "\n",
    "batch_size, max_len = 512, 64\n",
    "train_iter, vocab = load_data_wiki(batch_size, max_len)\n",
    "\n",
    "for (tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X,\n",
    "     mlm_Y, nsp_y) in train_iter:\n",
    "    print(tokens_X.shape, segments_X.shape, valid_lens_x.shape,\n",
    "          pred_positions_X.shape, mlm_weights_X.shape, mlm_Y.shape,\n",
    "          nsp_y.shape)\n",
    "    break\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b86cc4",
   "metadata": {},
   "source": [
    "================================Pretraining BERT===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ea6dfd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d1bfbd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data\\wikitext-2-v1.zip from https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip...\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadZipFile\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m batch_size, max_len = \u001b[32m512\u001b[39m, \u001b[32m64\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_iter, vocab = \u001b[43md2l\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_data_wiki\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\d2l\\torch.py:2443\u001b[39m, in \u001b[36mload_data_wiki\u001b[39m\u001b[34m(batch_size, max_len)\u001b[39m\n\u001b[32m   2439\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the WikiText-2 dataset.\u001b[39;00m\n\u001b[32m   2440\u001b[39m \n\u001b[32m   2441\u001b[39m \u001b[33;03mDefined in :numref:`subsec_prepare_mlm_data`\"\"\"\u001b[39;00m\n\u001b[32m   2442\u001b[39m num_workers = d2l.get_dataloader_workers()\n\u001b[32m-> \u001b[39m\u001b[32m2443\u001b[39m data_dir = \u001b[43md2l\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwikitext-2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwikitext-2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m paragraphs = _read_wiki(data_dir)\n\u001b[32m   2445\u001b[39m train_set = _WikiTextDataset(paragraphs, max_len)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\huiya\\pytorch-basics\\.venv311\\Lib\\site-packages\\d2l\\torch.py:3247\u001b[39m, in \u001b[36mdownload_extract\u001b[39m\u001b[34m(name, folder)\u001b[39m\n\u001b[32m   3245\u001b[39m data_dir, ext = os.path.splitext(fname)\n\u001b[32m   3246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ext == \u001b[33m'\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3247\u001b[39m     fp = \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3248\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33m.tar\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.gz\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   3249\u001b[39m     fp = tarfile.open(fname, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1312\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1314\u001b[39m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[32m   1315\u001b[39m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[32m   1316\u001b[39m         \u001b[38;5;28mself\u001b[39m._didModify = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1379\u001b[39m, in \u001b[36mZipFile._RealGetContents\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug > \u001b[32m1\u001b[39m:\n\u001b[32m   1381\u001b[39m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[31mBadZipFile\u001b[39m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "batch_size, max_len = 512, 64\n",
    "train_iter, vocab = d2l.load_data_wiki(batch_size, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = d2l.BERTModel(len(vocab), num_hiddens=128, ffn_num_hiddens=256, num_heads=2, num_blks=2, dropout=0.2)\n",
    "devices = d2l.try_all_gpus()\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_batch_loss_bert(net, loss, vocab_size, tokens_X,\n",
    "                         segments_X, valid_lens_x,\n",
    "                         pred_positions_X, mlm_weights_X,\n",
    "                         mlm_Y, nsp_y):\n",
    "    # Forward pass\n",
    "    _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X,\n",
    "                                  valid_lens_x.reshape(-1),\n",
    "                                  pred_positions_X)\n",
    "    # Compute masked language model loss\n",
    "    mlm_l = loss(mlm_Y_hat.reshape(-1, vocab_size), mlm_Y.reshape(-1)) *\\\n",
    "    mlm_weights_X.reshape(-1, 1)\n",
    "    mlm_l = mlm_l.sum() / (mlm_weights_X.sum() + 1e-8)\n",
    "    # Compute next sentence prediction loss\n",
    "    nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "    l = mlm_l + nsp_l\n",
    "    return mlm_l, nsp_l, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(train_iter, net, loss, vocab_size, devices, num_steps):\n",
    "    net(*next(iter(train_iter))[:4])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    step, timer = 0, d2l.Timer()\n",
    "    animator = d2l.Animator(xlabel='step', ylabel='loss',\n",
    "                            xlim=[1, num_steps], legend=['mlm', 'nsp'])\n",
    "    # Sum of masked language modeling losses, sum of next sentence prediction\n",
    "    # losses, no. of sentence pairs, count\n",
    "    metric = d2l.Accumulator(4)\n",
    "    num_steps_reached = False\n",
    "    while step < num_steps and not num_steps_reached:\n",
    "        for tokens_X, segments_X, valid_lens_x, pred_positions_X,\\\n",
    "            mlm_weights_X, mlm_Y, nsp_y in train_iter:\n",
    "            tokens_X = tokens_X.to(devices[0])\n",
    "            segments_X = segments_X.to(devices[0])\n",
    "            valid_lens_x = valid_lens_x.to(devices[0])\n",
    "            pred_positions_X = pred_positions_X.to(devices[0])\n",
    "            mlm_weights_X = mlm_weights_X.to(devices[0])\n",
    "            mlm_Y, nsp_y = mlm_Y.to(devices[0]), nsp_y.to(devices[0])\n",
    "            trainer.zero_grad()\n",
    "            timer.start()\n",
    "            mlm_l, nsp_l, l = _get_batch_loss_bert(\n",
    "                net, loss, vocab_size, tokens_X, segments_X, valid_lens_x,\n",
    "                pred_positions_X, mlm_weights_X, mlm_Y, nsp_y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            metric.add(mlm_l, nsp_l, tokens_X.shape[0], 1)\n",
    "            timer.stop()\n",
    "            animator.add(step + 1,\n",
    "                         (metric[0] / metric[3], metric[1] / metric[3]))\n",
    "            step += 1\n",
    "            if step == num_steps:\n",
    "                num_steps_reached = True\n",
    "                break\n",
    "\n",
    "    print(f'MLM loss {metric[0] / metric[3]:.3f}, '\n",
    "          f'NSP loss {metric[1] / metric[3]:.3f}')\n",
    "    print(f'{metric[2] / timer.sum():.1f} sentence pairs/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49709c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert(train_iter, net, loss, len(vocab), devices, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
