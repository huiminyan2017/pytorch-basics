{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a090fd2",
   "metadata": {},
   "source": [
    "============================ Introduction to Gaussian Processes ============================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590172ea",
   "metadata": {},
   "source": [
    "### Introduction to Gaussian Processes\n",
    "\n",
    "This section introduces **Gaussian Processes (GPs)** as a Bayesian, non-parametric way of placing a prior directly over functions. GPs are fundamental in probabilistic modeling and provide a flexible alternative to parametric methods like neural networks or linear models.\n",
    "\n",
    "#### What is a Gaussian Process?\n",
    "\n",
    "A **Gaussian Process** defines a distribution over functions:\n",
    "\n",
    "> A function $f(\\mathbf{x})$ is said to follow a Gaussian Process if any finite collection of function values has a joint multivariate normal distribution.\n",
    "\n",
    "Formally:\n",
    "$$\n",
    "f(\\mathbf{x}) \\sim \\mathcal{GP}(m(\\mathbf{x}),\\,k(\\mathbf{x},\\mathbf{x}'))\n",
    "$$\n",
    "Where:\n",
    "- $m(\\mathbf{x}) = \\mathbb{E}[f(\\mathbf{x})]$ — **mean function**\n",
    "- $k(\\mathbf{x},\\mathbf{x}') = \\text{cov}(f(\\mathbf{x}),f(\\mathbf{x}'))$ — **covariance/kernel function**\n",
    "\n",
    "So a GP is completely specified by a mean and a kernel.\n",
    "\n",
    "#### Why Gaussian Processes?\n",
    "\n",
    "##### Non-parametric view of functions\n",
    "\n",
    "- Parametric models (e.g., linear regression) assume a fixed form with a finite number of parameters.\n",
    "- GPs instead define a **probability distribution over the space of functions** itself.\n",
    "\n",
    "This means:\n",
    "- With more data, the GP can become more complex.\n",
    "- It doesn’t fix the complexity a priori.\n",
    "\n",
    "#### Core Components\n",
    "\n",
    "##### 1. Mean Function $m(\\mathbf{x})$\n",
    "\n",
    "Typically assumed to be zero:  \n",
    "$m(\\mathbf{x}) = 0$\n",
    "This simplifies analysis and practical implementation without loss of generality, because the kernel can absorb offsets anyway.\n",
    "\n",
    "##### 2. Covariance Function $k(\\mathbf{x},\\mathbf{x}')$\n",
    "\n",
    "The kernel encodes assumptions about:\n",
    "- smoothness,\n",
    "- stationarity,\n",
    "- length scale,\n",
    "- and generalization behavior.\n",
    "\n",
    "Popular choices include:\n",
    "- **Squared Exponential (RBF)**\n",
    "- **Matern**\n",
    "- **Periodic kernels**\n",
    "\n",
    "Covariance determines how strongly correlated function values are at two inputs.\n",
    "\n",
    "#### GP as a Prior Over Functions\n",
    "\n",
    "Consider a set of inputs $\\mathbf{X} = \\{\\mathbf{x}_1,\\ldots,\\mathbf{x}_n\\}$.\n",
    "\n",
    "A GP prior asserts:\n",
    "$$\n",
    "[f(\\mathbf{x}_1),\\,\\ldots,\\,f(\\mathbf{x}_n)]^\\top\n",
    "\\sim\n",
    "\\mathcal{N}(\\mathbf{m},\\,\\mathbf{K}),\n",
    "$$\n",
    "where\n",
    "- $\\mathbf{m} = [m(\\mathbf{x}_1),\\ldots,m(\\mathbf{x}_n)]^\\top$\n",
    "- $\\mathbf{K}_{i,j}=k(\\mathbf{x}_i,\\mathbf{x}_j)$\n",
    "\n",
    "This is a multivariate Gaussian over the function values.\n",
    "\n",
    "#### Intuition Behind Gaussian Processes\n",
    "\n",
    "##### Smoothness vs. flexibility\n",
    "\n",
    "The **kernel function** controls:\n",
    "- how quickly correlations decay with distance,\n",
    "- how smooth the functions sampled from the GP are.\n",
    "\n",
    "Example:\n",
    "- RBF kernel → very smooth functions\n",
    "- Matern kernel → rougher but still continuous functions\n",
    "\n",
    "### Uncertainty as a first-class citizen\n",
    "\n",
    "GPs provide **predictive uncertainty** automatically:\n",
    "- near observed data → uncertainty low,\n",
    "- far from data → uncertainty high.\n",
    "\n",
    "This is due to conditioning a multivariate Gaussian.\n",
    "\n",
    "#### Connection to Bayesian Inference\n",
    "\n",
    "Given data $\\{(\\mathbf{x}_i,y_i)\\}$:\n",
    "- GP treats unknown function values at both observed and new inputs as jointly Gaussian.\n",
    "- Inference is done by conditioning the joint distribution on observed data.\n",
    "\n",
    "Result:\n",
    "- A predictive mean function — the best guess for the true function\n",
    "- A predictive variance — uncertainty at each prediction point\n",
    "\n",
    "This gives a full **posterior distribution over functions**.\n",
    "\n",
    "#### GP Regression View\n",
    "\n",
    "GP regression predicts outputs as: $y_i = f(\\mathbf{x}_i) + \\varepsilon$\n",
    "where \\(\\varepsilon\\) is Gaussian noise.\n",
    "\n",
    "The predictive distribution at a new input $\\mathbf{x}_*$ is:\n",
    "$$\n",
    "f_* \\mid \\mathbf{X},\\mathbf{y},\\mathbf{x}_*\n",
    "\\sim\n",
    "\\mathcal{N}(\\mu_*,\\,\\sigma_*^2),\n",
    "$$\n",
    "Where:\n",
    "- $\\mu_*$ comes from the kernel similarity with training points,\n",
    "- $\\sigma_*^2$ captures both noise and lack of nearby data.\n",
    "\n",
    "#### Relation to Other Methods\n",
    "\n",
    "##### Parametric Models\n",
    "- Assume a fixed functional form $f(\\mathbf{x}; \\theta)$\n",
    "- Parameters are inferred from data\n",
    "\n",
    "##### GPs\n",
    "- Function values themselves are random\n",
    "- Model complexity grows with data instead of being fixed\n",
    "\n",
    "GPs are thus more **flexible** and **uncertainty-aware**.\n",
    "\n",
    "#### Practical Implications\n",
    "\n",
    "- GPs work well for small to medium datasets where uncertainty matters (e.g., Bayesian optimization).\n",
    "- Computational complexity is high for large datasets ($O(n^3)$) due to inversion of covariance matrices.\n",
    "- Choice of kernel hyperparameters is crucial and often learned via marginal likelihood optimization.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- A **Gaussian Process** places a prior over functions rather than parameters.\n",
    "- It is defined by mean and covariance functions.\n",
    "- The kernel controls correlation and smoothness.\n",
    "- Posterior predictions naturally come with uncertainty estimates.\n",
    "- GPs excel in principled Bayesian modeling of functions when data is limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a676e",
   "metadata": {},
   "source": [
    "=========================== Gaussian Process Priors ========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c1c82",
   "metadata": {},
   "source": [
    "### Gaussian Process Priors\n",
    "\n",
    "This section explains how **Gaussian Processes (GPs)** define prior distributions over functions via **mean** and **covariance (kernel) functions**, and how different kernel choices encode different assumptions about smoothness and structure.\n",
    "\n",
    "#### 1. What a GP Prior Is\n",
    "\n",
    "A GP prior places a probability distribution directly over the space of functions:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) \\sim \\mathcal{GP}\\big(m(\\mathbf{x}),\\,k(\\mathbf{x},\\mathbf{x}')\\big)\n",
    "$$\n",
    "\n",
    "- $m(\\mathbf{x})$: mean function  \n",
    "- $k(\\mathbf{x},\\mathbf{x}')$: covariance (kernel) function\n",
    "\n",
    "The prior defines how values $f(\\mathbf{x})$ at any finite set of inputs relate to each other before seeing data.\n",
    "\n",
    "#### 2. Mean Function\n",
    "\n",
    "The **mean function** $m(\\mathbf{x}) = \\mathbb{E}[f(\\mathbf{x})]$ describes expected function values under the prior.\n",
    "\n",
    "In practice:\n",
    "- It is often set to zero: $m(\\mathbf{x}) = 0$\n",
    "- Zero mean doesn’t imply functions are zero — the kernel controls variability.\n",
    "- Any nonzero trend can be learned by incorporating it into the kernel or adding a separate parametric component.\n",
    "\n",
    "This simplifies formulas without restricting expressiveness.\n",
    "\n",
    "#### 3. Covariance (Kernel) Function\n",
    "\n",
    "The **covariance function** $k(\\mathbf{x},\\mathbf{x}')$ encodes assumptions about\n",
    "function behavior, such as smoothness, periodicity, and correlation length.\n",
    "\n",
    "##### Formally\n",
    "Given a set of inputs $\\{\\mathbf{x}_1,\\ldots,\\mathbf{x}_n\\}$, the prior over the function values $\\mathbf{f} = [f(\\mathbf{x}_1),\\ldots,f(\\mathbf{x}_n)]^\\top$ is: \n",
    "\n",
    "$$\n",
    "\\mathbf{f} \\sim \\mathcal{N}\\!\\big(\\mathbf{m},\\,\\mathbf{K}\\big)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{m} = [m(\\mathbf{x}_1),\\ldots,m(\\mathbf{x}_n)]^\\top$\n",
    "- $\\mathbf{K}$ is the covariance matrix with entries $\\mathbf{K}_{ij} = k(\\mathbf{x}_i,\\mathbf{x}_j)$\n",
    "\n",
    "The kernel determines the structure of $\\mathbf{K}$ and therefore how correlated\n",
    "function values at different inputs are under the prior.\n",
    "\n",
    "#### 4. Example: Exponentiated Quadratic (RBF) Kernel\n",
    "\n",
    "One of the most commonly used kernels:\n",
    "\n",
    "$$\n",
    "k_{\\text{RBF}}(\\mathbf{x},\\mathbf{x}')\n",
    "= \\sigma^2 \\exp\\!\\Big(-\\frac{\\|\\mathbf{x}-\\mathbf{x}'\\|^2}{2\\ell^2}\\Big)\n",
    "$$\n",
    "\n",
    "- $\\sigma^2$: variance (controls vertical scale)\n",
    "- $\\ell$: length-scale (controls horizontal smoothness)\n",
    "\n",
    "Interpretation:\n",
    "- Larger $\\ell$: functions vary slowly (very smooth)\n",
    "- Smaller $\\ell$: functions vary quickly (wiggly)\n",
    "- Far apart inputs → correlation goes to zero.\n",
    "\n",
    "Together, $m(\\mathbf{x})$ and $k_{\\text{RBF}}$ define a function prior that favors smooth continuous functions.\n",
    "\n",
    "#### 5. Visualizing the GP Prior\n",
    "\n",
    "Under a GP prior, if you sample functions from:\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = [f(\\mathbf{x}_1),\\ldots,f(\\mathbf{x}_n)]^\\top\n",
    "\\sim \\mathcal{N}(\\mathbf{0},\\,\\mathbf{K})\n",
    "$$\n",
    "\n",
    "the draws look like:\n",
    "- smooth wiggly curves if the RBF kernel is used\n",
    "- rougher or structured curves if other kernels are chosen\n",
    "\n",
    "Even before observing any data, the prior expresses beliefs about the shape of $f$.\n",
    "\n",
    "#### 6. Kernel Encodes Inductive Bias\n",
    "\n",
    "Choosing the kernel means choosing what kind of functions are *a priori* likely.  \n",
    "Examples:\n",
    "\n",
    "- **RBF kernel** → infinitely differentiable smooth functions\n",
    "- **Matern kernel** → functions with controlled roughness\n",
    "- **Periodic kernel** → functions that repeat\n",
    "\n",
    "The kernel hyperparameters (e.g., $\\ell,\\sigma^2$) control:\n",
    "- correlation strength\n",
    "- characteristic length scale\n",
    "- function amplitude\n",
    "\n",
    "These are often learned from data (e.g., by maximizing marginal likelihood).\n",
    "\n",
    "#### 7. Why Priors Matter\n",
    "\n",
    "GP priors directly influence:\n",
    "- how uncertainty changes with distance from observed points\n",
    "- how quickly predictions revert to the prior mean\n",
    "- the shape of the predictive mean–variance curves\n",
    "\n",
    "Far from data:\n",
    "- predictive variance → prior variance\n",
    "- predictive mean → prior mean\n",
    "\n",
    "This reflects increased uncertainty in regions without observations.\n",
    "\n",
    "#### 8. Posterior with Observations (Preview)\n",
    "\n",
    "Given data $(\\mathbf{X}, \\mathbf{y})$, the GP prior combines with the likelihood\n",
    "to form a **posterior over functions**. The result is: $\\text{Posterior mean and covariance}$\n",
    "\n",
    "that interpolate smoothly between observed points — with uncertainty captured in\n",
    "the posterior covariance.\n",
    "\n",
    "Details are covered in the GP regression section of the chapter.\n",
    "\n",
    "#### 9. Intuition vs. Parametric Models\n",
    "\n",
    "Unlike parametric models with fixed numbers of parameters:\n",
    "- GP priors define distributions over functions with potentially **infinite degrees of freedom**\n",
    "- Complexity grows with data\n",
    "- Uncertainty quantification is built in\n",
    "\n",
    "GPs thus balance flexibility and Bayesian regularization via the kernel.\n",
    "\n",
    "#### 10. Summary\n",
    "\n",
    "- A **Gaussian Process prior** places a distribution over functions via a mean and kernel.\n",
    "- The **kernel** encodes assumptions about correlation, smoothness, and generalization.\n",
    "- GP priors control how functions behave *before* seeing any data.\n",
    "- Hyperparameters of the kernel shape the prior and influence predictions after observing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14691d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix\n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.set_figsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dcae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"261.160937pt\" height=\"193.034375pt\" viewBox=\"0 0 261.160937 193.034375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2026-01-31T23:38:45.838002</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 193.034375 \n",
       "L 261.160937 193.034375 \n",
       "L 261.160937 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 58.660938 145.8 \n",
       "L 253.960938 145.8 \n",
       "L 253.960938 7.2 \n",
       "L 58.660938 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PolyCollection_1\">\n",
       "    <path d=\"M 67.53821 29.809981 \n",
       "L 67.53821 134.37162 \n",
       "L 71.161587 132.321459 \n",
       "L 74.784963 130.274936 \n",
       "L 78.40834 128.232534 \n",
       "L 82.031717 126.194827 \n",
       "L 85.655093 124.162497 \n",
       "L 89.27847 122.136362 \n",
       "L 92.901847 120.117412 \n",
       "L 96.525223 118.106856 \n",
       "L 100.1486 116.106183 \n",
       "L 103.771976 114.117244 \n",
       "L 107.395353 112.142369 \n",
       "L 111.01873 110.184525 \n",
       "L 114.642106 108.247536 \n",
       "L 118.265483 106.336402 \n",
       "L 121.88886 104.45775 \n",
       "L 125.512236 102.620499 \n",
       "L 129.135613 100.836827 \n",
       "L 132.758989 99.123573 \n",
       "L 136.382366 97.504239 \n",
       "L 140.005743 96.011638 \n",
       "L 143.629119 94.690888 \n",
       "L 147.252496 93.601298 \n",
       "L 150.875873 92.813571 \n",
       "L 154.499249 92.397154 \n",
       "L 158.122626 92.397154 \n",
       "L 161.746002 92.813571 \n",
       "L 165.369379 93.601298 \n",
       "L 168.992756 94.690888 \n",
       "L 172.616132 96.011638 \n",
       "L 176.239509 97.504239 \n",
       "L 179.862886 99.123573 \n",
       "L 183.486262 100.836827 \n",
       "L 187.109639 102.620499 \n",
       "L 190.733015 104.45775 \n",
       "L 194.356392 106.336402 \n",
       "L 197.979769 108.247536 \n",
       "L 201.603145 110.184525 \n",
       "L 205.226522 112.142369 \n",
       "L 208.849899 114.117244 \n",
       "L 212.473275 116.106183 \n",
       "L 216.096652 118.106856 \n",
       "L 219.720028 120.117412 \n",
       "L 223.343405 122.136362 \n",
       "L 226.966782 124.162497 \n",
       "L 230.590158 126.194827 \n",
       "L 234.213535 128.232534 \n",
       "L 237.836912 130.274936 \n",
       "L 241.460288 132.321459 \n",
       "L 245.083665 134.37162 \n",
       "L 245.083665 29.809981 \n",
       "L 245.083665 29.809981 \n",
       "L 241.460288 31.860143 \n",
       "L 237.836912 33.906666 \n",
       "L 234.213535 35.949068 \n",
       "L 230.590158 37.986775 \n",
       "L 226.966782 40.019105 \n",
       "L 223.343405 42.04524 \n",
       "L 219.720028 44.06419 \n",
       "L 216.096652 46.074746 \n",
       "L 212.473275 48.075419 \n",
       "L 208.849899 50.064358 \n",
       "L 205.226522 52.039233 \n",
       "L 201.603145 53.997077 \n",
       "L 197.979769 55.934065 \n",
       "L 194.356392 57.8452 \n",
       "L 190.733015 59.723852 \n",
       "L 187.109639 61.561103 \n",
       "L 183.486262 63.344775 \n",
       "L 179.862886 65.058028 \n",
       "L 176.239509 66.677363 \n",
       "L 172.616132 68.169964 \n",
       "L 168.992756 69.490714 \n",
       "L 165.369379 70.580303 \n",
       "L 161.746002 71.368031 \n",
       "L 158.122626 71.784447 \n",
       "L 154.499249 71.784447 \n",
       "L 150.875873 71.368031 \n",
       "L 147.252496 70.580303 \n",
       "L 143.629119 69.490714 \n",
       "L 140.005743 68.169964 \n",
       "L 136.382366 66.677363 \n",
       "L 132.758989 65.058028 \n",
       "L 129.135613 63.344775 \n",
       "L 125.512236 61.561103 \n",
       "L 121.88886 59.723852 \n",
       "L 118.265483 57.8452 \n",
       "L 114.642106 55.934065 \n",
       "L 111.01873 53.997077 \n",
       "L 107.395353 52.039233 \n",
       "L 103.771976 50.064358 \n",
       "L 100.1486 48.075419 \n",
       "L 96.525223 46.074746 \n",
       "L 92.901847 44.06419 \n",
       "L 89.27847 42.04524 \n",
       "L 85.655093 40.019105 \n",
       "L 82.031717 37.986775 \n",
       "L 78.40834 35.949068 \n",
       "L 74.784963 33.906666 \n",
       "L 71.161587 31.860143 \n",
       "L 67.53821 29.809981 \n",
       "z\n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: #1f77b4; fill-opacity: 0.25\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m8b0370c867\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b0370c867\" x=\"85.292756\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −4 -->\n",
       "      <g transform=\"translate(77.921662 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b0370c867\" x=\"120.801847\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(113.430753 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b0370c867\" x=\"156.310938\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(153.129688 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b0370c867\" x=\"191.820028\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(188.638778 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b0370c867\" x=\"227.329119\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(224.147869 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- x -->\n",
       "     <g transform=\"translate(150.392188 181.675) scale(0.2 -0.2)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-78\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path id=\"m6efd4ab05f\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6efd4ab05f\" x=\"58.660938\" y=\"133.356362\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- −10 -->\n",
       "      <g transform=\"translate(30.55625 137.155581) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"147.412109\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6efd4ab05f\" x=\"58.660938\" y=\"107.723582\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- −5 -->\n",
       "      <g transform=\"translate(36.91875 111.5228) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6efd4ab05f\" x=\"58.660938\" y=\"82.090801\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(45.298438 85.89002) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6efd4ab05f\" x=\"58.660938\" y=\"56.45802\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(45.298438 60.257239) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m6efd4ab05f\" x=\"58.660938\" y=\"30.82524\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(38.935938 34.624458) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- f(x) -->\n",
       "     <g transform=\"translate(22.396875 93.742188) rotate(-90) scale(0.2 -0.2)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \n",
       "L 2375 4384 \n",
       "L 1825 4384 \n",
       "Q 1516 4384 1395 4259 \n",
       "Q 1275 4134 1275 3809 \n",
       "L 1275 3500 \n",
       "L 2222 3500 \n",
       "L 2222 3053 \n",
       "L 1275 3053 \n",
       "L 1275 0 \n",
       "L 697 0 \n",
       "L 697 3053 \n",
       "L 147 3053 \n",
       "L 147 3500 \n",
       "L 697 3500 \n",
       "L 697 3744 \n",
       "Q 697 4328 969 4595 \n",
       "Q 1241 4863 1831 4863 \n",
       "L 2375 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" x=\"35.205078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"74.21875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" x=\"133.398438\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path d=\"M 67.53821 82.090801 \n",
       "L 71.161587 82.090801 \n",
       "L 74.784963 82.090801 \n",
       "L 78.40834 82.090801 \n",
       "L 82.031717 82.090801 \n",
       "L 85.655093 82.090801 \n",
       "L 89.27847 82.090801 \n",
       "L 92.901847 82.090801 \n",
       "L 96.525223 82.090801 \n",
       "L 100.1486 82.090801 \n",
       "L 103.771976 82.090801 \n",
       "L 107.395353 82.090801 \n",
       "L 111.01873 82.090801 \n",
       "L 114.642106 82.090801 \n",
       "L 118.265483 82.090801 \n",
       "L 121.88886 82.090801 \n",
       "L 125.512236 82.090801 \n",
       "L 129.135613 82.090801 \n",
       "L 132.758989 82.090801 \n",
       "L 136.382366 82.090801 \n",
       "L 140.005743 82.090801 \n",
       "L 143.629119 82.090801 \n",
       "L 147.252496 82.090801 \n",
       "L 150.875873 82.090801 \n",
       "L 154.499249 82.090801 \n",
       "L 158.122626 82.090801 \n",
       "L 161.746002 82.090801 \n",
       "L 165.369379 82.090801 \n",
       "L 168.992756 82.090801 \n",
       "L 172.616132 82.090801 \n",
       "L 176.239509 82.090801 \n",
       "L 179.862886 82.090801 \n",
       "L 183.486262 82.090801 \n",
       "L 187.109639 82.090801 \n",
       "L 190.733015 82.090801 \n",
       "L 194.356392 82.090801 \n",
       "L 197.979769 82.090801 \n",
       "L 201.603145 82.090801 \n",
       "L 205.226522 82.090801 \n",
       "L 208.849899 82.090801 \n",
       "L 212.473275 82.090801 \n",
       "L 216.096652 82.090801 \n",
       "L 219.720028 82.090801 \n",
       "L 223.343405 82.090801 \n",
       "L 226.966782 82.090801 \n",
       "L 230.590158 82.090801 \n",
       "L 234.213535 82.090801 \n",
       "L 237.836912 82.090801 \n",
       "L 241.460288 82.090801 \n",
       "L 245.083665 82.090801 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #000000; stroke-width: 4; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 67.53821 46.997173 \n",
       "L 71.161587 48.436642 \n",
       "L 74.784963 49.87611 \n",
       "L 78.40834 51.315578 \n",
       "L 82.031717 52.755046 \n",
       "L 85.655093 54.194515 \n",
       "L 89.27847 55.633983 \n",
       "L 92.901847 57.073451 \n",
       "L 96.525223 58.512919 \n",
       "L 100.1486 59.952388 \n",
       "L 103.771976 61.391856 \n",
       "L 107.395353 62.831324 \n",
       "L 111.01873 64.270792 \n",
       "L 114.642106 65.710261 \n",
       "L 118.265483 67.149729 \n",
       "L 121.88886 68.589197 \n",
       "L 125.512236 70.028665 \n",
       "L 129.135613 71.468134 \n",
       "L 132.758989 72.907602 \n",
       "L 136.382366 74.34707 \n",
       "L 140.005743 75.786538 \n",
       "L 143.629119 77.226007 \n",
       "L 147.252496 78.665475 \n",
       "L 150.875873 80.104943 \n",
       "L 154.499249 81.544411 \n",
       "L 158.122626 82.98388 \n",
       "L 161.746002 84.423348 \n",
       "L 165.369379 85.862816 \n",
       "L 168.992756 87.302284 \n",
       "L 172.616132 88.741753 \n",
       "L 176.239509 90.181221 \n",
       "L 179.862886 91.620689 \n",
       "L 183.486262 93.060157 \n",
       "L 187.109639 94.499626 \n",
       "L 190.733015 95.939094 \n",
       "L 194.356392 97.378562 \n",
       "L 197.979769 98.81803 \n",
       "L 201.603145 100.257499 \n",
       "L 205.226522 101.696967 \n",
       "L 208.849899 103.136435 \n",
       "L 212.473275 104.575903 \n",
       "L 216.096652 106.015371 \n",
       "L 219.720028 107.45484 \n",
       "L 223.343405 108.894308 \n",
       "L 226.966782 110.333776 \n",
       "L 230.590158 111.773244 \n",
       "L 234.213535 113.212713 \n",
       "L 237.836912 114.652181 \n",
       "L 241.460288 116.091649 \n",
       "L 245.083665 117.531117 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 67.53821 59.487411 \n",
       "L 71.161587 60.718322 \n",
       "L 74.784963 61.949233 \n",
       "L 78.40834 63.180144 \n",
       "L 82.031717 64.411055 \n",
       "L 85.655093 65.641967 \n",
       "L 89.27847 66.872878 \n",
       "L 92.901847 68.103789 \n",
       "L 96.525223 69.3347 \n",
       "L 100.1486 70.565611 \n",
       "L 103.771976 71.796522 \n",
       "L 107.395353 73.027434 \n",
       "L 111.01873 74.258345 \n",
       "L 114.642106 75.489256 \n",
       "L 118.265483 76.720167 \n",
       "L 121.88886 77.951078 \n",
       "L 125.512236 79.181989 \n",
       "L 129.135613 80.4129 \n",
       "L 132.758989 81.643812 \n",
       "L 136.382366 82.874723 \n",
       "L 140.005743 84.105634 \n",
       "L 143.629119 85.336545 \n",
       "L 147.252496 86.567456 \n",
       "L 150.875873 87.798367 \n",
       "L 154.499249 89.029278 \n",
       "L 158.122626 90.26019 \n",
       "L 161.746002 91.491101 \n",
       "L 165.369379 92.722012 \n",
       "L 168.992756 93.952923 \n",
       "L 172.616132 95.183834 \n",
       "L 176.239509 96.414745 \n",
       "L 179.862886 97.645656 \n",
       "L 183.486262 98.876568 \n",
       "L 187.109639 100.107479 \n",
       "L 190.733015 101.33839 \n",
       "L 194.356392 102.569301 \n",
       "L 197.979769 103.800212 \n",
       "L 201.603145 105.031123 \n",
       "L 205.226522 106.262034 \n",
       "L 208.849899 107.492946 \n",
       "L 212.473275 108.723857 \n",
       "L 216.096652 109.954768 \n",
       "L 219.720028 111.185679 \n",
       "L 223.343405 112.41659 \n",
       "L 226.966782 113.647501 \n",
       "L 230.590158 114.878412 \n",
       "L 234.213535 116.109324 \n",
       "L 237.836912 117.340235 \n",
       "L 241.460288 118.571146 \n",
       "L 245.083665 119.802057 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 67.53821 59.100287 \n",
       "L 71.161587 60.431964 \n",
       "L 74.784963 61.76364 \n",
       "L 78.40834 63.095317 \n",
       "L 82.031717 64.426994 \n",
       "L 85.655093 65.75867 \n",
       "L 89.27847 67.090347 \n",
       "L 92.901847 68.422024 \n",
       "L 96.525223 69.753701 \n",
       "L 100.1486 71.085377 \n",
       "L 103.771976 72.417054 \n",
       "L 107.395353 73.748731 \n",
       "L 111.01873 75.080407 \n",
       "L 114.642106 76.412084 \n",
       "L 118.265483 77.743761 \n",
       "L 121.88886 79.075437 \n",
       "L 125.512236 80.407114 \n",
       "L 129.135613 81.738791 \n",
       "L 132.758989 83.070468 \n",
       "L 136.382366 84.402144 \n",
       "L 140.005743 85.733821 \n",
       "L 143.629119 87.065498 \n",
       "L 147.252496 88.397174 \n",
       "L 150.875873 89.728851 \n",
       "L 154.499249 91.060528 \n",
       "L 158.122626 92.392204 \n",
       "L 161.746002 93.723881 \n",
       "L 165.369379 95.055558 \n",
       "L 168.992756 96.387234 \n",
       "L 172.616132 97.718911 \n",
       "L 176.239509 99.050588 \n",
       "L 179.862886 100.382265 \n",
       "L 183.486262 101.713941 \n",
       "L 187.109639 103.045618 \n",
       "L 190.733015 104.377295 \n",
       "L 194.356392 105.708971 \n",
       "L 197.979769 107.040648 \n",
       "L 201.603145 108.372325 \n",
       "L 205.226522 109.704001 \n",
       "L 208.849899 111.035678 \n",
       "L 212.473275 112.367355 \n",
       "L 216.096652 113.699032 \n",
       "L 219.720028 115.030708 \n",
       "L 223.343405 116.362385 \n",
       "L 226.966782 117.694062 \n",
       "L 230.590158 119.025738 \n",
       "L 234.213535 120.357415 \n",
       "L 237.836912 121.689092 \n",
       "L 241.460288 123.020768 \n",
       "L 245.083665 124.352445 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 67.53821 85.192655 \n",
       "L 71.161587 85.313989 \n",
       "L 74.784963 85.435322 \n",
       "L 78.40834 85.556655 \n",
       "L 82.031717 85.677989 \n",
       "L 85.655093 85.799322 \n",
       "L 89.27847 85.920655 \n",
       "L 92.901847 86.041989 \n",
       "L 96.525223 86.163322 \n",
       "L 100.1486 86.284655 \n",
       "L 103.771976 86.405989 \n",
       "L 107.395353 86.527322 \n",
       "L 111.01873 86.648655 \n",
       "L 114.642106 86.769989 \n",
       "L 118.265483 86.891322 \n",
       "L 121.88886 87.012655 \n",
       "L 125.512236 87.133989 \n",
       "L 129.135613 87.255322 \n",
       "L 132.758989 87.376655 \n",
       "L 136.382366 87.497989 \n",
       "L 140.005743 87.619322 \n",
       "L 143.629119 87.740655 \n",
       "L 147.252496 87.861989 \n",
       "L 150.875873 87.983322 \n",
       "L 154.499249 88.104655 \n",
       "L 158.122626 88.225989 \n",
       "L 161.746002 88.347322 \n",
       "L 165.369379 88.468655 \n",
       "L 168.992756 88.589989 \n",
       "L 172.616132 88.711322 \n",
       "L 176.239509 88.832655 \n",
       "L 179.862886 88.953989 \n",
       "L 183.486262 89.075322 \n",
       "L 187.109639 89.196655 \n",
       "L 190.733015 89.317989 \n",
       "L 194.356392 89.439322 \n",
       "L 197.979769 89.560655 \n",
       "L 201.603145 89.681989 \n",
       "L 205.226522 89.803322 \n",
       "L 208.849899 89.924655 \n",
       "L 212.473275 90.045988 \n",
       "L 216.096652 90.167322 \n",
       "L 219.720028 90.288655 \n",
       "L 223.343405 90.409988 \n",
       "L 226.966782 90.531322 \n",
       "L 230.590158 90.652655 \n",
       "L 234.213535 90.773988 \n",
       "L 237.836912 90.895322 \n",
       "L 241.460288 91.016655 \n",
       "L 245.083665 91.137988 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 67.53821 13.5 \n",
       "L 71.161587 16.040784 \n",
       "L 74.784963 18.581568 \n",
       "L 78.40834 21.122353 \n",
       "L 82.031717 23.663137 \n",
       "L 85.655093 26.203921 \n",
       "L 89.27847 28.744705 \n",
       "L 92.901847 31.285489 \n",
       "L 96.525223 33.826274 \n",
       "L 100.1486 36.367058 \n",
       "L 103.771976 38.907842 \n",
       "L 107.395353 41.448626 \n",
       "L 111.01873 43.98941 \n",
       "L 114.642106 46.530195 \n",
       "L 118.265483 49.070979 \n",
       "L 121.88886 51.611763 \n",
       "L 125.512236 54.152547 \n",
       "L 129.135613 56.693331 \n",
       "L 132.758989 59.234116 \n",
       "L 136.382366 61.7749 \n",
       "L 140.005743 64.315684 \n",
       "L 143.629119 66.856468 \n",
       "L 147.252496 69.397252 \n",
       "L 150.875873 71.938037 \n",
       "L 154.499249 74.478821 \n",
       "L 158.122626 77.019605 \n",
       "L 161.746002 79.560389 \n",
       "L 165.369379 82.101173 \n",
       "L 168.992756 84.641958 \n",
       "L 172.616132 87.182742 \n",
       "L 176.239509 89.723526 \n",
       "L 179.862886 92.26431 \n",
       "L 183.486262 94.805094 \n",
       "L 187.109639 97.345879 \n",
       "L 190.733015 99.886663 \n",
       "L 194.356392 102.427447 \n",
       "L 197.979769 104.968231 \n",
       "L 201.603145 107.509015 \n",
       "L 205.226522 110.0498 \n",
       "L 208.849899 112.590584 \n",
       "L 212.473275 115.131368 \n",
       "L 216.096652 117.672152 \n",
       "L 219.720028 120.212936 \n",
       "L 223.343405 122.753721 \n",
       "L 226.966782 125.294505 \n",
       "L 230.590158 127.835289 \n",
       "L 234.213535 130.376073 \n",
       "L 237.836912 132.916857 \n",
       "L 241.460288 135.457642 \n",
       "L 245.083665 137.998426 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 67.53821 84.603067 \n",
       "L 71.161587 84.529375 \n",
       "L 74.784963 84.455684 \n",
       "L 78.40834 84.381992 \n",
       "L 82.031717 84.308301 \n",
       "L 85.655093 84.23461 \n",
       "L 89.27847 84.160918 \n",
       "L 92.901847 84.087227 \n",
       "L 96.525223 84.013535 \n",
       "L 100.1486 83.939844 \n",
       "L 103.771976 83.866153 \n",
       "L 107.395353 83.792461 \n",
       "L 111.01873 83.71877 \n",
       "L 114.642106 83.645078 \n",
       "L 118.265483 83.571387 \n",
       "L 121.88886 83.497696 \n",
       "L 125.512236 83.424004 \n",
       "L 129.135613 83.350313 \n",
       "L 132.758989 83.276621 \n",
       "L 136.382366 83.20293 \n",
       "L 140.005743 83.129239 \n",
       "L 143.629119 83.055547 \n",
       "L 147.252496 82.981856 \n",
       "L 150.875873 82.908164 \n",
       "L 154.499249 82.834473 \n",
       "L 158.122626 82.760782 \n",
       "L 161.746002 82.68709 \n",
       "L 165.369379 82.613399 \n",
       "L 168.992756 82.539707 \n",
       "L 172.616132 82.466016 \n",
       "L 176.239509 82.392325 \n",
       "L 179.862886 82.318633 \n",
       "L 183.486262 82.244942 \n",
       "L 187.109639 82.17125 \n",
       "L 190.733015 82.097559 \n",
       "L 194.356392 82.023868 \n",
       "L 197.979769 81.950176 \n",
       "L 201.603145 81.876485 \n",
       "L 205.226522 81.802793 \n",
       "L 208.849899 81.729102 \n",
       "L 212.473275 81.655411 \n",
       "L 216.096652 81.581719 \n",
       "L 219.720028 81.508028 \n",
       "L 223.343405 81.434336 \n",
       "L 226.966782 81.360645 \n",
       "L 230.590158 81.286954 \n",
       "L 234.213535 81.213262 \n",
       "L 237.836912 81.139571 \n",
       "L 241.460288 81.065879 \n",
       "L 245.083665 80.992188 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path d=\"M 67.53821 105.356486 \n",
       "L 71.161587 104.509253 \n",
       "L 74.784963 103.66202 \n",
       "L 78.40834 102.814787 \n",
       "L 82.031717 101.967555 \n",
       "L 85.655093 101.120322 \n",
       "L 89.27847 100.273089 \n",
       "L 92.901847 99.425856 \n",
       "L 96.525223 98.578623 \n",
       "L 100.1486 97.731391 \n",
       "L 103.771976 96.884158 \n",
       "L 107.395353 96.036925 \n",
       "L 111.01873 95.189692 \n",
       "L 114.642106 94.342459 \n",
       "L 118.265483 93.495227 \n",
       "L 121.88886 92.647994 \n",
       "L 125.512236 91.800761 \n",
       "L 129.135613 90.953528 \n",
       "L 132.758989 90.106295 \n",
       "L 136.382366 89.259062 \n",
       "L 140.005743 88.41183 \n",
       "L 143.629119 87.564597 \n",
       "L 147.252496 86.717364 \n",
       "L 150.875873 85.870131 \n",
       "L 154.499249 85.022898 \n",
       "L 158.122626 84.175666 \n",
       "L 161.746002 83.328433 \n",
       "L 165.369379 82.4812 \n",
       "L 168.992756 81.633967 \n",
       "L 172.616132 80.786734 \n",
       "L 176.239509 79.939502 \n",
       "L 179.862886 79.092269 \n",
       "L 183.486262 78.245036 \n",
       "L 187.109639 77.397803 \n",
       "L 190.733015 76.55057 \n",
       "L 194.356392 75.703338 \n",
       "L 197.979769 74.856105 \n",
       "L 201.603145 74.008872 \n",
       "L 205.226522 73.161639 \n",
       "L 208.849899 72.314406 \n",
       "L 212.473275 71.467174 \n",
       "L 216.096652 70.619941 \n",
       "L 219.720028 69.772708 \n",
       "L 223.343405 68.925475 \n",
       "L 226.966782 68.078242 \n",
       "L 230.590158 67.23101 \n",
       "L 234.213535 66.383777 \n",
       "L 237.836912 65.536544 \n",
       "L 241.460288 64.689311 \n",
       "L 245.083665 63.842078 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #e377c2; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 67.53821 58.235766 \n",
       "L 71.161587 59.164246 \n",
       "L 74.784963 60.092726 \n",
       "L 78.40834 61.021206 \n",
       "L 82.031717 61.949686 \n",
       "L 85.655093 62.878166 \n",
       "L 89.27847 63.806647 \n",
       "L 92.901847 64.735127 \n",
       "L 96.525223 65.663607 \n",
       "L 100.1486 66.592087 \n",
       "L 103.771976 67.520567 \n",
       "L 107.395353 68.449047 \n",
       "L 111.01873 69.377527 \n",
       "L 114.642106 70.306007 \n",
       "L 118.265483 71.234488 \n",
       "L 121.88886 72.162968 \n",
       "L 125.512236 73.091448 \n",
       "L 129.135613 74.019928 \n",
       "L 132.758989 74.948408 \n",
       "L 136.382366 75.876888 \n",
       "L 140.005743 76.805368 \n",
       "L 143.629119 77.733848 \n",
       "L 147.252496 78.662329 \n",
       "L 150.875873 79.590809 \n",
       "L 154.499249 80.519289 \n",
       "L 158.122626 81.447769 \n",
       "L 161.746002 82.376249 \n",
       "L 165.369379 83.304729 \n",
       "L 168.992756 84.233209 \n",
       "L 172.616132 85.161689 \n",
       "L 176.239509 86.09017 \n",
       "L 179.862886 87.01865 \n",
       "L 183.486262 87.94713 \n",
       "L 187.109639 88.87561 \n",
       "L 190.733015 89.80409 \n",
       "L 194.356392 90.73257 \n",
       "L 197.979769 91.66105 \n",
       "L 201.603145 92.58953 \n",
       "L 205.226522 93.518011 \n",
       "L 208.849899 94.446491 \n",
       "L 212.473275 95.374971 \n",
       "L 216.096652 96.303451 \n",
       "L 219.720028 97.231931 \n",
       "L 223.343405 98.160411 \n",
       "L 226.966782 99.088891 \n",
       "L 230.590158 100.017371 \n",
       "L 234.213535 100.945852 \n",
       "L 237.836912 101.874332 \n",
       "L 241.460288 102.802812 \n",
       "L 245.083665 103.731292 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #7f7f7f; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_20\">\n",
       "    <path d=\"M 67.53821 139.5 \n",
       "L 71.161587 137.326846 \n",
       "L 74.784963 135.153692 \n",
       "L 78.40834 132.980539 \n",
       "L 82.031717 130.807385 \n",
       "L 85.655093 128.634231 \n",
       "L 89.27847 126.461077 \n",
       "L 92.901847 124.287924 \n",
       "L 96.525223 122.11477 \n",
       "L 100.1486 119.941616 \n",
       "L 103.771976 117.768462 \n",
       "L 107.395353 115.595308 \n",
       "L 111.01873 113.422155 \n",
       "L 114.642106 111.249001 \n",
       "L 118.265483 109.075847 \n",
       "L 121.88886 106.902693 \n",
       "L 125.512236 104.72954 \n",
       "L 129.135613 102.556386 \n",
       "L 132.758989 100.383232 \n",
       "L 136.382366 98.210078 \n",
       "L 140.005743 96.036925 \n",
       "L 143.629119 93.863771 \n",
       "L 147.252496 91.690617 \n",
       "L 150.875873 89.517463 \n",
       "L 154.499249 87.344309 \n",
       "L 158.122626 85.171156 \n",
       "L 161.746002 82.998002 \n",
       "L 165.369379 80.824848 \n",
       "L 168.992756 78.651694 \n",
       "L 172.616132 76.478541 \n",
       "L 176.239509 74.305387 \n",
       "L 179.862886 72.132233 \n",
       "L 183.486262 69.959079 \n",
       "L 187.109639 67.785925 \n",
       "L 190.733015 65.612772 \n",
       "L 194.356392 63.439618 \n",
       "L 197.979769 61.266464 \n",
       "L 201.603145 59.09331 \n",
       "L 205.226522 56.920157 \n",
       "L 208.849899 54.747003 \n",
       "L 212.473275 52.573849 \n",
       "L 216.096652 50.400695 \n",
       "L 219.720028 48.227541 \n",
       "L 223.343405 46.054388 \n",
       "L 226.966782 43.881234 \n",
       "L 230.590158 41.70808 \n",
       "L 234.213535 39.534926 \n",
       "L 237.836912 37.361773 \n",
       "L 241.460288 35.188619 \n",
       "L 245.083665 33.015465 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #bcbd22; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 67.53821 65.359463 \n",
       "L 71.161587 66.197994 \n",
       "L 74.784963 67.036524 \n",
       "L 78.40834 67.875055 \n",
       "L 82.031717 68.713585 \n",
       "L 85.655093 69.552115 \n",
       "L 89.27847 70.390646 \n",
       "L 92.901847 71.229176 \n",
       "L 96.525223 72.067707 \n",
       "L 100.1486 72.906237 \n",
       "L 103.771976 73.744768 \n",
       "L 107.395353 74.583298 \n",
       "L 111.01873 75.421828 \n",
       "L 114.642106 76.260359 \n",
       "L 118.265483 77.098889 \n",
       "L 121.88886 77.93742 \n",
       "L 125.512236 78.77595 \n",
       "L 129.135613 79.614481 \n",
       "L 132.758989 80.453011 \n",
       "L 136.382366 81.291541 \n",
       "L 140.005743 82.130072 \n",
       "L 143.629119 82.968602 \n",
       "L 147.252496 83.807133 \n",
       "L 150.875873 84.645663 \n",
       "L 154.499249 85.484194 \n",
       "L 158.122626 86.322724 \n",
       "L 161.746002 87.161254 \n",
       "L 165.369379 87.999785 \n",
       "L 168.992756 88.838315 \n",
       "L 172.616132 89.676846 \n",
       "L 176.239509 90.515376 \n",
       "L 179.862886 91.353907 \n",
       "L 183.486262 92.192437 \n",
       "L 187.109639 93.030967 \n",
       "L 190.733015 93.869498 \n",
       "L 194.356392 94.708028 \n",
       "L 197.979769 95.546559 \n",
       "L 201.603145 96.385089 \n",
       "L 205.226522 97.22362 \n",
       "L 208.849899 98.06215 \n",
       "L 212.473275 98.90068 \n",
       "L 216.096652 99.739211 \n",
       "L 219.720028 100.577741 \n",
       "L 223.343405 101.416272 \n",
       "L 226.966782 102.254802 \n",
       "L 230.590158 103.093333 \n",
       "L 234.213535 103.931863 \n",
       "L 237.836912 104.770393 \n",
       "L 241.460288 105.608924 \n",
       "L 245.083665 106.447454 \n",
       "\" clip-path=\"url(#p042aaae0e6)\" style=\"fill: none; stroke: #17becf; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 58.660938 145.8 \n",
       "L 58.660938 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 253.960938 145.8 \n",
       "L 253.960938 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 58.660938 145.8 \n",
       "L 253.960938 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 58.660938 7.2 \n",
       "L 253.960938 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p042aaae0e6\">\n",
       "   <rect x=\"58.660938\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lin_func(x, n_sample):\n",
    "    preds = np.zeros((n_sample, x.shape[0]))\n",
    "    for ii in range(n_sample):\n",
    "        w = np.random.normal(0, 1, 2)\n",
    "        y = w[0] + w[1] * x\n",
    "        preds[ii, :] = y\n",
    "    return preds\n",
    "\n",
    "x_points = np.linspace(-5, 5, 50)\n",
    "outs = lin_func(x_points, 10)\n",
    "lw_bd = -2 * np.sqrt((1 + x_points ** 2))\n",
    "up_bd = 2 * np.sqrt((1 + x_points ** 2))\n",
    "\n",
    "d2l.plt.fill_between(x_points, lw_bd, up_bd, alpha=0.25)\n",
    "d2l.plt.plot(x_points, np.zeros(len(x_points)), linewidth=4, color='black')\n",
    "d2l.plt.plot(x_points, outs.T)\n",
    "d2l.plt.xlabel(\"x\", fontsize=20)\n",
    "d2l.plt.ylabel(\"f(x)\", fontsize=20)\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbfkernel(x1, x2, ls=4.):  #@save\n",
    "    dist = distance_matrix(np.expand_dims(x1, 1), np.expand_dims(x2, 1))\n",
    "    return np.exp(-(1. / ls / 2) * (dist ** 2))\n",
    "\n",
    "x_points = np.linspace(0, 5, 50)\n",
    "meanvec = np.zeros(len(x_points))\n",
    "covmat = rbfkernel(x_points,x_points, 1)\n",
    "\n",
    "prior_samples= np.random.multivariate_normal(meanvec, covmat, size=5);\n",
    "d2l.plt.plot(x_points, prior_samples.T, alpha=0.5)\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed577539",
   "metadata": {},
   "source": [
    "### Gaussian Process Inference\n",
    "\n",
    "This section explains how to **do inference (prediction)** with Gaussian Processes (GPs), specifically how to compute the **posterior distribution** over function values at new inputs given observed data. The approach uses conditioning of multivariate Gaussian distributions.\n",
    "\n",
    "#### 1. Setup: GP Prior Over Function Values\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "- training inputs: $\\mathbf{X} = [\\mathbf{x}_1,\\ldots,\\mathbf{x}_n]$\n",
    "- observed function values: $\\mathbf{f} = [f(\\mathbf{x}_1),\\ldots,f(\\mathbf{x}_n)]$\n",
    "\n",
    "Under a GP prior with mean function $m(\\cdot)$ and covariance (kernel) function $k(\\cdot,\\cdot)$, the joint prior over training and test function values is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{f} \\\\ f_*\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\!\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{m} \\\\ m(\\mathbf{x}_*)\n",
    "\\end{bmatrix}\n",
    ",\\,\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{K} & \\mathbf{k}_* \\\\\n",
    "\\mathbf{k}_*^\\top & k_{**}\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{m} = [m(\\mathbf{x}_1),\\ldots,m(\\mathbf{x}_n)]^\\top$\n",
    "- $\\mathbf{K}$ is the $n\\times n$ training covariance matrix\n",
    "- $\\mathbf{k}_* = [k(\\mathbf{x}_1,\\mathbf{x}_*),\\ldots,k(\\mathbf{x}_n,\\mathbf{x}_*)]^\\top$\n",
    "- $k_{**} = k(\\mathbf{x}_*,\\mathbf{x}_*)$\n",
    "\n",
    "This is the prior joint distribution over training and test function values.\n",
    "\n",
    "## 2. Conditional Distribution of a Multivariate Gaussian\n",
    "\n",
    "Key fact:\n",
    "\n",
    "If\n",
    "$$\n",
    "\\begin{bmatrix} \\mathbf{a} \\\\ \\mathbf{b} \\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\Big(\n",
    "\\begin{bmatrix} \\boldsymbol{\\mu}_a \\\\ \\boldsymbol{\\mu}_b \\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "\\Sigma_{aa} & \\Sigma_{ab}\\\\\n",
    "\\Sigma_{ba} & \\Sigma_{bb}\n",
    "\\end{bmatrix}\n",
    "\\Big),\n",
    "$$\n",
    "then the conditional distribution $p(\\mathbf{b}\\mid\\mathbf{a})$ is:\n",
    "\n",
    "$$\n",
    "\\mathbf{b}\\mid\\mathbf{a}\n",
    "\\sim \n",
    "\\mathcal{N}(\\,\n",
    "\\boldsymbol{\\mu}_b \n",
    "+ \\Sigma_{ba}\\Sigma_{aa}^{-1}(\\mathbf{a}-\\boldsymbol{\\mu}_a),\n",
    "\\;\n",
    "\\Sigma_{bb}-\\Sigma_{ba}\\Sigma_{aa}^{-1}\\Sigma_{ab}\n",
    "\\,)\n",
    "$$\n",
    "\n",
    "This identity is the basis of GP inference.\n",
    "\n",
    "#### 3. Predictive Distribution of GP\n",
    "\n",
    "By conditioning the joint Gaussian prior on observed function values, we obtain the **posterior predictive distribution** at a new input $\\mathbf{x}_*$:\n",
    "\n",
    "$$\n",
    "f_* \\mid \\mathbf{X},\\mathbf{f},\\mathbf{x}_*\n",
    "\\sim\n",
    "\\mathcal{N}(\\mu_*,\\,\\sigma_*^2)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "**Predictive mean:**\n",
    "$$\n",
    "\\mu_*\n",
    "= m(\\mathbf{x}_*)\n",
    "+ \\mathbf{k}_*^\\top \\mathbf{K}^{-1}(\\mathbf{f}-\\mathbf{m})\n",
    "$$\n",
    "\n",
    "**Predictive variance:**\n",
    "$$\n",
    "\\sigma_*^2\n",
    "= k_{**} - \\mathbf{k}_*^\\top \\mathbf{K}^{-1}\\mathbf{k}_*\n",
    "$$\n",
    "\n",
    "These formulas show that:\n",
    "- The predictive mean is a linear combination of the kernel similarities between the test point $\\mathbf{x}_*$ and training points.\n",
    "- The predictive variance shrinks near training data and approaches the prior variance far away.\n",
    "\n",
    "#### 4. Observational Noise\n",
    "\n",
    "If observations are noisy:\n",
    "\n",
    "$$\n",
    "y_i = f(\\mathbf{x}_i) + \\varepsilon,\n",
    "\\quad\n",
    "\\varepsilon \\sim \\mathcal{N}(0,\\sigma_n^2),\n",
    "$$\n",
    "\n",
    "Then we replace the covariance matrix $\\mathbf{K}$ with $\\mathbf{K}+\\sigma_n^2\\mathbf{I}$ in the predictive equations:\n",
    "\n",
    "**Mean:**\n",
    "$$\n",
    "\\mu_*\n",
    "= m(\\mathbf{x}_*)\n",
    "+ \\mathbf{k}_*^\\top(\\mathbf{K}+\\sigma_n^2\\mathbf{I})^{-1}(\\mathbf{y}-\\mathbf{m})\n",
    "$$\n",
    "\n",
    "**Variance:**\n",
    "$$\n",
    "\\sigma_*^2\n",
    "= k_{**} - \\mathbf{k}_*^\\top(\\mathbf{K}+\\sigma_n^2\\mathbf{I})^{-1}\\mathbf{k}_*\n",
    "$$\n",
    "\n",
    "Noise increases predictive uncertainty and changes the effective influence of training points.\n",
    "\n",
    "## 5. Insight from Predictive Formulas\n",
    "\n",
    "### Influence of Training Points\n",
    "\n",
    "- If $\\mathbf{x}_*$ is close (in kernel distance) to training points, $\\mathbf{k}_*$ is large and predictions rely heavily on data.\n",
    "- If $\\mathbf{x}_*$ is far from all training points, $\\mathbf{k}_*$ is small → the posterior mean goes toward prior mean and variance toward prior variance.\n",
    "\n",
    "### Uncertainty Quantification\n",
    "\n",
    "Predictive variance captures two effects:\n",
    "1. **kernel structure** (how smoothly outputs vary)\n",
    "2. **data coverage** (distance to training points)\n",
    "\n",
    "GPs thus give principled uncertainty estimates.\n",
    "\n",
    "## 6. Matrix Form Perspective\n",
    "\n",
    "For $m=|\\mathbf{x}_*|$ new inputs $\\mathbf{X}_*$, define:\n",
    "\n",
    "- $\\mathbf{K}_{**} = k(\\mathbf{X}_*,\\mathbf{X}_*)$\n",
    "- $\\mathbf{K}_* = k(\\mathbf{X},\\mathbf{X}_*)$\n",
    "- $\\mathbf{K}_*^\\top = k(\\mathbf{X}_*,\\mathbf{X})$\n",
    "\n",
    "Then the **joint predictive distribution** is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{f}\\\\\n",
    "\\mathbf{f}_*\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{m}\\\\\n",
    "\\mathbf{m}_*\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{K} & \\mathbf{K}_*\\\\\n",
    "\\mathbf{K}_*^\\top & \\mathbf{K}_{**}\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Conditioning yields vectorized formulas for the mean and covariance over all new inputs.\n",
    "\n",
    "#### 7. Core Takeaways\n",
    "\n",
    "- GP inference uses conditioning of joint Gaussians to compute posterior predictions.\n",
    "- The predictive mean is a weighted combination of observed values.\n",
    "- The predictive variance reflects both kernel structure and distance from training data.\n",
    "- Observational noise is handled by inflating the covariance matrix.\n",
    "\n",
    "#### 8. Why This Matters\n",
    "\n",
    "GP inference gives:\n",
    "- **closed-form expressions** for predictions\n",
    "- **quantified uncertainty**\n",
    "- **nonparametric adaptation** with more data\n",
    "\n",
    "GPs thus provide a principled Bayesian approach to regression and uncertainty estimation without parametric assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397fbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_maker1(x, sig):\n",
    "    return np.sin(x) + 0.5 * np.sin(4 * x) + np.random.randn(x.shape[0]) * sig\n",
    "\n",
    "sig = 0.25\n",
    "train_x, test_x = np.linspace(0, 5, 50), np.linspace(0, 5, 500)\n",
    "train_y, test_y = data_maker1(train_x, sig=sig), data_maker1(test_x, sig=0.)\n",
    "\n",
    "d2l.plt.scatter(train_x, train_y)\n",
    "d2l.plt.plot(test_x, test_y)\n",
    "d2l.plt.xlabel(\"x\", fontsize=20)\n",
    "d2l.plt.ylabel(\"Observations y\", fontsize=20)\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbe0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros(test_x.shape[0])\n",
    "cov = d2l.rbfkernel(test_x, test_x, ls=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samples = np.random.multivariate_normal(mean=mean, cov=cov, size=5)\n",
    "d2l.plt.plot(test_x, prior_samples.T, color='black', alpha=0.5)\n",
    "d2l.plt.plot(test_x, mean, linewidth=2.)\n",
    "d2l.plt.fill_between(test_x, mean - 2 * np.diag(cov), mean + 2 * np.diag(cov),\n",
    "                 alpha=0.25)\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ell_est = 0.4\n",
    "post_sig_est = 0.5\n",
    "\n",
    "def neg_MLL(pars):\n",
    "    K = d2l.rbfkernel(train_x, train_x, ls=pars[0])\n",
    "    kernel_term = -0.5 * train_y @ \\\n",
    "        np.linalg.inv(K + pars[1] ** 2 * np.eye(train_x.shape[0])) @ train_y\n",
    "    logdet = -0.5 * np.log(np.linalg.det(K + pars[1] ** 2 * \\\n",
    "                                         np.eye(train_x.shape[0])))\n",
    "    const = -train_x.shape[0] / 2. * np.log(2 * np.pi)\n",
    "\n",
    "    return -(kernel_term + logdet + const)\n",
    "\n",
    "\n",
    "learned_hypers = optimize.minimize(neg_MLL, x0=np.array([ell_est,post_sig_est]),\n",
    "                                   bounds=((0.01, 10.), (0.01, 10.)))\n",
    "ell = learned_hypers.x[0]\n",
    "post_sig_est = learned_hypers.x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a657c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_x_xstar = d2l.rbfkernel(train_x, test_x, ls=ell)\n",
    "K_x_x = d2l.rbfkernel(train_x, train_x, ls=ell)\n",
    "K_xstar_xstar = d2l.rbfkernel(test_x, test_x, ls=ell)\n",
    "\n",
    "post_mean = K_x_xstar.T @ np.linalg.inv((K_x_x + \\\n",
    "                post_sig_est ** 2 * np.eye(train_x.shape[0]))) @ train_y\n",
    "post_cov = K_xstar_xstar - K_x_xstar.T @ np.linalg.inv((K_x_x + \\\n",
    "                post_sig_est ** 2 * np.eye(train_x.shape[0]))) @ K_x_xstar\n",
    "\n",
    "lw_bd = post_mean - 2 * np.sqrt(np.diag(post_cov))\n",
    "up_bd = post_mean + 2 * np.sqrt(np.diag(post_cov))\n",
    "\n",
    "d2l.plt.scatter(train_x, train_y)\n",
    "d2l.plt.plot(test_x, test_y, linewidth=2.)\n",
    "d2l.plt.plot(test_x, post_mean, linewidth=2.)\n",
    "d2l.plt.fill_between(test_x, lw_bd, up_bd, alpha=0.25)\n",
    "d2l.plt.legend(['Observed Data', 'True Function', 'Predictive Mean', '95% Set on True Func'])\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47efef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_bd_observed = post_mean - 2 * np.sqrt(np.diag(post_cov) + post_sig_est ** 2)\n",
    "up_bd_observed = post_mean + 2 * np.sqrt(np.diag(post_cov) + post_sig_est ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples = np.random.multivariate_normal(post_mean, post_cov, size=20)\n",
    "d2l.plt.scatter(train_x, train_y)\n",
    "d2l.plt.plot(test_x, test_y, linewidth=2.)\n",
    "d2l.plt.plot(test_x, post_mean, linewidth=2.)\n",
    "d2l.plt.plot(test_x, post_samples.T, color='gray', alpha=0.25)\n",
    "d2l.plt.fill_between(test_x, lw_bd, up_bd, alpha=0.25)\n",
    "plt.legend(['Observed Data', 'True Function', 'Predictive Mean', 'Posterior Samples'])\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ee6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's convert our data into tensors for use with PyTorch\n",
    "train_x = torch.tensor(train_x)\n",
    "train_y = torch.tensor(train_y)\n",
    "test_y = torch.tensor(test_y)\n",
    "\n",
    "# We are using exact GP inference with a zero mean and RBF kernel\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c76fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gaussian likelihood\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "training_iter = 50\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "# Use the adam optimizer, includes GaussianLikelihood parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "# Set our loss as the negative log GP marginal likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b504f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iter {i+1:d}/{training_iter:d} - Loss: {loss.item():.3f} '\n",
    "              f'squared lengthscale: '\n",
    "              f'{model.covar_module.base_kernel.lengthscale.item():.3f} '\n",
    "              f'noise variance: {model.likelihood.noise.item():.3f}')\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "test_x = torch.tensor(test_x)\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35750be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = d2l.plt.subplots(1, 1, figsize=(4, 3))\n",
    "    # Get upper and lower bounds for 95\\% credible set (in this case, in\n",
    "    # observation space)\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    ax.scatter(train_x.numpy(), train_y.numpy())\n",
    "    ax.plot(test_x.numpy(), test_y.numpy(), linewidth=2.)\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), linewidth=2.)\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.25)\n",
    "    ax.set_ylim([-1.5, 1.5])\n",
    "    ax.legend(['True Function', 'Predictive Mean', 'Observed Data',\n",
    "               '95% Credible Set'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
